{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"fr\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Tracking de Particules avec Trackpy</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "        }\n",
    "        h1 {\n",
    "            color: skyblue;\n",
    "            font-size: 24px;\n",
    "        }\n",
    "        p {\n",
    "            font-size: 16px;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Tracking de Particules avec Trackpy</h1>\n",
    "    <p>Ce code est conçu pour effectuer le tracking de particules à partir de séquences d'images, notamment des mosaïques obtenues par microscopie. Nous utilisons pour cela la librairie Trackpy, spécialisée dans l'analyse de trajectoires de particules.</p>\n",
    "    <p>Toutes les expériences contenues dans le dossier spécifié sont automatiquement analysées. Le processus consiste à :</p>\n",
    "    <ol>\n",
    "        <li><strong>Identification des particules :</strong> Détecter et enregistrer les données de toutes les particules visibles sur chaque image de la séquence.</li>\n",
    "        <li><strong>Enregistrement des trajectoires :</strong> Compiler les mouvements des particules à travers les images pour former des trajectoires cohérentes, qui sont ensuite enregistrées dans un fichier dédié.</li>\n",
    "    </ol>\n",
    "    <p>Les fichiers générés comprennent des données détaillées sur les particules pour chaque frame et un second fichier contenant les trajectoires complètes. Ces données sont préparées pour être réanalysées et traitées plus en détail dans un second code.</p>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Aug 21 10:51:23 2023\n",
    "\n",
    "@author: souchaud\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import imageio.v2 as imageio\n",
    "import cv2\n",
    "import gc  # Garbage Collector interface\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import trackpy as tp\n",
    "from scipy import ndimage\n",
    "from skimage import util\n",
    "from tqdm import tqdm\n",
    "# import functions_track_and_analyze as lib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "# from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidated parameters\n",
    "CONDITION = 'CytoOne_HL5_AMPC_10x'\n",
    "PARAMS = {\n",
    "        # Préparation images\n",
    "        'GaussianBlur': (5, 5), # (19, 19), #  (5, 5),\n",
    "        'sigmaX': 10,\n",
    "        'sigmaY': 10, \n",
    "        'threshold': 1, # 3, # 10  # 40,\n",
    "        'percentile': 10, #10,\n",
    "        'lenght_study': 50, # Découpage de la manip en nombre de frale pour favoriser l'étude (performence ordi)\n",
    "        'smoothing_size': None,\n",
    "        'invert': False,\n",
    "        'preprocess': True, \n",
    "        'characterize': True,\n",
    "        'filter_before': None,\n",
    "        'filter_after': None,\n",
    "        # Paramètres Manip\n",
    "        'pixel_size': 0.637,  # 1.2773, # en um\n",
    "        'frame_interval': 15, # temps entre chaque frame [s]\n",
    "        'long_time': False,\n",
    "        'max_frame': 340, # 340, #340 # Nombre de frame d'étude max.\n",
    "        'min_frames': 150, #150, # Nombre de frame sur laquelle doit être suivie une cellule\n",
    "        'topn': 1500, # None, # Nombre de particules max à détecter\n",
    "\n",
    "        # Détéction particules\n",
    "        'diameter': 15,  # 15, # Diamètres évalué des particules\n",
    "        'max_displacement': 30, # 35, # 25, # Déplacement maximal des cellules entre deux images (en pixel)\n",
    "        'search_range': 30, #  30, #  20 # même chose\n",
    "        'minmass': 500, #  Mass minimale mesurée des cellules\n",
    "        'max_size': 30, # 25, # Taille maximum de la particule\n",
    "        'separation': 20, # 9, # distance mimimanl pour séparé deux objets\n",
    "        'noise_size': 3,  # 7, # 7, # taille des particules à exclure \n",
    "        'max_iterations': 15, # Nombre d'itérations max pour résoudre un sous-réseau (déterminer les trajectoires entre 2 cellules)\n",
    "        'memory': 5, # Nombre de frame au dela de laquelle on oublie la cellule\n",
    "        'engine': 'auto',\n",
    "\n",
    "        # Format et chemins\n",
    "        'remove_exts': ['.jpg', '.svg', 'hdf5', '.png'],   \n",
    "        # 'data_dir': '/Users/souchaud/Desktop/A_Analyser/CytoOne_SorC_10x/',\n",
    "        'data_dir': os.path.join('/Users/souchaud/Desktop/A_Analyser/',CONDITION),\n",
    "        # 'data_dir': '/Volumes/Labo_Alex_Mac/A_analyser/CytoOne_HL5/',\n",
    "        # 'data_dir': '/Users/souchaud/Desktop/A_Analyser/NonT_SorC/',\n",
    "        # 'output_dir': '/Users/souchaud/Desktop/Analyses/CytoOne_HL5_longtime/'\n",
    "        # 'data_dir': '/Volumes/Labo_Alex_Mac/A_analyser/CytoOne_HL5/',´\n",
    "        # 'output_dir': '/Users/souchaud/Desktop/Analyses/CytoOne_SorC_10x_results_tracking/'\n",
    "        'output_dir': os.path.join('/Users/souchaud/Desktop/Analyses/', CONDITION + '_results_tracking')\n",
    "        # 'output_dir': '/Users/souchaud/Desktop/Analyses/NonT_SorC_longtime_New/'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAMES = [f + '/mosaic/' for f in os.listdir(PARAMS['data_dir'])\n",
    "                    if os.path.isdir(os.path.join(PARAMS['data_dir'], f))]\n",
    "print(EXPERIMENT_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_speed(filtered):\n",
    "    \"\"\"\n",
    "    Compute mean speed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - filtered: DataFrame with tracked cells\n",
    "    Returns\n",
    "    - mean_speed: Mean speed of all particles\n",
    "    - mean_speed_part: Mean speed per particle\n",
    "    \"\"\"\n",
    "    dx = filtered.groupby('particle')['x'].diff()\n",
    "    dy = filtered.groupby('particle')['y'].diff()\n",
    "    displacement = np.sqrt(dx**2 + dy**2)\n",
    "    duration = filtered.groupby('particle')['frame'].diff() * PARAMS['frame_interval']\n",
    "    mean_speed = (displacement.sum() / duration.sum()) * PARAMS['pixel_size'] * 60\n",
    "    instant_speed = displacement / duration\n",
    "    mean_speed_part = instant_speed.groupby(filtered['particle']).mean() * PARAMS['pixel_size'] * 60\n",
    "    return mean_speed, mean_speed_part\n",
    "\n",
    "\n",
    "def clean_directory(dir_path):\n",
    "    \"\"\"Remove all files with the specified extensions in the directory.\"\"\"\n",
    "    for file in os.listdir(dir_path):\n",
    "        if file.endswith(tuple(PARAMS['remove_exts'])):\n",
    "            os.remove(os.path.join(dir_path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_brightness_contrast(img, brightness=0, contrast=0):\n",
    "    \"\"\" Ajuster la luminosité et le contraste d'une image \"\"\"\n",
    "    B = brightness / 100.0\n",
    "    C = contrast / 100.0\n",
    "    k = np.tan((45 + 44 * C) / 180 * np.pi)\n",
    "\n",
    "    img = (img - 127.5 * (1 - B)) * k + 127.5 * (1 + B)\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_experiment(exp_name, PARAMS):\n",
    "    \"\"\"Process a single experiment.\"\"\"\n",
    "    output_path = os.path.join(PARAMS['output_dir'], exp_name)\n",
    "    print(\"output_path : \", output_path)\n",
    "    # Séparer la chaîne au premier \"/\"\n",
    "    exp_name_solo = exp_name.split('/', 1)[0]\n",
    "    print(\"exp name : \", exp_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    clean_directory(output_path)\n",
    "\n",
    "    experiment_data_dir = os.path.join(PARAMS['data_dir'], exp_name)\n",
    "\n",
    "    def extract_number(filename):\n",
    "        # Extrait le numéro à partir du nom de fichier\n",
    "        base_name = os.path.basename(filename)\n",
    "        # Supprime l'extension et extrait le numéro\n",
    "        number = int(base_name.split('_')[-1].split('.')[0])\n",
    "        return number\n",
    "\n",
    "    tiff_files = sorted(glob.glob(os.path.join(experiment_data_dir, \"*.tif\")), key=extract_number)\n",
    "\n",
    "    # Use PARAMS dictionary to get the parameters\n",
    "    frame_data = []\n",
    "    frame_counter = 0\n",
    "    boucle = []\n",
    "    if PARAMS['long_time'] is False:\n",
    "        if len(os.listdir(experiment_data_dir)) < PARAMS['max_frame']:\n",
    "            nbr_frame_study_total = len(os.listdir(experiment_data_dir))\n",
    "        else:\n",
    "            nbr_frame_study_total = PARAMS['max_frame']\n",
    "    else:\n",
    "        nbr_frame_study_total = len(os.listdir(experiment_data_dir))\n",
    "\n",
    "    lenght_study = PARAMS['lenght_study']\n",
    "    if nbr_frame_study_total > lenght_study:\n",
    "        number = lenght_study\n",
    "        while number < nbr_frame_study_total:\n",
    "            boucle.append(lenght_study)\n",
    "            number += lenght_study\n",
    "            if number > nbr_frame_study_total:\n",
    "                boucle.append(nbr_frame_study_total - len(boucle) * lenght_study)\n",
    "        nbr_frame_study = lenght_study\n",
    "    else:\n",
    "        nbr_frame_study = nbr_frame_study_total\n",
    "        boucle.append(nbr_frame_study)\n",
    "\n",
    "    # Process each batch of frames\n",
    "    frame_0 = None  # Initialize frame_0 with a default value\n",
    "    for i in tqdm(boucle, desc=\"processing batches\"):\n",
    "        batch_frames = tiff_files[frame_counter:frame_counter + i]\n",
    "        batch_data = [np.array(imageio.imread(tiff_file)) for tiff_file in batch_frames]\n",
    "        time_count = time.time()\n",
    "\n",
    "        for num, frame in enumerate(batch_data):\n",
    "            # Prétraitement\n",
    "            blurred = ndimage.median_filter(frame, size=8)\n",
    "            blurred = cv2.GaussianBlur(blurred, PARAMS['GaussianBlur'], 0)\n",
    "            # equalized = cv2.equalizeHist(blurred)\n",
    "            frame = blurred\n",
    "            batch_data[num] = frame\n",
    "\n",
    "            if num == 0:\n",
    "                if frame_counter == 0:\n",
    "                    frame_0 = frame  # Ensure frame_0 is assigned here\n",
    "                    \n",
    "                plt.figure(figsize=(12, 6))\n",
    "                plt.imshow(frame_0, cmap='gray')\n",
    "                plt.show()\n",
    "            \n",
    "                f = tp.locate(frame,\n",
    "                              diameter=PARAMS['diameter'],\n",
    "                              minmass=PARAMS['minmass'],\n",
    "                              maxsize=PARAMS['max_size'],\n",
    "                              separation=PARAMS['separation'],\n",
    "                              noise_size=PARAMS['noise_size'],\n",
    "                              smoothing_size=PARAMS['smoothing_size'],\n",
    "                              threshold=PARAMS['threshold'],\n",
    "                              invert=PARAMS['invert'],\n",
    "                              percentile=PARAMS['percentile'],\n",
    "                              topn=PARAMS['topn'],\n",
    "                              preprocess=PARAMS['preprocess'],\n",
    "                              max_iterations=PARAMS['max_iterations'],\n",
    "                              filter_before=PARAMS['filter_before'],\n",
    "                              filter_after=PARAMS['filter_after'],\n",
    "                              characterize=PARAMS['characterize'],\n",
    "                              engine=PARAMS['engine'])\n",
    "                print(len(f))\n",
    "\n",
    "                transformed_image_path = os.path.join(output_path, f'transformed_frame_{i}.jpg')\n",
    "                cv2.imwrite(transformed_image_path, frame)\n",
    "\n",
    "                fig, ax = plt.subplots(figsize=(12, 6))\n",
    "                tp.annotate(f, frame, ax=ax)\n",
    "                display(fig)\n",
    "\n",
    "                # Extract size information\n",
    "                # The specific column name depends on your data; it might be 'size', 'mass', etc.\n",
    "                sizes = f['size']\n",
    "\n",
    "                # Plot the particle sizes\n",
    "                # plt.figure(figsize=(12, 6))\n",
    "                fig, ax = plt.subplots(figsize=(12, 6))\n",
    "                plt.hist(sizes, bins=30)\n",
    "                plt.xlabel('Particle size')\n",
    "                plt.ylabel('Frequency')\n",
    "                plt.title('Particle Size Distribution')\n",
    "                plt.savefig(os.path.join(output_path, f'Hist_size_{i}.jpg'), format='jpg')  # Enregistrer avant de montrer\n",
    "                # plt.show()\n",
    "                display(fig)\n",
    "\n",
    "                # plt.figure(figsize=(12,6))\n",
    "                fig, ax = plt.subplots(figsize=(12, 6))\n",
    "                tp.mass_size(f, ax=ax)  # Assurez-vous que 'f' est correctement configuré\n",
    "                plt.savefig(os.path.join(output_path, f'mass_size_{i}.jpg'), format='jpg')\n",
    "                # plt.show()\n",
    "                # plt.close()  # Ferme la figure\n",
    "                display(fig)\n",
    "            del frame\n",
    "        print(\"temps de travail sur les images : \", (time.time() - time_count)/60, \"min\")\n",
    "        try:\n",
    "            cells_loc = tp.batch(batch_data,\n",
    "                                diameter= PARAMS['diameter'], #PARAMS['diameter'],\n",
    "                                minmass=PARAMS['minmass']                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,\n",
    "                                maxsize=PARAMS['max_size'],\n",
    "                                separation=PARAMS['separation'],\n",
    "                                noise_size=PARAMS['noise_size'],\n",
    "                                smoothing_size=PARAMS['smoothing_size'],\n",
    "                                threshold=PARAMS['threshold'],\n",
    "                                invert=PARAMS['invert'],\n",
    "                                percentile=PARAMS['percentile'],\n",
    "                                topn=PARAMS['topn'],\n",
    "                                preprocess=PARAMS['preprocess'],\n",
    "                                max_iterations=PARAMS['max_iterations'],\n",
    "                                filter_before=PARAMS['filter_before'],\n",
    "                                filter_after=PARAMS['filter_after'],\n",
    "                                characterize=PARAMS['characterize'],\n",
    "                                engine=PARAMS['engine'],\n",
    "                                )\n",
    "            display(cells_loc)\n",
    "            cells_loc['frame'] += frame_counter\n",
    "            frame_counter += i\n",
    "            frame_data.append(cells_loc)\n",
    "            del cells_loc\n",
    "        except Exception as e:\n",
    "            print(f\"{exp_name} got an issue.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            del batch_data  # Tente de supprimer batch_data si elle existe\n",
    "        except NameError:\n",
    "            pass  # Ne fait rien si batch_data n'existe pas\n",
    "\n",
    "        gc.collect()  # Force la collecte de déchets pour libérer de la mémoire\n",
    "\n",
    "\n",
    "    all_features = pd.concat(frame_data)\n",
    "\n",
    "    try:\n",
    "        trajectories = tp.link_df(all_features,\n",
    "                                  search_range=PARAMS['search_range'],  # PARAMS['max_displacement'],\n",
    "                                  memory=PARAMS['memory'],\n",
    "                                  neighbor_strategy='KDTree',\n",
    "                                  link_strategy='auto',  # 'hybrid',\n",
    "                                  adaptive_stop=30,\n",
    "                                  # verify_integritxy=True,\n",
    "                                  )\n",
    "        trajectories.to_hdf(os.path.join(output_path, 'filtered.hdf5'), 'table')\n",
    "        # verify_intetegrity=True)\n",
    "        # neighbor_strategy='KDTree',\n",
    "    except tp.SubnetOversizeException:\n",
    "        print(\"Issue with this one\")\n",
    "        \n",
    "    if trajectories.empty:\n",
    "        print(\"oupsy oups\")\n",
    "        return\n",
    "    filtered = tp.filter_stubs(trajectories, PARAMS['min_frames'])\n",
    "    # filtered = filtered[~filtered.particle.isin(\n",
    "    #     tp.filter_clusters(filtered, quantile=0.1,\n",
    "    #                        threshold=filtered['size'].mean() * 1).index)]\n",
    "    all_features.to_hdf(os.path.join(output_path, 'features.hdf5'), 'table')\n",
    "    filtered.to_hdf(os.path.join(output_path, 'filtered.hdf5'), 'table')\n",
    "    if not filtered.empty:\n",
    "        if frame_0 is not None:\n",
    "            fig, ax = plt.subplots(figsize=(10, 10))\n",
    "            plt.title(f'Trajectories after suspicious particles {exp_name}')\n",
    "            tp.plot_traj(filtered, ax=ax, superimpose=frame_0, label=False)\n",
    "            plt.savefig(f'{output_path}/trajectories_{exp_name_solo}.png')  # Sauvegarder la figure\n",
    "            plt.close(fig)  # Fermer la figure pour libérer la mémoire\n",
    "    else:\n",
    "        print(f\"No trajectories to plot for {exp_name}.\")\n",
    "    gc.collect()  # Force la collecte de déchets pour libérer de la mémoire\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Process all experiments.\"\"\"\n",
    "    for exp_name in EXPERIMENT_NAMES:\n",
    "        print(exp_name)\n",
    "        process_experiment(exp_name, PARAMS)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracking_and_analyse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
