{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "Code d'analyse de tracking. Il permet de récupérer les fichiers issus du tracking et d'en tirer les trajectoires pertinentes et d'en faire l'étude statistique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Mar  1 12:46:56 2023.\n",
    "\n",
    "@author: souchaud\n",
    "\"\"\"\n",
    "# %%\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.optimize import curve_fit, minimize_scalar\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.gridspec as gridspec\n",
    "import trackpy as tp\n",
    "import functions_analyze as lib\n",
    "import warnings\n",
    "import importlib\n",
    "from collections import defaultdict\n",
    "from colorama import init, Fore, Style\n",
    "from typing import List, Optional, Union, Any, Dict, Tuple\n",
    "importlib.reload(lib)\n",
    "\n",
    "init(autoreset=True)\n",
    "# from matplotlib.cm import ScalarMappable\n",
    "# import pdb; pdb.set_trace()\n",
    "# warnings.simplefilter(\"always\")  # This will always display warnings\n",
    "# warnings.simplefilter('error', RuntimeWarning)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisation des variables et constantes de travail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial time\n",
    "INITIAL_TIME = time.time()\n",
    "\n",
    "# experiment parameters\n",
    "TIME_FRAME = 15 # 15  # 75\n",
    "SIZE_PIX = 0.637# 1.2773  # 1.634  # 4.902\n",
    "FPS = 1/TIME_FRAME\n",
    "\n",
    "# File to study\n",
    "file_name = 'filtered_final' # 'features'  # 'filtered'Any\n",
    "# number of frame kept\n",
    "N_FRAME = 2\n",
    "N_FRAME_MIN_STUDY = 100  # Nombre minimal de frame sur laquelle la cellule doit être suivie\n",
    "\n",
    "# nber hours of stydy:\n",
    "LONG_TIME = False\n",
    "\n",
    "# Study parameters\n",
    "ROLLING_MEAN = False\n",
    "PIXELISATION = False\n",
    "TIME_FRAME_STUDY = False\n",
    "DRIFT = False\n",
    "\n",
    "# plot parameters\n",
    "IMG_TYPE = 'jpg'\n",
    "ALPHA = 0.5\n",
    "LINEWIDTH = 0.1\n",
    "COLOR_SUP = 'blue'\n",
    "COLOR_INF = 'red'\n",
    "color_sup_inf = (COLOR_SUP, COLOR_INF)\n",
    "\n",
    "# % de présences de la particules sur le total de frame étudiées\n",
    "\n",
    "FRAME_PARTICULE = 1\n",
    "\n",
    "# ##########\n",
    "# % de présences des courbes dans les frames\n",
    "\n",
    "FRAME_PARTICULE = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition des path et dossiers de travails / enregistrements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##########################   GENERAL PATH   #################################\n",
    "GENERAL_PATH = '/Users/souchaud/Desktop/Analyses/'\n",
    "GENERAL_PATH_PICTURES = '/Users/souchaud/Desktop/A_analyser/'\n",
    "# GENERAL_PATH_PICTURES = '/Volumes/Labo_Alex_Mac/A_analyser/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# CONDITION SIMPLE ################\n",
    "# CONDITION_simple = 'CytoOne_SorC'\n",
    "# CONDITION_simple = 'NonT_SorC'\n",
    "CONDITION_simple = 'CytoOne_HL5_10x'\n",
    "# CONDITION_simple = 'CytoOne_HL5'\n",
    "\n",
    "############### CONDITION ################\n",
    "CONDITION = f'{CONDITION_simple}_new_param' # _longtime_new_param'\n",
    "# CONDITION = 'ASMOT035_fiji'\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of pathway to the experiments\n",
    "PATHWAY_EXPERIMENT = []\n",
    "\n",
    "if len(PATHWAY_EXPERIMENT) == 0:\n",
    "    PATHWAY_EXPERIMENT = [f for f in os.listdir(GENERAL_PATH + CONDITION) if\n",
    "                          os.path.isdir(os.path.join(GENERAL_PATH + CONDITION, f))]\n",
    "# ##########################   Path Exp final  ###############################\n",
    "\n",
    "PATHWAY_EXPERIMENT = [f'{GENERAL_PATH}{CONDITION}/' +\n",
    "                      elem + '/mosaic/' for elem in PATHWAY_EXPERIMENT]\n",
    "\n",
    "# ##########################   Path to Save pic  ##############################\n",
    "\n",
    "path_save_pic = f'{GENERAL_PATH}résultats_{CONDITION}_ALL_OK_x5_15s/'\n",
    "\n",
    "# création d'un dossier spécific d'enregistrement.\n",
    "if not os.path.exists(path_save_pic):\n",
    "    os.mkdir(path_save_pic)\n",
    "os.chdir(path_save_pic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture des données expériementales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(lib)\n",
    "DATA = lib.read_hdf5_all(pathway_experiment=PATHWAY_EXPERIMENT, name_file=file_name,\n",
    "                         nbr_frame_min=N_FRAME_MIN_STUDY, condition=CONDITION, drift=DRIFT,\n",
    "                         search_range=20, memory=5)\n",
    "# Trier le DataFrame par la colonne \"frame\"\n",
    "DATA = DATA.sort_values(by='frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA['experiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On décide de travailler que sur un certain nombre de frame. Ici je décide de travailler sur les 240 première frames. \n",
    "Donc la cellules doit être suivi sur N_MIN_STUDY sur les 240 premières frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre de particule avant tri: \", DATA['particle'].nunique())\n",
    "DATA = DATA[DATA['frame'] < 340]\n",
    "\n",
    "filter_data = DATA.groupby('particle').filter(lambda x: len(x) >= N_FRAME_MIN_STUDY)\n",
    "print(\"Nombre de particule après le premier tri sur le temps suivi des cellules: \", filter_data['particle'].nunique())\n",
    "DATA = filter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA['time (min)'] = DATA['frame']*TIME_FRAME/60\n",
    "DATA = lib.vit_instant_new(traj=DATA, lag_time=TIME_FRAME, pix_size=SIZE_PIX, triage=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = DATA.query(f'frame % {N_FRAME} == 0')\n",
    "# DATA['frame'] = pd.factorize(DATA['frame'])[0]\n",
    "# FPS = FPS/N_FRAME\n",
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supposons que DATA est votre DataFrame et qu'il contient une colonne 'manip' pour identifier chaque manipulation\n",
    "manips = DATA['experiment'].unique()\n",
    "num_manips = len(manips)\n",
    "\n",
    "# Créer une figure pour accueillir tous les subplots\n",
    "fig = plt.figure(figsize=(16, 6*num_manips))\n",
    "\n",
    "# Créer un gridspec pour mieux organiser les subplots\n",
    "gs = gridspec.GridSpec(num_manips, 3, fig)\n",
    "\n",
    "colors = ['skyblue', 'lightgreen', 'salmon']  # Couleurs pour les différents types de graphiques\n",
    "\n",
    "for i, manip in enumerate(manips):\n",
    "    data_manip = DATA[DATA['experiment'] == manip]\n",
    "    mass_means = data_manip.groupby('particle')['mass'].mean()\n",
    "    size_means = data_manip.groupby('particle')['size'].mean()\n",
    "\n",
    "    # Masse moyenne\n",
    "    ax1 = fig.add_subplot(gs[i, 0])\n",
    "    ax1.hist(mass_means, bins=100, color=colors[0], density=True)\n",
    "    ax1.set_title(f\"Mean mass of particles for {manip}\")\n",
    "    ax1.set_xlabel(\"Mean mass\")\n",
    "    ax1.set_ylabel(\"Density\")\n",
    "\n",
    "    # Taille moyenne\n",
    "    ax2 = fig.add_subplot(gs[i, 1])\n",
    "    ax2.hist(size_means, bins=100, color=colors[1], density=True)\n",
    "    ax2.set_title(f\"Mean size of particles for {manip}\")\n",
    "    ax2.set_xlabel(\"Mean size\")\n",
    "    ax2.set_ylabel(\"Density\")\n",
    "\n",
    "    # Mass vs. Size au frame 0\n",
    "    filtered_data = data_manip[data_manip['frame'] == 0]\n",
    "    ax3 = fig.add_subplot(gs[i, 2])\n",
    "    tp.mass_size(filtered_data, ax=ax3)\n",
    "    ax3.set_title(f\"Mass vs. Size at frame 0 for {manip}\")\n",
    "\n",
    "# Ajuster l'espacement entre les subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Afficher la figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In[Filter on mass]\n",
    "# if 'mass' in DATA.columns:\n",
    "#     mask = DATA.groupby('particle')['mass'].transform('mean') >= 1000\n",
    "#     DATA = DATA[mask]\n",
    "# if 'level_0' in DATA.columns:\n",
    "#     DATA = DATA.drop('level_0', axis=1)\n",
    "# DATA.reset_index(inplace=True)\n",
    "# # In[Compute some datas as instant displacement /speed / centering trajectories ...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On trace le nombre de particules par frame en fonction du temps pour chaque manips. Ca permets de repérer des anomalies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les expériences uniques pour les itérations\n",
    "experiments = DATA['experiment'].unique()\n",
    "\n",
    "# Déterminer le nombre de lignes et de colonnes pour les sous-graphiques\n",
    "# Vous pouvez ajuster cela en fonction du nombre total d'expériences\n",
    "n_cols = 2  # Nombre de colonnes, ajustez selon le besoin\n",
    "n_rows = (len(experiments) + n_cols - 1) // n_cols  # Nombre de lignes\n",
    "\n",
    "# Créer une figure et des axes pour les sous-graphiques\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(20 * n_cols, 10 * n_rows))\n",
    "axs = axs.flatten()  # Aplatir le tableau d'axes si nécessaire\n",
    "\n",
    "# Tracer les graphiques pour chaque expérience\n",
    "for i, exp in enumerate(experiments):\n",
    "    # Grouper les données par 'frame' et calculer le nombre de particules par frame\n",
    "    nbr_part_per_frame = DATA[DATA['experiment'] == exp].groupby('time (min)')['particle'].nunique()\n",
    "\n",
    "    # Tracer le graphique sur le sous-graphique correspondant\n",
    "    ax = axs[i]\n",
    "    ax.plot(nbr_part_per_frame.index, nbr_part_per_frame.values)\n",
    "    ax.set_title(f'Nbr particle per Frame - {exp}')\n",
    "    ax.set_xlabel('time (min)')\n",
    "    ax.set_ylabel('Number of particle')\n",
    "    # ax.set_xlim([0, 340])\n",
    "    # ax.set_ylim([0, 2000])  # Ajustez selon vos données\n",
    "\n",
    "# Masquer les axes non utilisés s'il y en a\n",
    "for ax in axs[len(experiments):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "# Ajustement de la mise en page\n",
    "plt.tight_layout()\n",
    "# Ajustement de l'espacement et des marges\n",
    "# plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "# Enregistrer la figure entière\n",
    "plt.savefig(f\"{path_save_pic}Nbr_particle_per_Frame_manip_par_manip.jpg\", format='jpg')\n",
    "\n",
    "# Afficher la figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "path_data = lib.calculate_total_path_first_frames(DATA, first_n_frames=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Grouper les données par 'experiment'\n",
    "grouped = path_data.groupby('experiment')\n",
    "\n",
    "# Calculer le nombre d'experiments pour déterminer le nombre de subplots nécessaires\n",
    "n_experiments = len(grouped)\n",
    "\n",
    "# Créer une figure et des axes pour les subplots\n",
    "fig, axes = plt.subplots(nrows=n_experiments, figsize=(10, 4*n_experiments))\n",
    "\n",
    "# Assurer que 'axes' est un array, même s'il n'y a qu'un seul subplot\n",
    "if n_experiments == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for (experiment, group), ax in zip(grouped, axes):\n",
    "    # Créer un histogramme pour chaque 'experiment'\n",
    "    ax.hist(group['total_path_first_n'], bins=10, range=[0, 100], density=True, alpha=0.5)\n",
    "    ax.set_title(f\"Total path in first 100 frames for {experiment}\")\n",
    "    ax.set_xlabel('Lenght path (um)')\n",
    "    ax.set_ylabel('Density')\n",
    "\n",
    "# Ajuster l'espacement entre les subplots pour éviter le chevauchement\n",
    "plt.tight_layout()\n",
    "\n",
    "# Afficher la figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul du nombre de cellules ayant un déplacement inférieur à une valeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de cellules avec un déplacement total inférieur à 10 sur les 20 premières frames\n",
    "num_cells_low_displacement = path_data[path_data['total_path_first_n'] < 15]['particle'].nunique()\n",
    "\n",
    "print(\"Nombre de cellules dont le déplacement est trop faible : \" , num_cells_low_displacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the indices of rows to drop\n",
    "# to_drop = find_swaps_with_return(DATA)\n",
    "\n",
    "# print(len(to_drop), \" movements to delete there while the run is too much.\")\n",
    "\n",
    "# # # Drop the rows from DATA\n",
    "# DATA = DATA.drop(to_drop)\n",
    "DATA.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul des vitesses instantanées et des trajectoires recentrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA = DATA[DATA['displacement [pix]'] < 5]\n",
    "DATA = lib.center(traj=DATA)\n",
    "\n",
    "print(\"\\n\"*2)\n",
    "print(f\"Le temps de lecture et de préparation des données pour la condition {CONDITION} est : \",\n",
    "      (time.time() - INITIAL_TIME), 'min')\n",
    "print(\"\\n\"*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [Compute the DATAS according to some parameters]\n",
    "if ROLLING_MEAN:\n",
    "    DATA = lib.rolling_mean(datas=DATA, roll=3)\n",
    "if PIXELISATION:\n",
    "    DATA = lib.pixelisation(datas=DATA, size_pix=SIZE_PIX)\n",
    "if TIME_FRAME_STUDY:\n",
    "    DATA, TIME_FRAME = lib.keep_nth_image(traj=DATA, n=N_FRAME, time_frame=TIME_FRAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# %% [Calculation of total and cumulative displacement]\n",
    "# #############################################################################\n",
    "DATA, start_end = lib.length_displacement(traj=DATA, size_pix=SIZE_PIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %% [Recalcul du max displacement]\n",
    "# # ###################Erasing the suspicious displacements #####################\n",
    "# grouped_data = DATA.groupby('particle')\n",
    "# # Obtenir la valeur maximale de 'displacement' pour chaque groupe\n",
    "# max_displacements = SIZE_PIX*grouped_data['displacement [pix]'].max()\n",
    "# # Sélectionner les groupes dont la valeur maximale de 'displacement' est supérieure à 10\n",
    "# selected_particles = max_displacements.loc[max_displacements > 50].index.tolist()\n",
    "# bool_mask = DATA['particle'].isin(selected_particles)\n",
    "# DATA_HIGH_DISP = DATA[bool_mask]\n",
    "# if len(DATA_HIGH_DISP) > 0:\n",
    "#     lib.plot_msd(msd=tp.imsd(traj=DATA_HIGH_DISP, mpp=SIZE_PIX, fps=FPS),\n",
    "#                  fps=FPS, name='MSD with HIGHT DISP (sup at 10)', color_plot=COLOR_SUP,\n",
    "#                  save=True, pathway_saving=path_save_pic, alpha=ALPHA, linewidth=LINEWIDTH)\n",
    "# # Erasing the spurious traectories with too high displacement\n",
    "# DATA = DATA[~bool_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #############################################################################\n",
    "# #############################################################################\n",
    "# We now Consider having all the good particles and all good datas.\n",
    "# #############################################################################\n",
    "# #############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [Plot all the trajectories]\n",
    "fig, axis = plt.subplots(figsize=(10, 10))\n",
    "# Assurer une échelle égale pour les axes\n",
    "axis.set_aspect('equal', 'box')\n",
    "plt.title('Trajectories after suspicious particles')\n",
    "tp.plot_traj(DATA, label=(False))\n",
    "plt.show()\n",
    "fig.savefig(path_save_pic +\n",
    "            'Trajectories after removing suspicious particles.jpg', format='jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire le chemin complet\n",
    "image_path = os.path.join(GENERAL_PATH_PICTURES, CONDITION_simple)\n",
    "image_path = image_path + '_faits'\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trackpy as tp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supposons que DATA est votre DataFrame\n",
    "plot_exp = DATA.groupby('experiment')\n",
    "\n",
    "# Déterminer le nombre de sous-graphiques basé sur le nombre d'expériences\n",
    "num_experiments = len(plot_exp)\n",
    "num_cols = 2  # Par exemple, vous pouvez définir 2 colonnes pour vos sous-graphiques\n",
    "num_rows = (num_experiments + num_cols - 1) // num_cols  # Calculer le nombre de lignes nécessaire\n",
    "\n",
    "# Créer la figure et les axes pour les sous-graphiques\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, num_rows * 10))  # Ajustez la taille selon vos besoins\n",
    "axes = axes.flatten()  # Aplatir le tableau d'axes pour une itération facile\n",
    "\n",
    "for ax, (exp_name, exp_data) in zip(axes, plot_exp):\n",
    "    exp_directories = []\n",
    "    for dirpath, dirnames, filenames in os.walk(image_path):\n",
    "        for dirname in dirnames:\n",
    "            if exp_name in dirname:\n",
    "                full_path = os.path.join(dirpath, dirname)\n",
    "                exp_directories.append(full_path)\n",
    "    if exp_directories:\n",
    "        image_path_directory = f'{exp_directories[0]}/mosaic/mosaic_total_0.tif'\n",
    "        frame = imageio.imread(image_path_directory)\n",
    "        ax.set_aspect('equal', 'box')\n",
    "        ax.set_title(f'Trajectories after suspicious particles for {exp_name}')\n",
    "        tp.plot_traj(exp_data, superimpose=frame, label=False, ax=ax)\n",
    "    else:\n",
    "        print(f\"No directory found for {exp_name}\")\n",
    "        ax.axis('off')\n",
    "# Ajuster la mise en page pour éviter le chevauchement\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(path_save_pic + 'trajectories_on_frame_all_experiment.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_y = DATA.groupby('experiment')['y'].max().div(2048).apply(math.ceil).astype(int)\n",
    "series_x = DATA.groupby('experiment')['x'].max().div(2048).apply(math.ceil).astype(int)\n",
    "# Multiplication élément par élément entre les deux séries\n",
    "result = series_y * series_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [Mean speed]\n",
    "# Grouper les données par 'frame' et calculer la moyenne de 'VitInst [um/min]'\n",
    "mean_VitInst_per_frame = DATA.groupby('time (min)')['VitInst [um/min]'].mean()\n",
    "mean_VitInst_per_frame.index = mean_VitInst_per_frame.index\n",
    "\n",
    "mean_VitInst_per_frame = mean_VitInst_per_frame.rolling(5).mean().dropna()\n",
    "\n",
    "lib.plot_datas(x_values=mean_VitInst_per_frame.index,\n",
    "               y_values=mean_VitInst_per_frame.values,\n",
    "               title='Mean VitInst [um/min] per Frame',\n",
    "               x_label='time (min)', y_label='Mean VitInst [um/min]',\n",
    "               x_lim=[0, max(mean_VitInst_per_frame.index)], y_lim=[0, 10], save=True,\n",
    "               path_save_pic=path_save_pic, img_type=\"jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Supposons que DATA est votre DataFrame\n",
    "experiments = DATA['experiment'].unique()\n",
    "n_experiments = len(experiments)\n",
    "\n",
    "# Créer une figure avec deux colonnes de subplots pour chaque expérience\n",
    "# La première colonne pour la vitesse instantanée moyenne par frame\n",
    "# La deuxième colonne pour l'histogramme de la vitesse moyenne des particules\n",
    "fig, axes = plt.subplots(n_experiments, 2, figsize=(20, 6*n_experiments), sharex='col', sharey='row')\n",
    "\n",
    "# S'assurer que axes est toujours un array 2D pour faciliter l'itération\n",
    "if n_experiments == 1:\n",
    "    axes = np.expand_dims(axes, 0)\n",
    "\n",
    "for i, exp in enumerate(experiments):\n",
    "    # Filtrer les données pour l'expérience courante\n",
    "    data_exp = DATA[DATA['experiment'] == exp]\n",
    "    \n",
    "    # Premier subplot : vitesse instantanée moyenne par frame\n",
    "    mean_VitInst_per_frame_i = data_exp.groupby('time (min)')['VitInst [um/min]'].mean()\n",
    "    mean_VitInst_per_frame_i.index = mean_VitInst_per_frame_i.index\n",
    "    mean_VitInst_per_frame_smoothed_i = mean_VitInst_per_frame_i.rolling(5).mean().dropna()\n",
    "    axes[i, 0].plot(mean_VitInst_per_frame_smoothed_i.index, mean_VitInst_per_frame_smoothed_i.values, label=f'Exp: {exp}')\n",
    "    axes[i, 0].set_title(f'Mean VitInst [um/min] per Frame for {exp}')\n",
    "    axes[i, 0].set_xlabel('time (min)')\n",
    "    axes[i, 0].set_ylabel('Mean VitInst [um/min]')\n",
    "    axes[i, 0].set_xlim([0, max(mean_VitInst_per_frame_i.index)])  # Ajustez selon vos données\n",
    "    axes[i, 0].set_ylim([0, 15])   # Ajustez selon vos données\n",
    "    axes[i, 0].legend()\n",
    "\n",
    "    # Deuxième subplot : histogramme de la vitesse moyenne des particules pour l'expérience\n",
    "    mean_VitInst_per_particle_i = data_exp.groupby('particle')['VitInst [um/min]'].mean()\n",
    "    axes[i, 1].hist(mean_VitInst_per_particle_i, bins=30, alpha=0.5)\n",
    "    axes[i, 1].set_title(f'Particle Mean VitInst [um/min] for {exp}')\n",
    "    axes[i, 1].set_xlabel('Mean VitInst [um/min]')\n",
    "    axes[i, 1].set_ylabel('Count')\n",
    "\n",
    "# Ajuster automatiquement l'espacement entre les subplots pour éviter le chevauchement\n",
    "plt.tight_layout()\n",
    "\n",
    "# Afficher la figure\n",
    "plt.show()\n",
    "\n",
    "# Si vous souhaitez sauvegarder la figure entière\n",
    "# plt.savefig(f\"{path_save_pic}/combined_mean_vitinst_per_experiment.jpg\", format=\"jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Supposons que DATA est un DataFrame Pandas avec vos données\n",
    "experiences_uniques = DATA['experiment'].unique()\n",
    "nombre_experiences = len(experiences_uniques)\n",
    "\n",
    "# Créer une grille de subplots avec un nombre approprié de lignes\n",
    "fig, axs = plt.subplots(nombre_experiences, 1, figsize=(10, 5 * nombre_experiences), sharex=True)\n",
    "\n",
    "# Générer une palette de couleurs\n",
    "palette = plt.cm.get_cmap('tab10', nombre_experiences)  # 'tab10' est une palette de 10 couleurs\n",
    "\n",
    "# Définir les limites de l'axe des x basées sur les données globales\n",
    "x_min = DATA.groupby('particle')['VitInst [um/min]'].mean().min()\n",
    "x_max = DATA.groupby('particle')['VitInst [um/min]'].mean().max()\n",
    "\n",
    "# Assurez-vous que axs est un array, même s'il n'y a qu'un seul subplot\n",
    "if nombre_experiences == 1:\n",
    "    axs = [axs]\n",
    "\n",
    "# Remplir chaque subplot\n",
    "for idx, exp in enumerate(experiences_uniques):\n",
    "    # Calculer la moyenne de la vitesse instantanée pour chaque particule\n",
    "    moyennes_vitesses = DATA[DATA['experiment'] == exp].groupby('particle')['VitInst [um/min]'].mean()\n",
    "    \n",
    "    # Créer un histogramme sur le subplot correspondant avec une couleur unique\n",
    "    axs[idx].hist(moyennes_vitesses, bins=30, alpha=0.3, color=palette(idx))\n",
    "    axs[idx].set_title(f'Expérience: {exp}')\n",
    "    axs[idx].set_xlabel('Vitesse Instantanée (µm/min)')\n",
    "    axs[idx].set_ylabel('Fréquence')\n",
    "    axs[idx].set_xlim([x_min, x_max])  # Appliquer la même échelle des x à tous les subplots\n",
    "\n",
    "# Ajuster l'espace entre les subplots pour éviter le chevauchement\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtenir la liste unique des expériences\n",
    "experiments = DATA['experiment'].unique()\n",
    "n_experiments = len(experiments)\n",
    "\n",
    "# Créer une figure et un ensemble de subplots\n",
    "# Ajustez nrows et ncols selon le nombre d'experiences que vous avez\n",
    "fig, axes = plt.subplots(nrows=n_experiments, ncols=1, figsize=(10, 5*n_experiments))\n",
    "\n",
    "# S'assurer que 'axes' est un array pour faciliter l'itération, même s'il n'y a qu'une seule expérience\n",
    "if n_experiments == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, exp in zip(axes, experiments):\n",
    "    # Sélectionner les données pour l'expérience courante\n",
    "    data_exp = DATA[DATA['experiment'] == exp]\n",
    "    \n",
    "    # Calculer la vitesse instantanée moyenne pour chaque particule\n",
    "    mean_vitinst_per_particle = data_exp.groupby('particle')['VitInst [um/min]'].mean()\n",
    "    \n",
    "    # Tracer l'histogramme sur le subplot correspondant\n",
    "    ax.hist(mean_vitinst_per_particle, bins=30, alpha=0.3)\n",
    "    ax.set_title(f'Vitesse instantanée moyenne [um/min] - {exp}')\n",
    "    ax.set_xlabel('VitInst [um/min]')\n",
    "    ax.set_ylabel('Nombre de particules')\n",
    "\n",
    "# Ajuster l'espacement entre les subplots pour éviter le chevauchement\n",
    "plt.tight_layout()\n",
    "\n",
    "# Afficher la figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculer les limites globales pour la vitesse instantanée moyenne\n",
    "all_mean_vitinst = DATA.groupby(['experiment', 'particle'])['VitInst [um/min]'].mean()\n",
    "global_min, global_max = all_mean_vitinst.min(), all_mean_vitinst.max()\n",
    "\n",
    "# Ajuster légèrement les limites pour une meilleure visualisation\n",
    "global_min, global_max = global_min - (global_max - global_min) * 0.1, global_max + (global_max - global_min) * 0.1\n",
    "\n",
    "# Obtenir la liste unique des expériences\n",
    "experiments = DATA['experiment'].unique()\n",
    "n_experiments = len(experiments)\n",
    "\n",
    "# Créer une figure et un ensemble de subplots\n",
    "fig, axes = plt.subplots(nrows=n_experiments, ncols=1, figsize=(10, 5*n_experiments), sharex=True, sharey=True)\n",
    "\n",
    "# S'assurer que 'axes' est un array pour faciliter l'itération, même s'il n'y a qu'une seule expérience\n",
    "if n_experiments == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, exp in zip(axes, experiments):\n",
    "    # Sélectionner les données pour l'expérience courante\n",
    "    data_exp = DATA[DATA['experiment'] == exp]\n",
    "    \n",
    "    # Calculer la vitesse instantanée moyenne pour chaque particule\n",
    "    mean_vitinst_per_particle = data_exp.groupby('particle')['VitInst [um/min]'].mean()\n",
    "    \n",
    "    # Tracer l'histogramme sur le subplot correspondant\n",
    "    ax.hist(mean_vitinst_per_particle, bins=30, alpha=0.3, range=(global_min, global_max))\n",
    "    ax.set_title(f'Vitesse instantanée moyenne [um/min] - {exp}')\n",
    "    ax.set_xlabel('VitInst [um/min]')\n",
    "    ax.set_ylabel('Nombre de particules')\n",
    "    \n",
    "    # Calculer et tracer la médiane en rouge\n",
    "    median_value = mean_vitinst_per_particle.median()\n",
    "    ax.axvline(median_value, color='red', linestyle='dashed', linewidth=1)\n",
    "    ax.text(median_value, ax.get_ylim()[1]*0.95, f'Median: {median_value:.2f}', color='red', ha='right')\n",
    "\n",
    "    # Appliquer les mêmes limites d'axes à tous les subplots\n",
    "    ax.set_xlim(global_min, global_max)\n",
    "\n",
    "# Ajuster l'espacement entre les subplots pour éviter le chevauchement\n",
    "plt.tight_layout()\n",
    "\n",
    "# Afficher la figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [Number of particle on each frame]\n",
    "\n",
    "# Grouper les données par 'frame' et calculer la moyenne de 'VitInst [um/min]'\n",
    "nbr_part_per_frame = DATA.groupby('time (min)')['particle'].nunique()\n",
    "\n",
    "lib.plot_datas(x_values=nbr_part_per_frame.index, y_values=nbr_part_per_frame.values,\n",
    "               title='Nbr particle per Frame',\n",
    "               x_label='time (min)', y_label='Number of particle',\n",
    "               x_lim=[0, max(nbr_part_per_frame.index)], y_lim=[0, 1000], save=True,\n",
    "               path_save_pic=path_save_pic, img_type=\"jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Supposons que df est votre DataFrame contenant les résultats du tracking\n",
    "# df devrait avoir des colonnes 'particle', 'frame', 'x', et 'y'\n",
    "df = DATA\n",
    "# Fonction pour calculer le vecteur de déplacement\n",
    "def displacement_vectors(df):\n",
    "    df['dx'] = df.groupby('particle')['x'].diff()\n",
    "    df['dy'] = df.groupby('particle')['y'].diff()\n",
    "    return df.dropna()\n",
    "\n",
    "# Normaliser les vecteurs de déplacement\n",
    "def normalize_vectors(df):\n",
    "    df = df.copy()\n",
    "    magnitude = np.sqrt(df['dx']**2 + df['dy']**2)\n",
    "    df.loc[:, 'dx_norm'] = df['dx'] / magnitude\n",
    "    df.loc[:, 'dy_norm'] = df['dy'] / magnitude\n",
    "    return df\n",
    "\n",
    "# Calculer l'angle des vecteurs\n",
    "# Arctan2 permet de calculer l'angle en radians entre la partie positive de l'axe des abscisses d'un plan et le point (x,y)\n",
    "# Angle positif dans le sens trigo et négativ dans le sens inverse trigo\n",
    "def calculate_angles(df):\n",
    "    df = df.copy()\n",
    "    df.loc[:, 'angle'] = np.arctan2(df['dy_norm'], df['dx_norm'])\n",
    "    return df\n",
    "\n",
    "# Calculer l'autocorrélation directionnelle\n",
    "def direction_autocorrelation(df, max_lag):\n",
    "    results = []\n",
    "    for particle in df['particle'].unique():\n",
    "        particle_df = df[df['particle'] == particle].copy()\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            particle_df['angle_lag'] = particle_df['angle'].shift(-lag)\n",
    "            cos_diff = np.cos(particle_df['angle'] - particle_df['angle_lag'])\n",
    "            autocorr = cos_diff.mean()\n",
    "            results.append({'particle': particle, 'lag': lag, 'autocorrelation': autocorr})\n",
    "    return pd.DataFrame(results).dropna()\n",
    "\n",
    "# Appliquer les fonctions\n",
    "df = displacement_vectors(df)\n",
    "df = normalize_vectors(df)\n",
    "df = calculate_angles(df)\n",
    "max_lag = 10  # Ajustez en fonction de la longueur de vos trajectoires\n",
    "autocorr_df = direction_autocorrelation(df, max_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA2 = DATA\n",
    "DATA2['frame'] = pd.factorize(DATA2['frame'])[0]\n",
    "IMSD = tp.imsd(traj=DATA2,\n",
    "               mpp=SIZE_PIX, fps=FPS,\n",
    "               max_lagtime=200, statistic='msd',\n",
    "               pos_columns=None)\n",
    "IMSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.plot_msd(IMSD, fps=FPS, name=\"MSD of all frames in function of lag time (s)\",\n",
    "             color_plot = 'red', save=False, pathway_saving=None,\n",
    "             alpha=0.5, linewidth=0.3, img_type='jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [traj clustering with fit and defining a cutoff]\n",
    "LAG_TIME_FIT = 5\n",
    "# Compute et plot the director factor of the imsd\n",
    "importlib.reload(lib)\n",
    "\n",
    "COEF_INF, COEF_SUP, PART_COEF_INF, PART_COEF_SUP, CUTOFF =\\\n",
    "    lib.traj_clustering_with_fit_cutoff(DATA2, imsd=IMSD, hist=True,\n",
    "                                        lag_time_fit=LAG_TIME_FIT,\n",
    "                                        micronperpixel=SIZE_PIX,\n",
    "                                        fps=FPS, binsize=250,\n",
    "                                        peak_height=50, peak_width=1,\n",
    "                                        save=True, pathway_fig=path_save_pic,\n",
    "                                        name='all the experiment autocorr', img_type=\"jpg\",\n",
    "                                        plot=True, color_sup_inf=color_sup_inf,\n",
    "                                        cutoff_default=0.5\n",
    "                                        )\n",
    "\n",
    "# # DATA_INF, DATA_SUP, IMSD_INF, IMSD_SUP,\n",
    "# DATA_INF = DATA[DATA['particle'].isin(PART_COEF_INF)]\n",
    "# DATA_SUP = DATA[DATA['particle'].isin(PART_COEF_SUP)]\n",
    "# IMSD_INF = IMSD.loc[:, IMSD.columns.isin(PART_COEF_INF)]\n",
    "# IMSD_SUP = IMSD.loc[:, IMSD.columns.isin(PART_COEF_SUP)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for numero_particule in df_negative['particle'].unique():\n",
    "#     print(numero_particule)\n",
    "#     print(\"Etude de la particule : \", numero_particule, ' dans la manip', DATA[DATA['particle']==numero_particule]['experiment'].iloc[0])\n",
    "#     lib.create_cropped_tracking_gif(datas=DATA, target_particle = numero_particule,\n",
    "#                                     condition = CONDITION_simple,\n",
    "#                                     dot_size= 7,\n",
    "#                                     crop_size=100, \n",
    "#                                     gif=False,\n",
    "#                                     pathway_saving=None,\n",
    "                                    # pathway_initial='/Volumes/Labo_Alex_Mac/A_analyser/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assurez-vous que sums_df est un DataFrame Pandas\n",
    "sums_df = pd.DataFrame(columns=['experiment', 'particle', 'displacement_sum'])\n",
    "\n",
    "rows = []\n",
    "\n",
    "for exp in DATA['experiment'].unique():\n",
    "    exp_data = DATA[DATA['experiment'] == exp]\n",
    "    for particle_id, part in exp_data.groupby('particle'):\n",
    "        displacement_sum = part['displacement [pix]'].head(200).sum()\n",
    "        new_row = {'experiment': exp, 'particle': particle_id, 'displacement_sum': displacement_sum}\n",
    "        rows.append(new_row)\n",
    "\n",
    "# Création d'un nouveau DataFrame à partir de la liste de dictionnaires\n",
    "sums_df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sum = []\n",
    "for _, exp in sums_df.groupby('experiment'):\n",
    "    mean_sum.append(exp['displacement_sum'].mean())\n",
    "\n",
    "plt.hist(mean_sum, bins = 100)\n",
    "plt.title(\"Nbr of exp in function of mean displacement per particule\")\n",
    "plt.savefig(path_save_pic + f\"Nbr of exp in function of mean displacement per particule {CONDITION_simple}.png\", format='png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y'a t'il l'air d'enregistrer? \n",
    "# size en fonction ? \n",
    "# faire des manip en x10\n",
    "# calculer un pseudo packing fraction : nombre de cellule par unité d'air. Ensuite, on essaye de voir la size des cells. \n",
    "# Cela dit, c'est vraiment le nombre de cellules par unité d'aire qui m'interesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(lib)\n",
    "lib.plot_displacement(DATA, start_end=start_end, alpha = 0.5, linewidth=0.5, ylim=[0, 750], xlim=[0, max(DATA['time (min)'])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(start_end, bins=250)\n",
    "plt.xlim([0,400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in DATA['experiment'].unique():\n",
    "    # Calculer ymax et xmax pour chaque expérience\n",
    "    ymax = math.ceil(DATA[DATA['experiment'] == exp]['y'].max() / 2048)\n",
    "    xmax = math.ceil(DATA[DATA['experiment'] == exp]['x'].max() / 2048)\n",
    "\n",
    "    # Convertir en int si nécessaire (math.ceil retourne déjà un int)\n",
    "    ymax = int(ymax)\n",
    "    xmax = int(xmax)\n",
    "    # Filtrer le DataFrame pour l'expérience et les 200 premières frames\n",
    "    exp_data = DATA[(DATA['experiment'] == exp) & (DATA['frame'] < 340)]\n",
    "    nbr_particles = exp_data['particle'].nunique()\n",
    " \n",
    "    # # Grouper par 'frame' et compter les particules\n",
    "    # particules_par_frame = exp_data.groupby('frame')['particle'].nunique()\n",
    "\n",
    "    # # Calculer la moyenne du nombre de particules\n",
    "    # moyenne_particules = particules_par_frame.mean()\n",
    "    # nombre_part_par_champs = moyenne_particules/(xmax*ymax)\n",
    "    nombre_part_par_champs = nbr_particles/(xmax*ymax)\n",
    "    print(f\"Nombre de cellules par champs pour la manips {exp}:\", nombre_part_par_champs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "# Liste pour stocker les données de chaque expérience\n",
    "data = []\n",
    "\n",
    "for exp in DATA['experiment'].unique():\n",
    "    # Calculer ymax et xmax\n",
    "    ymax = math.ceil(DATA[DATA['experiment'] == exp]['y'].max() / 2048)\n",
    "    xmax = math.ceil(DATA[DATA['experiment'] == exp]['x'].max() / 2048)\n",
    "    ymax, xmax = int(ymax), int(xmax)\n",
    "\n",
    "    # Filtrer pour l'expérience et les 200 premières frames\n",
    "    exp_data = DATA[(DATA['experiment'] == exp) & (DATA['frame'] < 200)]\n",
    "\n",
    "    # Compter les particules par frame et calculer la moyenne\n",
    "    moyenne_particules = exp_data.groupby('frame')['particle'].nunique().mean()\n",
    "    nombre_part_par_champs = int(moyenne_particules / (xmax * ymax))\n",
    "\n",
    "    # Calculer mean_sum pour l'expérience\n",
    "    mean_sum = int(sums_df[sums_df['experiment'] == exp]['displacement_sum'].mean())\n",
    "\n",
    "    #Calcul de la vitesse moyenne des particules\n",
    "    mean_speed = exp_data.groupby('particle')['VitInst [um/min]'].mean().mean()\n",
    "\n",
    "\n",
    "    # Ajouter les données calculées à la liste\n",
    "    data.append({\n",
    "        'experiment': exp,\n",
    "        'mean_sum': mean_sum,\n",
    "        'taille': xmax * ymax,\n",
    "        'nombre_part_par_champs': nombre_part_par_champs,\n",
    "        'mean_speed [um/min]': mean_speed,\n",
    "    })\n",
    "\n",
    "# Création du DataFrame\n",
    "result_df = pd.DataFrame(data)\n",
    "\n",
    "# # Affichage du DataFrame\n",
    "# print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supposons que result_df est votre DataFrame contenant les données nécessaires\n",
    "\n",
    "# Création d'une grille de sous-graphiques 2x2\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 6))  # Ajustez la taille selon vos besoins\n",
    "\n",
    "# Aplatir le tableau d'axes pour un accès plus facile\n",
    "ax1, ax2, = axes.flatten()\n",
    "\n",
    "# Premier graphique: Mean Sum vs. Nombre de Particules par Champ\n",
    "ax1.scatter(result_df['nombre_part_par_champs'], result_df['mean_sum'], marker='+', color='orange')\n",
    "ax1.set_title('Average distance traveled vs. Number of particles per field')\n",
    "ax1.set_xlabel('Number of particles per field')\n",
    "ax1.set_ylabel('Average distance traveled')\n",
    "\n",
    "# Deuxième graphique: Mean Speed vs. Nombre de Particules par Champ\n",
    "ax2.scatter(result_df['nombre_part_par_champs'], result_df['mean_speed [um/min]'], marker='+', color='blue')\n",
    "ax2.set_title('Mean Speed vs. Number of particles per field')\n",
    "ax2.set_xlabel('Number of particles per field')\n",
    "ax2.set_ylabel('Mean Speed [um/min]')\n",
    "\n",
    "# # Masquer le quatrième axe car il n'est pas utilisé\n",
    "# ax4.axis('off')\n",
    "\n",
    "# Ajustement de la mise en page pour éviter le chevauchement des titres\n",
    "plt.tight_layout()\n",
    "\n",
    "# Afficher les graphiques\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(path_save_pic + f\"graph in function of nbr of particles per field {CONDITION_simple}.png\", format='png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=filtered_DATA[filtered_DATA['particle']==filtered_DATA['particle'].unique()[0]]['experiment'].iloc[0]\n",
    "import glob\n",
    "glob.glob(f'/Users/souchaud/Desktop/A_analyser/CytoOne_HL5_10x_faits/*{path}*')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(lib)\n",
    "# import glob\n",
    "# for i in filtered_DATA['particle'].unique():\n",
    "#     path=filtered_DATA[filtered_DATA['particle']==i]['experiment'].iloc[0]\n",
    "#     path_frames = glob.glob(f'/Users/souchaud/Desktop/A_analyser/CytoOne_HL5_10x/faits/*{path}*')[0]\n",
    "#     print('path frames' , path_frames)\n",
    "#     lib.create_cropped_tracking_gif(datas=filtered_DATA, target_particle=i,\n",
    "#                                     condition=None, crop_size = 200, \n",
    "#                                     dot_size = 15, gif = False,\n",
    "#                                     pathway_saving = '/Users/souchaud/Desktop/gif',\n",
    "#                                     pathway_initial = path_frames + '/mosaic/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les particules dont le coefficient inférieur est inférieur à 0.2\n",
    "particules_filtrées = [part for coef, part in zip(COEF_INF, PART_COEF_INF) if coef < 0.25]\n",
    "# regarder de quelle manip\n",
    "DATA_INF_025 = DATA[DATA['particle'].isin(particules_filtrées)]\n",
    "DATA_INF_025_136 = DATA_INF_025[DATA_INF_025['experiment']=='ASMOT136']\n",
    "fig, axis = plt.subplots(figsize=(10, 10))\n",
    "# Assurer une échelle égale pour les axes\n",
    "axis.set_aspect('equal', 'box')\n",
    "plt.title('Trajectories after suspicious particles')\n",
    "tp.plot_traj(DATA_INF_025_136, label=(False))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pour afficher entièrement le DataFrame\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Affichez par exemple les premières ou dernières N lignes\n",
    "DATA_INF_025_136.head(10)\n",
    "# DATA_INF_025.groupby('experiment')['particle'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_INF_025_136['frame'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lister tous les éléments dans le chemin racine\n",
    "chemin_racine = '/Users/souchaud/Desktop/A_analyser/CytoOne_HL5_10x_faits/'\n",
    "for nom in os.listdir(chemin_racine):\n",
    "    # Construire le chemin complet de l'élément\n",
    "    chemin_complet = os.path.join(chemin_racine, nom)\n",
    "    # Vérifier si c'est un dossier et si \"ASMOT136\" est dans le nom\n",
    "    if os.path.isdir(os.path.join(chemin_racine, nom)) and \"ASMOT136\" in nom:\n",
    "        chemin_final = chemin_complet\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossiers_asmot136 = [nom for nom in os.listdir(chemin_racine)\n",
    "                     if os.path.isdir(os.path.join(chemin_racine, nom)) and \"ASMOT136\" in nom]\n",
    "\n",
    "for dossier in dossiers_asmot136:\n",
    "    print(dossier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.create_cropped_tracking_gif(datas=DATA_INF_025, target_particle = None,\n",
    "                                condition: str = None, crop_size: int = None, \n",
    "                                dot_size: int = 25, gif: bool = False,\n",
    "                                pathway_saving=None,\n",
    "                                pathway_initial=chemin_complet + '/mosaic/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "def create_cropped_tracking_gif(datas, condition=None, dot_size=15, gif=True, pathway_saving=None, pathway_initial=None):\n",
    "    \"\"\"Creates a cropped tracking GIF from particle data.\n",
    "\n",
    "    Args:\n",
    "        datas (pd.DataFrame): DataFrame containing particle data with columns 'frame', 'x', and 'y'.\n",
    "        condition (str, optional): Optional condition to filter files within the initial pathway. Defaults to None.\n",
    "        dot_size (int, optional): Size of the dots representing particles. Defaults to 15.\n",
    "        gif (bool, optional): Whether to create a GIF (True) or individual PNG frames (False). Defaults to True.\n",
    "        pathway_saving (str, optional): Path to save the GIF or PNG frames. Defaults to None (automatic creation).\n",
    "        pathway_initial (str, optional): Path to the directory containing image frames. Defaults to None.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `datas` is not a pandas DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(datas, pd.DataFrame):\n",
    "        raise ValueError(\"Data must be a pandas DataFrame.\")\n",
    "\n",
    "    if pathway_initial is None:\n",
    "        pathway_initial = '/Users/souchaud/Desktop/A_analyser/'\n",
    "    dossier_manip = glob.glob(f'{pathway_initial}{condition}/*') if condition else glob.glob(f'{pathway_initial}*')\n",
    "    if not dossier_manip:\n",
    "        print(\"No such file\")\n",
    "        return\n",
    "    pathway_experiment = dossier_manip[0] + '/mosaic/' if condition else pathway_initial\n",
    "\n",
    "    if pathway_saving is None:\n",
    "        path = '/users/souchaud/Desktop/Analyses/gif_particle_seule/'\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        condition_path = f\"{condition}_\" if condition else \"\"\n",
    "        pathway_saving = os.path.join(path, f'{condition_path}all_particles/')\n",
    "    os.makedirs(pathway_saving, exist_ok=True)\n",
    "\n",
    "    # Clear existing files (can be optimized based on deletion preference)\n",
    "    for filename in os.listdir(pathway_saving):\n",
    "        file_path = os.path.join(pathway_saving, filename)\n",
    "        os.remove(file_path)\n",
    "\n",
    "    frames = []  # List to store image frames for GIF creation\n",
    "\n",
    "    for frame_number in range(datas['frame'].min(), datas['frame'].max() + 1):\n",
    "        image_path = os.path.join(pathway_experiment, f\"mosaic_total_{frame_number}.tif\")\n",
    "        with Image.open(image_path) as img:\n",
    "            # Convert to RGBA for transparency (optional, comment out if not needed)\n",
    "            # img = img.convert(\"RGBA\")\n",
    "\n",
    "            draw = ImageDraw.Draw(img)\n",
    "\n",
    "            frame_data = datas[datas['frame'] == frame_number]\n",
    "\n",
    "            for _, particle in frame_data.iterrows():\n",
    "                red_transparent = (255, 0, 0, 127)  # Rouge semi-transparent\n",
    "                draw.ellipse([(particle['x'] - dot_size / 2, particle['y'] - dot_size / 2),\n",
    "                              (particle['x'] + dot_size / 2, particle['y'] + dot_size / 2)],\n",
    "                              fill=red_transparent)\n",
    "\n",
    "            if gif:\n",
    "                # Efficiently append to frames list for GIF creation\n",
    "                frames.append(img.copy())\n",
    "            else:\n",
    "                output_path = os.path.join(pathway_saving, f\"frame_{frame_number}.png\")\n",
    "                img.save(output_path, format=\"PNG\")  # Adjust quality parameter for smaller PNGs\n",
    "\n",
    "    if gif:\n",
    "        # Create GIF using an appropriate library (e.g., moviepy, PillowGif)\n",
    "        # ... (implementation using your preferred library)\n",
    "        # Example using moviepy (install with `pip install moviepy`):\n",
    "        from moviepy.editor import ImageSequenceClip\n",
    "        clip = ImageSequenceClip(frames, fps=10)  # Adjust fps as needed\n",
    "        clip.write_gif(os.path.join(pathway_saving, \"tracking.gif\"), quantizer=8)  # Lower quantizer for smaller GIFs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "def create_cropped_tracking_gif(datas, condition=None, dot_size=15, gif=False, pathway_saving=None, pathway_initial=None):\n",
    "    if not isinstance(datas, pd.DataFrame):\n",
    "        raise ValueError(\"Data must be a pandas DataFrame.\")\n",
    "\n",
    "    if pathway_initial is None:\n",
    "        pathway_initial = '/Users/souchaud/Desktop/A_analyser/'\n",
    "    dossier_manip = glob.glob(f'{pathway_initial}{condition}/*') if condition else glob.glob(f'{pathway_initial}*')\n",
    "    if not dossier_manip:\n",
    "        print(\"No such file\")\n",
    "        return\n",
    "    pathway_experiment = dossier_manip[0] + '/mosaic/' if condition else pathway_initial\n",
    "\n",
    "    if pathway_saving is None:\n",
    "        path = '/users/souchaud/Desktop/Analyses/gif_particle_seule/'\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        condition_path = f\"{condition}_\" if condition else \"\"\n",
    "        pathway_saving = os.path.join(path, f'{condition_path}all_particles/')\n",
    "    os.makedirs(pathway_saving, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(pathway_saving):\n",
    "        file_path = os.path.join(pathway_saving, filename)\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "\n",
    "    # Tracer toutes les particules pour chaque frame\n",
    "    for frame_number in range(datas['frame'].min(), datas['frame'].max() + 1):\n",
    "        image_path = os.path.join(pathway_experiment, f\"mosaic_total_{frame_number}.tif\")\n",
    "        with Image.open(image_path) as img:\n",
    "            # Convertir en RGBA pour supporter la transparence\n",
    "            img = img.convert(\"RGBA\")\n",
    "            draw = ImageDraw.Draw(img)\n",
    "\n",
    "            frame_data = datas[datas['frame'] == frame_number]\n",
    "            for _, particle in frame_data.iterrows():\n",
    "                red_transparent = (255, 0, 0, 100)  # Rouge semi-transparent\n",
    "                draw.ellipse([(particle['x'] - dot_size / 2, particle['y'] - dot_size / 2),\n",
    "                              (particle['x'] + dot_size / 2, particle['y'] + dot_size / 2)],\n",
    "                              fill=red_transparent)\n",
    "\n",
    "            output_path = os.path.join(pathway_saving, f\"frame_{frame_number}.png\")\n",
    "            img.save(output_path, format=\"PNG\")\n",
    "\n",
    "    # Si gif est demandé, cette partie nécessite une adaptation pour gérer tous les frames sans se focaliser sur une particule spécifique\n",
    "    # Il faut collecter tous les images sauvegardées et les assembler en un GIF\n",
    "    # Cela peut être implémenté en fonction de vos besoins spécifiques\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# Assurez-vous que DATA_INF_025 est défini et que le chemin_initial pointe vers le dossier correct\n",
    "create_cropped_tracking_gif(datas=DATA_INF_025, condition=None, dot_size=25,\n",
    "                            gif=False, pathway_saving='/Users/souchaud/Desktop/A_analyser/test2/',\n",
    "                            pathway_initial=chemin_final + '/mosaic/')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
