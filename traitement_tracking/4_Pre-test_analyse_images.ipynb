{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"fr\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Extraction de Trajectoires</title>\n",
    "    <style>\n",
    "        h1 {\n",
    "            color: skyblue;\n",
    "            font-size: 30px;\n",
    "            font-weight: bold; /* Notez que c'est 'font-weight' et non 'font-style' pour le gras */\n",
    "        }\n",
    "        .red-text {\n",
    "            color: red;\n",
    "        }\n",
    "        .green-text {\n",
    "            color: DarkSeaGreen;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Pre-test analyse des images</h1>\n",
    "    <p>L'objectif de ce programme est simplement d'analyser la première image pour tester si les paramètres de traitement sont efficaces. Pour cela, on peut vérifier les tracés de particules repérés et des graphiques de mass et taille. Ces paramètres sont à copier par la suite dans le code de tracking.</p>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from skimage import util\n",
    "import trackpy as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><span style=\"color: skyblue; font-size: 30px; font-style: bold\">Définition des paramètres d'études </span></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidated parameters\n",
    "PARAMS = {\n",
    "        # Préparation images\n",
    "        'GaussianBlur': (5, 5), # (19, 19), #  (5, 5),\n",
    "        'sigmaX': 10,\n",
    "        'sigmaY': 10, \n",
    "        'threshold': 1, # 3, # 10  # 40,\n",
    "        'percentile': 10, #10,\n",
    "        'lenght_study': 50, # Découpage de la manip en nombre de frale pour favoriser l'étude (performence ordi)\n",
    "        'smoothing_size': None,\n",
    "        'invert': False,\n",
    "        'preprocess': True, \n",
    "        'characterize': True,\n",
    "        'filter_before': None,\n",
    "        'filter_after': None,\n",
    "        # Paramètres Manip\n",
    "        'pixel_size': 0.637,  # 1.2773, # en um\n",
    "        'frame_interval': 15, # temps entre chaque frame [s]\n",
    "        'long_time': False,\n",
    "        'max_frame': 340, # 340, #340 # Nombre de frame d'étude max.\n",
    "        'min_frames': 150, #150, # Nombre de frame sur laquelle doit être suivie une cellule\n",
    "        'topn': 500, # None, # Nombre de particules max à détecter\n",
    "\n",
    "        # Détéction particules\n",
    "        'diameter': 15,  # 15, # Diamètres évalué des particules\n",
    "        'max_displacement': 30, # 35, # 25, # Déplacement maximal des cellules entre deux images (en pixel)\n",
    "        'search_range': 30, #  30, #  20 # même chose\n",
    "        'minmass': 500, #  Mass minimale mesurée des cellules\n",
    "        'max_size': 30, # 25, # Taille maximum de la particule\n",
    "        'separation': 20, # 9, # distance mimimanl pour séparé deux objets\n",
    "        'noise_size': 3,  # 7, # 7, # taille des particules à exclure \n",
    "        'max_iterations': 15, # Nombre d'itérations max pour résoudre un sous-réseau (déterminer les trajectoires entre 2 cellules)\n",
    "        'memory': 5, # Nombre de frame au dela de laquelle on oublie la cellule\n",
    "        'engine': 'auto',\n",
    "\n",
    "        # Format et chemins\n",
    "        'remove_exts': ['.jpg', '.svg', 'hdf5', '.png'],   \n",
    "        'data_dir': '/Users/souchaud/Desktop/A_Analyser/CytoOne_SorC_10x/',\n",
    "        # 'data_dir': '/Volumes/Labo_Alex_Mac/A_analyser/CytoOne_HL5/',\n",
    "        # 'data_dir': '/Users/souchaud/Desktop/A_Analyser/NonT_SorC/',\n",
    "        # 'output_dir': '/Users/souchaud/Desktop/Analyses/CytoOne_HL5_longtime/'\n",
    "        # 'data_dir': '/Volumes/Labo_Alex_Mac/A_analyser/CytoOne_HL5/',´\n",
    "        'output_dir': '/Users/souchaud/Desktop/Analyses/CytoOne_SorC_10x_results_tracking/'\n",
    "        # 'output_dir': '/Users/souchaud/Desktop/Analyses/NonT_SorC_longtime_New/'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Charger l'image\n",
    "# manip = '2024_03_26_ASMOT141_AX3_2024_P1_10x_CytoOne_HL5_2603-10h25-2603-14h30'\n",
    "# manip = '2024_03_26_ASMOT140_AX3_2024_P1_10x_CytoOne_HL5_2603-10h25-2603-10h45'\n",
    "# manip = '2024_03_26_ASMOT142_AX3_2024_P1_10x_CytoOne_HL5_2603-10h25-2703-09h35'\n",
    "# manip = '2024_03_26_ASMOT143_AX3_2024_P1_10x_CytoOne_HL5_2603-17h00-2703-12h00'\n",
    "# manip = '2024_03_26_ASMOT145_AX3_2024_P1_10x_CytoOne_HL5_2603-17h00-2703-17h25'\n",
    "# manip = '2024_03_28_ASMOT147_AX3_2024_P1_10x_CytoOne_HL5_2603-17h00-2803-13h55'\n",
    "# manip = '2024_04_30_ASMOT154_AX3_2024_P4_10x_CytoOne_HL5_2604-10h30_3004_09h15'\n",
    "manip = '2024_10_14_ASMOT185_AX3_2024_P3_10x_CytoOne_SorC_1410-10h30_1410_11h20'\n",
    "# image = cv2.imread('/Users/souchaud/Desktop/A_analyser/CytoOne_HL5_10x/2024_03_06_ASMOT133_AX3_MAT_P3_10x_CytoOne_HL5_0403-15h-0603-09h10/mosaic/mosaic_total_0.tif', cv2.IMREAD_GRAYSCALE)\n",
    "tiff_file = f'/Users/souchaud/Desktop/A_analyser/CytoOne_SorC_10x/{manip}/mosaic/mosaic_total_0.tif'\n",
    "import imageio\n",
    "image = np.array(imageio.imread(tiff_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement\n",
    "blurred = ndimage.median_filter(image, size=8)\n",
    "blurred = cv2.GaussianBlur(blurred, PARAMS['GaussianBlur'], 0)\n",
    "frame = blurred\n",
    "# equalized = cv2.equalizeHist(blurred)\n",
    "# frame = util.invert(blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a CLAHE object (Arguments are optional)\n",
    "# clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(10, 10))\n",
    "# # Apply CLAHE\n",
    "# frame = clahe.apply(frame)\n",
    "for percentile in [5]: \n",
    "    f = tp.locate(frame,\n",
    "                diameter=PARAMS['diameter'],\n",
    "                minmass=PARAMS['minmass'],\n",
    "                maxsize=PARAMS['max_size'],\n",
    "                separation=PARAMS['separation'],\n",
    "                noise_size=PARAMS['noise_size'],\n",
    "                smoothing_size=PARAMS['smoothing_size'],\n",
    "                threshold=PARAMS['threshold'], # 20,\n",
    "                invert=PARAMS['invert'],\n",
    "                percentile=PARAMS['percentile'],\n",
    "                topn=PARAMS['topn'],\n",
    "                preprocess=PARAMS['preprocess'],\n",
    "                max_iterations=PARAMS['max_iterations'],\n",
    "                filter_before=PARAMS['filter_before'],\n",
    "                filter_after=PARAMS['filter_after'],\n",
    "                characterize=PARAMS['characterize'],\n",
    "                engine=PARAMS['engine'])\n",
    "    print(len(f))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    tp.annotate(f, frame, ax=ax)\n",
    "    # display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.mass_size(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import ndimage\n",
    "\n",
    "# def get_top_x_percent_luminous_pixels(image_path, percentile):\n",
    "#     # Charger l'image en grayscale\n",
    "#     image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "#     ndimage.median_filter(image, size=5)\n",
    "\n",
    "#     # Calculer le seuil correspondant au percentile donné\n",
    "#     # np.percentile retourne la valeur sous laquelle un certain pourcentage des valeurs tombe\n",
    "#     threshold = np.percentile(blurred, 100 - percentile)\n",
    "    \n",
    "#     # Créer un masque binaire : 1 pour les pixels >= seuil, 0 sinon\n",
    "#     mask = image >= threshold\n",
    "    \n",
    "#     # Appliquer le masque sur l'image : conserver les pixels originaux où le masque est vrai\n",
    "#     result = np.zeros_like(image)\n",
    "#     result[mask] = image[mask]\n",
    "\n",
    "    \n",
    "#     return result\n",
    "\n",
    "# # Usage\n",
    "# image_path='/Users/souchaud/Desktop/A_analyser/CytoOne_HL5_10x/2024_01_31_ASMOT120_AX3_Chi1_P3_10x_CytoOne_HL5/mosaic/mosaic_total_0.tif'\n",
    "\n",
    "# percentile = 0.05  # Exemple : récupérer les 5% les plus lumineux\n",
    "# result_image = get_top_x_percent_luminous_pixels(image_path, percentile)\n",
    "\n",
    "# # Afficher ou sauvegarder le résultat\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(result_image, cmap='gray')  # cmap='gray' assure que l'image BGR est convertie correctement en nuances de gris pour l'affichage\n",
    "# plt.axis('off')  # Désactiver les axes pour une meilleure visibilité\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Segmentation\n",
    "# _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# # Nettoyage\n",
    "# kernel = np.ones((2,2), np.uint8)  # Plus petit noyau pour opérations morphologiques\n",
    "# opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# # Détection des contours\n",
    "# contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# # Création d'une copie de l'image pour dessiner les contours\n",
    "# image_contours = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)  # Convertir en BGR pour dessiner des contours en couleur\n",
    "\n",
    "# # Filtrage et analyse (exemple)\n",
    "# for contour in contours:\n",
    "#     area = cv2.contourArea(contour)\n",
    "#     if 20 < area < 200:  # Ajustez ces valeurs selon la taille des objets que vous souhaitez conserver\n",
    "#         cv2.drawContours(binary, [contour], -1, (0, 255, 0), 2)\n",
    "\n",
    "# # Utiliser matplotlib pour afficher l'image\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(binary, cmap='gray')  # cmap='gray' assure que l'image BGR est convertie correctement en nuances de gris pour l'affichage\n",
    "# plt.axis('off')  # Désactiver les axes pour une meilleure visibilité\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tracking_and_analyse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
