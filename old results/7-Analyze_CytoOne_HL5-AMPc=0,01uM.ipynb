{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"fr\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Analyse de Trajectoires de Tracking</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "        }\n",
    "        h1 {\n",
    "            color: skyblue;\n",
    "            font-size: 24px;\n",
    "        }\n",
    "        p, li {\n",
    "            font-size: 16px;\n",
    "        }\n",
    "        .green-text{\n",
    "            color: DarkSeaGreen;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Analyse de Trajectoires de Tracking</h1>\n",
    "    <p>Ce code d'analyse permet de traiter les données issues du tracking pour extraire et étudier statistiquement les trajectoires pertinentes. Le processus est structuré comme suit :</p>\n",
    "    <ol>\n",
    "        <li><strong class=\"green-text\">Récupération des trajectoires :</strong> Collecte de toutes les trajectoires issues des différentes manipulations.</li>\n",
    "        <li><strong class=\"green-text\">Pré-analyse :</strong> Examen initial des trajectoires pour déterminer celles à conserver pour l'analyse approfondie.</li>\n",
    "        <li><strong class=\"green-text\">Analyse statistique :</strong> Application de méthodes statistiques aux trajectoires conservées. Les données peuvent être séparées en deux populations pour un traitement spécifique si nécessaire.</li>\n",
    "    </ol>\n",
    "    <p>L'analyse se concentre sur les paramètres suivants :</p>\n",
    "    <ul>\n",
    "        <li>Angle entre les directions successives d'une particule entre chaque intervalle de temps.</li>\n",
    "        <li>Vitesses moyennes et instantanées des particules.</li>\n",
    "        <li>Variation de la vitesse en fonction du temps d'incubation.</li>\n",
    "        <li>Effet potentiel de la densité de cellules sur la motilité.</li>\n",
    "    </ul>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<center><span style=\"color: seagreen; font-size: 50px; font-style: bold\">Chargement et préparation des données.</span></center>\n",
    "<span style=\"color: skyblue; font-size: 20px; font-style: bold\">Chargement des librairies.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Mar  1 12:46:56 2023.\n",
    "\n",
    "@author: souchaud\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import colormaps\n",
    "from cycler import cycler\n",
    "import trackpy as tp\n",
    "import functions_analyze as lib\n",
    "import warnings\n",
    "import importlib\n",
    "from colorama import init\n",
    "from typing import List, Optional, Union, Any, Dict, Tuple\n",
    "from scipy.stats import linregress\n",
    "from scipy.optimize import curve_fit\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Reload custom library\n",
    "importlib.reload(lib)\n",
    "\n",
    "# Initialize colorama\n",
    "init(autoreset=True)\n",
    "\n",
    "# Suppress specific warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Set default matplotlib style\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: skyblue; font-size: 20px; font-style: bold\">Paramètres de graphs.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    # Figure\n",
    "    \"figure.figsize\": (7, 5),  # Taille classique pour une figure d'article\n",
    "    \"figure.dpi\": 300,\n",
    "    \"figure.facecolor\": \"white\",\n",
    "    \"figure.edgecolor\": \"white\",\n",
    "    \"figure.titlesize\": 14,\n",
    "    \"figure.titleweight\": \"bold\",\n",
    "\n",
    "    # Axes\n",
    "    \"axes.facecolor\": \"white\",\n",
    "    \"axes.edgecolor\": \"black\",\n",
    "    \"axes.linewidth\": 1,\n",
    "    \"axes.titlesize\": 12,\n",
    "    \"axes.titleweight\": \"bold\",\n",
    "    \"axes.labelsize\": 11,\n",
    "    \"axes.labelweight\": \"normal\",\n",
    "    \"axes.labelcolor\": \"black\",\n",
    "    \"axes.prop_cycle\": cycler(color=[\n",
    "        \"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\"\n",
    "    ]),\n",
    "    \"axes.grid\": False,\n",
    "\n",
    "    # Ticks\n",
    "    \"xtick.color\": \"black\",\n",
    "    \"ytick.color\": \"black\",\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,\n",
    "    \"xtick.direction\": \"out\",\n",
    "    \"ytick.direction\": \"out\",\n",
    "    \"xtick.major.size\": 5,\n",
    "    \"ytick.major.size\": 5,\n",
    "    \"xtick.major.width\": 1,\n",
    "    \"ytick.major.width\": 1,\n",
    "\n",
    "    # Lignes\n",
    "    \"lines.linewidth\": 1.5,\n",
    "    \"lines.markersize\": 6,\n",
    "\n",
    "    # Police\n",
    "    \"font.size\": 11,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Arial\", \"Helvetica\", \"DejaVu Sans\"],\n",
    "    \"text.color\": \"black\",\n",
    "\n",
    "    # Légendes\n",
    "    \"legend.loc\": \"best\",\n",
    "    \"legend.fontsize\": 10,\n",
    "    \"legend.frameon\": False,\n",
    "\n",
    "    # Sauvegarde\n",
    "    \"savefig.dpi\": 600,\n",
    "    \"savefig.format\": \"png\",\n",
    "    \"savefig.facecolor\": \"white\",\n",
    "    \"savefig.edgecolor\": \"white\",\n",
    "    \"savefig.transparent\": False,\n",
    "\n",
    "    # Images\n",
    "    \"image.cmap\": \"viridis\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<span style=\"color: skyblue; font-size: 20px; font-style: bold\">Initialisation des variables et constantes de travail..</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial time\n",
    "INITIAL_TIME = time.time()\n",
    "\n",
    "# Experiment parameters\n",
    "TIME_FRAME = 15\n",
    "SIZE_PIX = 0.637\n",
    "FPS = 1 / TIME_FRAME\n",
    "\n",
    "# File to study\n",
    "file_name = 'filtered_final'\n",
    "N_FRAME_MIN_STUDY = 200\n",
    "\n",
    "# Study parameters\n",
    "ROLLING_MEAN = False\n",
    "PIXELISATION = False\n",
    "TIME_FRAME_STUDY = False\n",
    "DRIFT = False\n",
    "\n",
    "# Plot parameters\n",
    "IMG_TYPE = 'png'\n",
    "ALPHA = 0.5\n",
    "LINEWIDTH = 0.1\n",
    "COLOR_SUP = 'blue'\n",
    "COLOR_INF = 'red'\n",
    "color_sup_inf = (COLOR_SUP, COLOR_INF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<span style=\"color: skyblue; font-size: 20px; font-style: bold\">Définition des path et dossiers de travails / enregistrements.</span>\n",
    "\n",
    "<span style=\"color: skyblue; font-size: 20px; font-style: bold\">Conditions des manips étudiées.</span>\n",
    "\n",
    "<span style=\"color: skyblue; font-size: 20px; font-style: bold\">Défintions et créations des différents dossiers d'enregistrements.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General paths\n",
    "GENERAL_PATH = '/Users/souchaud/Desktop/Analyses/'\n",
    "GENERAL_PATH_PICTURES = '/Users/souchaud/Desktop/A_analyser/'\n",
    "\n",
    "# Condition\n",
    "CONDITION_simple = 'CytoOne_HL5_AMPC_100pourcent_10x'\n",
    "CONDITION = f'{CONDITION_simple}_results_tracking'\n",
    "\n",
    "# Get list of experiments\n",
    "PATHWAY_EXPERIMENT = [f for f in os.listdir(GENERAL_PATH + CONDITION)\n",
    "                      if os.path.isdir(os.path.join(GENERAL_PATH + CONDITION, f))]\n",
    "\n",
    "# Update experiment paths\n",
    "PATHWAY_EXPERIMENT = [os.path.join(GENERAL_PATH, CONDITION, elem, 'mosaic')\n",
    "                      for elem in PATHWAY_EXPERIMENT]\n",
    "\n",
    "# Path to save pictures\n",
    "path_save_pic = os.path.join(GENERAL_PATH, f'résultats_{CONDITION}_All')\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(path_save_pic, exist_ok=True)\n",
    "os.chdir(path_save_pic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: skyblue; font-size: 20px; font-style: bold\">Ajout des temps d'incubation.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add incubation times to DATA\n",
    "conditions_to_values = {\n",
    "    'ASMOT263': 21.33, 'ASMOT264': 24.33, 'ASMOT265': 43.33, 'ASMOT266': 45.33, 'ASMOT267': 48.33, 'ASMOT268': 1.33, 'ASMOT_bis_268': 2.67,\n",
    "    'ASMOT269': 4.67, 'ASMOT270': 49, 'ASMOT271': 52.50, 'ASMOT272': 73, 'ASMOT273': 76.50,\n",
    "    \n",
    "}\n",
    "\n",
    "experiment_to_dell= {\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "##\n",
    "<center><span style=\"color: Crimson; font-size: 30px; font-style: bold\">Lecture des données expériementales.</span></center>\n",
    "\n",
    "<span style=\"color: skyblue; font-size: 20px\">On décide de travailler que sur un certain nombre de frame. Ici je décide de travailler sur les 340 première frames pour normaliser les expériences. \n",
    "Donc la cellules doit être suivi sur N_MIN_STUDY sur les 340 premières frames. </span>\n",
    "\n",
    "<span style=\"color: skyblue; font-size: 20px\">Application de fonctions pour moyenne flissante et pixelisation et étude d'une frame sur x </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read HDF5 data\n",
    "importlib.reload(lib)\n",
    "DATA = lib.read_hdf5_all(\n",
    "    pathway_experiment=PATHWAY_EXPERIMENT,\n",
    "    name_file=file_name,\n",
    "    nbr_frame_min=N_FRAME_MIN_STUDY,\n",
    "    condition=CONDITION,\n",
    "    drift=DRIFT,\n",
    "    search_range=20,\n",
    "    memory=5\n",
    ")\n",
    "# Vérifier si le dictionnaire `experiment_to_dell` n'est pas vide\n",
    "if experiment_to_dell:\n",
    "    print(f\"Suppression des expériences : {experiment_to_dell}\")\n",
    "    \n",
    "    # Supprimer les expériences spécifiées\n",
    "    DATA = DATA[~DATA['experiment'].isin(experiment_to_dell)]\n",
    "    DATA.reset_index(drop=True, inplace=True)\n",
    "    print(f\"Nombre d'expériences restantes après suppression des expériences ratées: {DATA['experiment'].nunique()}\")\n",
    "else:\n",
    "    print(\"Aucune expérience à supprimer, `experiment_to_dell` est vide.\")\n",
    "\n",
    "# Sort DATA by 'frame'\n",
    "DATA.sort_values(by='frame', inplace=True)\n",
    "\n",
    "# Filter DATA\n",
    "print(\"Nombre de particules avant tri: \", DATA['particle'].nunique())\n",
    "DATA = DATA[DATA['frame'] < 340]\n",
    "\n",
    "# Keep particles with sufficient frames\n",
    "DATA = DATA.groupby('particle').filter(lambda x: len(x) >= N_FRAME_MIN_STUDY)\n",
    "print(\"Nombre de particules après tri: \", DATA['particle'].nunique())\n",
    "\n",
    "# Apply optional data transformations\n",
    "if ROLLING_MEAN:\n",
    "    DATA = lib.rolling_mean(datas=DATA, roll=3)\n",
    "if PIXELISATION:\n",
    "    DATA = lib.pixelisation(datas=DATA, size_pix=SIZE_PIX)\n",
    "if TIME_FRAME_STUDY:\n",
    "    DATA, TIME_FRAME = lib.keep_nth_image(traj=DATA, n=N_FRAME_MIN_STUDY, time_frame=TIME_FRAME)\n",
    "\n",
    "# Calculate instant velocities\n",
    "DATA['time (min)'] = DATA['frame'] * TIME_FRAME / 60\n",
    "DATA = lib.vit_instant_new(traj=DATA, lag_time=TIME_FRAME, pix_size=SIZE_PIX, triage=1)\n",
    "\n",
    "DATA['time to incubation (hours)'] = DATA['experiment'].map(conditions_to_values).fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<center><span style=\"color: skyblue; font-size: 20px\"> Mean Mass and size plot </span></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Mean Mass and Size per Manipulation\n",
    "def plot_mean_mass_size(DATA, path_save_pic, IMG_TYPE):\n",
    "    manips = DATA['experiment'].unique()\n",
    "    num_manips = len(manips)\n",
    "    fig = plt.figure(figsize=(16, 6 * num_manips))\n",
    "    gs = gridspec.GridSpec(num_manips, 3, fig)\n",
    "    colors = ['skyblue', 'lightgreen', 'salmon']\n",
    "    for i, manip in enumerate(manips):\n",
    "        data_manip = DATA[DATA['experiment'] == manip]\n",
    "        mass_means = data_manip.groupby('particle')['mass'].mean()\n",
    "        size_means = data_manip.groupby('particle')['size'].mean()\n",
    "        filtered_data = data_manip[data_manip['frame'] == 0]\n",
    "\n",
    "        ax1 = fig.add_subplot(gs[i, 0])\n",
    "        ax1.hist(mass_means, bins=100, color=colors[0], density=True)\n",
    "        ax1.set_title(f\"Mean mass of particles for {manip}\")\n",
    "        ax1.set_xlabel(\"Mean mass\")\n",
    "        ax1.set_ylabel(\"Density\")\n",
    "\n",
    "        ax2 = fig.add_subplot(gs[i, 1])\n",
    "        ax2.hist(size_means, bins=100, color=colors[1], density=True)\n",
    "        ax2.set_title(f\"Mean size of particles for {manip}\")\n",
    "        ax2.set_xlabel(\"Mean size\")\n",
    "        ax2.set_ylabel(\"Density\")\n",
    "\n",
    "        ax3 = fig.add_subplot(gs[i, 2])\n",
    "        ax3.scatter(filtered_data['size'], filtered_data['mass'], c=\"#d62728\", edgecolors=\"#d62728\", alpha=0.7)\n",
    "        ax3.set_title(f\"Mass vs. Size at frame 0 for {manip}\")\n",
    "        ax3.set_xlabel(\"Size\")\n",
    "        ax3.set_ylabel(\"Mass\")\n",
    "        ax3.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(os.path.join(path_save_pic, f\"Mean_Mass_Size_manip.{IMG_TYPE}\"), format=IMG_TYPE)\n",
    "\n",
    "plot_mean_mass_size(DATA, path_save_pic, IMG_TYPE='svg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<center><span style=\"color: skyblue; font-size: 20px\"> plot total path for each partciel in each experiment (histograms) </span></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total path for the first N frames\n",
    "path_data = lib.calculate_total_path_first_frames(DATA, first_n_frames=100)\n",
    "\n",
    "# Plot Total Path in First 100 Frames per Experiment\n",
    "def plot_total_path(path_data):\n",
    "    grouped = path_data.groupby('experiment')\n",
    "    n_experiments = len(grouped)\n",
    "    fig, axes = plt.subplots(nrows=n_experiments, figsize=(10, 4 * n_experiments))\n",
    "    axes = axes if n_experiments > 1 else [axes]\n",
    "    for (experiment, group), ax in zip(grouped, axes):\n",
    "        ax.hist(group['total_path_first_n'], bins=50, range=[0, 100], density=True, alpha=0.5)\n",
    "        ax.set_title(f\"Total path in first 100 frames for {experiment}\")\n",
    "        ax.set_xlabel('Length path (μm)')\n",
    "        ax.set_ylabel('Density')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_save_pic, f\"Total path in first 100 frames.{IMG_TYPE}\"), format=IMG_TYPE)\n",
    "    plt.show()\n",
    "\n",
    "plot_total_path(path_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<center><span style=\"color: skyblue; font-size: 20px\"> Creation des traj centrées / distance cumulée / IMSD </span></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center trajectories\n",
    "DATA.reset_index(inplace=True)\n",
    "DATA = lib.center(traj=DATA)\n",
    "\n",
    "print(f\"\\n\\nTemps de préparation des données pour {CONDITION}: {time.time() - INITIAL_TIME} sec\\n\\n\")\n",
    "\n",
    "# Calculate total and cumulative displacement\n",
    "DATA, start_end = lib.length_displacement(traj=DATA, size_pix=SIZE_PIX)\n",
    "\n",
    "# Compute MSD and cutoff\n",
    "DATA2 = DATA.copy()\n",
    "DATA2['frame'] = pd.factorize(DATA2['frame'])[0]\n",
    "IMSD = tp.imsd(traj=DATA2, mpp=SIZE_PIX, fps=FPS, max_lagtime=200, statistic='msd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<center><span style=\"color: skyblue; font-size: 20px\"> Premier fit pour exclure certaines traj </span></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trajectory clustering with fit and defining a cutoff\n",
    "LAG_TIME_FIT = 5\n",
    "importlib.reload(lib)\n",
    "COEF_INF, COEF_SUP, PART_COEF_INF, PART_COEF_SUP, CUTOFF = lib.traj_clustering_with_fit_cutoff(\n",
    "    DATA2, imsd=IMSD, hist=True, lag_time_fit=LAG_TIME_FIT, micronperpixel=SIZE_PIX,\n",
    "    fps=FPS, binsize=250, peak_height=50, peak_width=1, save=True, pathway_fig=path_save_pic,\n",
    "    name='all_experiment_autocorr', img_type=IMG_TYPE, plot=True, color_sup_inf=color_sup_inf,\n",
    "    cutoff_default=0\n",
    ")\n",
    "\n",
    "# Keep only particles above cutoff\n",
    "DATA = DATA[DATA['particle'].isin(PART_COEF_SUP)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<center><span style=\"color: skyblue; font-size: 20px\"> Nombre de particules par frame pour les expériences. </span></center>\n",
    "\n",
    "ça n'a pas un grand interêt ici, mais c'est par principe pour vérification et compréhension d'éventuels phenomènes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Number of Particles per Frame for All Experiments in One Graph\n",
    "def plot_nbr_particles_per_frame_combined(DATA, path_save_pic, IMG_TYPE):\n",
    "    \"\"\"\n",
    "    Plot the number of unique particles per frame for all experiments on a single graph with different colors.\n",
    "\n",
    "    Parameters:\n",
    "    - DATA (DataFrame): The input data containing tracking information.\n",
    "    - path_save_pic (str): The path where the plot will be saved.\n",
    "    - IMG_TYPE (str): The format for saving the plot (e.g., 'png', 'jpg').\n",
    "    \"\"\"\n",
    "    experiments = DATA['experiment'].unique()\n",
    "\n",
    "    # Generate a colormap with enough unique colors for all experiments\n",
    "    colormap = plt.colormaps['tab20']  # Use the modern colormap API\n",
    "    colors = [colormap(i / len(experiments)) for i in range(len(experiments))]\n",
    "\n",
    "    plt.figure(figsize=(12, 13))\n",
    "    for i, exp in enumerate(experiments):\n",
    "        # Group data by time and calculate the number of unique particles per frame\n",
    "        nbr_part_per_frame = DATA[DATA['experiment'] == exp].groupby('time (min)')['particle'].nunique()\n",
    "        plt.plot(\n",
    "            nbr_part_per_frame.index, nbr_part_per_frame.values, \n",
    "            label=exp, color=colors[i], alpha=1, linewidth=0.8\n",
    "        )\n",
    "\n",
    "    # Add labels, legend, and title\n",
    "    plt.title('Number of Particles per Frame for All Experiments', fontsize=14)\n",
    "    plt.xlabel('Time (min)', fontsize=12)\n",
    "    plt.ylabel('Number of Particles', fontsize=12)\n",
    "    plt.legend(title=\"Experiments\", bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and show the plot\n",
    "    fig_path = os.path.join(path_save_pic, f\"Nbr_particle_per_Frame_combined.{IMG_TYPE}\")\n",
    "    plt.savefig(fig_path, format=IMG_TYPE, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Plot saved to {fig_path}\")\n",
    "\n",
    "# Appel de la fonction\n",
    "plot_nbr_particles_per_frame_combined(DATA, path_save_pic, IMG_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot Number of Particles per Frame per Experiment\n",
    "# def plot_nbr_particles_per_frame(DATA, path_save_pic, IMG_TYPE):\n",
    "#     experiments = DATA['experiment'].unique()\n",
    "#     n_cols = 2\n",
    "#     n_rows = (len(experiments) + n_cols - 1) // n_cols\n",
    "#     fig, axs = plt.subplots(n_rows, n_cols, figsize=(20 * n_cols, 10 * n_rows))\n",
    "#     axs = axs.flatten()\n",
    "#     for i, exp in enumerate(experiments):\n",
    "#         nbr_part_per_frame = DATA[DATA['experiment'] == exp].groupby('time (min)')['particle'].nunique()\n",
    "#         ax = axs[i]\n",
    "#         ax.plot(nbr_part_per_frame.index, nbr_part_per_frame.values)\n",
    "#         ax.set_ylim([0, nbr_part_per_frame.max() + 10])\n",
    "#         ax.set_title(f'Nbr particle per Frame - {exp}')\n",
    "#         ax.set_xlabel('Time (min)')\n",
    "#         ax.set_ylabel('Number of particles')\n",
    "#     for ax in axs[len(experiments):]:\n",
    "#         ax.axis('off')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(os.path.join(path_save_pic, f\"Nbr_particle_per_Frame_manip_par_manip.{IMG_TYPE}\"), format=IMG_TYPE)\n",
    "#     plt.show()\n",
    "\n",
    "# plot_nbr_particles_per_frame(DATA, path_save_pic, IMG_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<center><span style=\"color: skyblue; font-size: 20px\"> Nombre de particules par frame pour toutes les paticules. </span></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Number of Particles per Frame\n",
    "nbr_part_per_frame = DATA.groupby('time (min)')['particle'].nunique()\n",
    "lib.plot_datas(\n",
    "    x_values=nbr_part_per_frame.index,\n",
    "    y_values=nbr_part_per_frame.values,\n",
    "    title='Nbr particles per Frame',\n",
    "    x_label='Time (min)', y_label='Number of particles',\n",
    "    x_lim=[0, nbr_part_per_frame.index.max()], y_lim=[0, 10000],\n",
    "    save=True, path_save_pic=path_save_pic, img_type=IMG_TYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<center><span style=\"color: skyblue; font-size: 40px\">Trajectoires toutes rassemblées. </span></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Trajectories after Removing Suspicious Particles\n",
    "fig, axis = plt.subplots(figsize=(12, 12), dpi=300)\n",
    "axis.set_aspect('equal', 'box')\n",
    "plt.title('Trajectories after removing suspicious particles', fontsize=16)\n",
    "tp.plot_traj(DATA, label=False, ax=axis)\n",
    "for line in axis.get_lines():\n",
    "    line.set_linewidth(0.1)\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(path_save_pic, f'Trajectories_after_removing_suspicious_particles.{IMG_TYPE}'),\n",
    "            format=IMG_TYPE, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot centered Trajectories after Removing Suspicious Particles\n",
    "fig, axis = plt.subplots(figsize=(12, 12), dpi=300)\n",
    "axis.set_aspect('equal', 'box')\n",
    "plt.title('Centered trajectories after removing suspicious particles', fontsize=16)\n",
    "tp.plot_traj(DATA[['Xc [pix]', 'Yc [pix]', 'frame', 'particle']].rename(columns={'Xc [pix]': 'x', 'Yc [pix]': 'y'}), label=False, ax=axis)\n",
    "for line in axis.get_lines():\n",
    "    line.set_linewidth(0.2)\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(path_save_pic, f'Centered trajectories_after_removing_suspicious_particles.{IMG_TYPE}'),\n",
    "            format=IMG_TYPE, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Trajectories on Original Frames\n",
    "def plot_trajectories_on_frames(DATA, path_save_pic, GENERAL_PATH_PICTURES, CONDITION_simple):\n",
    "    image_path = os.path.join(GENERAL_PATH_PICTURES, f\"{CONDITION_simple}_faits\")\n",
    "    plot_exp = DATA.groupby('experiment')\n",
    "    num_experiments = len(plot_exp)\n",
    "    num_cols = 2\n",
    "    num_rows = (num_experiments + num_cols - 1) // num_cols\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, num_rows * 10))\n",
    "    axes = axes.flatten()\n",
    "    for ax, (exp_name, exp_data) in zip(axes, plot_exp):\n",
    "        exp_directories = []\n",
    "        for dirpath, dirnames, _ in os.walk(image_path):\n",
    "            for dirname in dirnames:\n",
    "                if exp_name in dirname:\n",
    "                    full_path = os.path.join(dirpath, dirname)\n",
    "                    exp_directories.append(full_path)\n",
    "        if exp_directories:\n",
    "            image_path_directory = os.path.join(exp_directories[0], 'mosaic', 'mosaic_total_0.tif')\n",
    "            frame = imageio.imread(image_path_directory)\n",
    "            ax.set_aspect('equal', 'box')\n",
    "            ax.set_title(f'Trajectories for {exp_name}')\n",
    "            tp.plot_traj(exp_data, superimpose=frame, label=False, ax=ax)\n",
    "        else:\n",
    "            print(f\"No directory found for {exp_name}\")\n",
    "            ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(os.path.join(path_save_pic, 'trajectories_on_frame_all_experiment.pdf'), format='pdf')\n",
    "\n",
    "plot_trajectories_on_frames(DATA, path_save_pic, GENERAL_PATH_PICTURES, CONDITION_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<center><span style=\"color: skyblue; font-size: 20px\"> Vitesse instantanée moyenne par frame. </span></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Mean Instantaneous Speed per Frame\n",
    "mean_VitInst_per_frame = DATA.groupby('time (min)')['VitInst [um/min]'].median()\n",
    "mean_VitInst_per_frame = mean_VitInst_per_frame.rolling(5).mean().dropna()\n",
    "\n",
    "# Appel avec vérification du répertoire\n",
    "lib.plot_datas(\n",
    "    x_values=mean_VitInst_per_frame.index,\n",
    "    y_values=mean_VitInst_per_frame.values,\n",
    "    title='Mean VitInst [um/min] per Frame',\n",
    "    x_label='Time (min)', y_label='Mean VitInst [um/min]',\n",
    "    x_lim=[0, mean_VitInst_per_frame.index.max()], y_lim=[0, 10],\n",
    "    save=True, path_save_pic=path_save_pic, img_type=IMG_TYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute MSD\n",
    "# DATA_intermediaire = DATA.copy()\n",
    "DATA['frame'] = pd.factorize(DATA['frame'])[0]\n",
    "IMSD = tp.imsd(traj=DATA, mpp=SIZE_PIX, fps=FPS, max_lagtime=200, statistic='msd')\n",
    "\n",
    "lib.plot_msd(IMSD, fps=FPS, name=\"MSD of all frames vs lag time (s)\",\n",
    "             color_plot='forestgreen', save=True, pathway_saving=path_save_pic,\n",
    "             alpha=0.3, linewidth=0.1, img_type=IMG_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload custom library\n",
    "importlib.reload(lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute trajectory clustering with new cutoff\n",
    "LAG_TIME_FIT = 5\n",
    "COEF_INF, COEF_SUP, PART_COEF_INF, PART_COEF_SUP, CUTOFF = lib.traj_clustering_with_fit_cutoff(\n",
    "    DATA, imsd=IMSD, hist=True, lag_time_fit=LAG_TIME_FIT, micronperpixel=SIZE_PIX,\n",
    "    fps=FPS, binsize=250, peak_height=50, peak_width=1, save=True, pathway_fig=path_save_pic,\n",
    "    name='MSD and slopes', img_type=IMG_TYPE, plot=True, color_sup_inf=color_sup_inf,\n",
    "    cutoff_default=1.0\n",
    ")\n",
    "\n",
    "# Ajouter les colonnes 'is_inf' et 'is_sup' à DATA\n",
    "DATA['particle'] = DATA['particle'].astype(int)\n",
    "PART_COEF_INF = set(map(int, PART_COEF_INF))\n",
    "PART_COEF_SUP = set(map(int, PART_COEF_SUP))\n",
    "\n",
    "# Ajout des colonnes 'is_inf' et 'is_sup'\n",
    "DATA['is_inf'] = DATA['particle'].isin(PART_COEF_INF).astype(int)\n",
    "DATA['is_sup'] = DATA['particle'].isin(PART_COEF_SUP).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<center><span style=\"color: skyblue; font-size: 40px\">Calculs des différents metrics importants </span></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(DATA):\n",
    "    # Calculer les vitesses moyennes instantanées pour toutes les particules\n",
    "    mean_vitinst_df = DATA.groupby(['experiment', 'particle'])['VitInst [um/min]'].mean().reset_index()\n",
    "    mean_vitinst_df = mean_vitinst_df.rename(columns={'VitInst [um/min]': 'mean_vit_inst'})\n",
    "\n",
    "    # Calculer les médianes des vitesses instantanées pour toutes les particules\n",
    "    median_vitinst_df = DATA.groupby(['experiment', 'particle'])['VitInst [um/min]'].median().reset_index()\n",
    "    median_vitinst_df = median_vitinst_df.rename(columns={'VitInst [um/min]': 'median_vit_inst'})\n",
    "\n",
    "    # Initialisation d'une liste pour stocker les résultats\n",
    "    metrics = []\n",
    "\n",
    "    # Parcours de chaque particule pour calculer les métriques\n",
    "    for particle, group in DATA.groupby('particle'):\n",
    "        experiment = group['experiment'].iloc[0]\n",
    "\n",
    "        # Limiter aux 200 premières lignes\n",
    "        limited_group = group.head(200)\n",
    "\n",
    "        # Somme des déplacements (seulement sur les 200 premières lignes)\n",
    "        displacement_sum = limited_group['displacement [pix]'].sum()\n",
    "\n",
    "        # Récupérer la vitesse moyenne instantanée pré-calculée\n",
    "        mean_vit_inst = mean_vitinst_df.loc[\n",
    "            (mean_vitinst_df['experiment'] == experiment) & (mean_vitinst_df['particle'] == particle),\n",
    "            'mean_vit_inst'\n",
    "        ].values[0]\n",
    "\n",
    "        # Récupérer la médiane des vitesses instantanées pré-calculée\n",
    "        median_vit_inst = median_vitinst_df.loc[\n",
    "            (median_vitinst_df['experiment'] == experiment) & (median_vitinst_df['particle'] == particle),\n",
    "            'median_vit_inst'\n",
    "        ].values[0]\n",
    "\n",
    "        # Distance entre la position de départ et d'arrivée\n",
    "        start_position = limited_group.iloc[0][['x', 'y']].values\n",
    "        end_position = limited_group.iloc[-1][['x', 'y']].values\n",
    "        start_end_distance = np.linalg.norm(end_position - start_position)\n",
    "\n",
    "        # Stocker les résultats dans un dictionnaire\n",
    "        metrics.append({\n",
    "            'experiment': experiment,\n",
    "            'particle': particle,\n",
    "            'displacement_sum [um]': displacement_sum,\n",
    "            'mean_vit_inst [um/min]': mean_vit_inst,\n",
    "            'median_vit_inst [um/min]': median_vit_inst,\n",
    "            'start_end_distance [um]': start_end_distance\n",
    "        })\n",
    "\n",
    "    # Conversion en DataFrame\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    return metrics_df\n",
    "\n",
    "# Appel de la fonction pour obtenir le DataFrame consolidé\n",
    "metrics_df = calculate_metrics(DATA)\n",
    "\n",
    "# Affichage pour vérification\n",
    "metrics_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_metrics(DATA):\n",
    "    \"\"\"\n",
    "    Calcule diverses métriques pour chaque expérience, y compris la vitesse moyenne\n",
    "    des particules sup et inf.\n",
    "    \"\"\"\n",
    "    # Calculer le temps d'incubation et le nombre de particules (exp_hours)\n",
    "    exp_hours = (\n",
    "        DATA.groupby('experiment')\n",
    "        .agg({\n",
    "            'time to incubation (hours)': 'first',\n",
    "            'particle': 'nunique'\n",
    "        })\n",
    "        .reset_index()\n",
    "        .rename(columns={'particle': 'number_of_particles'})\n",
    "    )\n",
    "\n",
    "    # Compter les particules is_inf et is_sup\n",
    "    particle_counts = (\n",
    "        DATA.groupby(['experiment', 'particle'])\n",
    "        .agg(\n",
    "            is_inf=('is_inf', 'max'),\n",
    "            is_sup=('is_sup', 'max')\n",
    "        )\n",
    "        .reset_index()\n",
    "        .groupby('experiment')\n",
    "        .agg(\n",
    "            number_of_inf=('is_inf', 'sum'),\n",
    "            number_of_sup=('is_sup', 'sum')\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    particle_counts['proportion_inf'] = particle_counts['number_of_inf'] / (\n",
    "        particle_counts['number_of_inf'] + particle_counts['number_of_sup']\n",
    "    )\n",
    "\n",
    "    # Calculer les métriques issues de metrics_df\n",
    "    metrics_df = DATA.groupby(['experiment', 'particle']).apply(\n",
    "        lambda group: {\n",
    "            'displacement_sum [um]': group.head(200)['displacement [pix]'].sum(),\n",
    "            'start_end_distance [um]': np.linalg.norm(\n",
    "                group.head(200).iloc[0][['x', 'y']].values -\n",
    "                group.head(200).iloc[-1][['x', 'y']].values\n",
    "            ),\n",
    "            'mean_vit_inst [um/min]': group['VitInst [um/min]'].median()\n",
    "        }\n",
    "    ).apply(pd.Series).reset_index()\n",
    "\n",
    "    # Ajouter la vitesse mediane pour les particules sup et inf\n",
    "    sup_inf_speeds = DATA.groupby(['experiment', 'particle']).agg(\n",
    "        is_sup=('is_sup', 'max'),\n",
    "        is_inf=('is_inf', 'max'),\n",
    "        mean_vit_inst=('VitInst [um/min]', 'median')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Calculer la vitesse mediane des particules sup et inf par expérience\n",
    "    sup_inf_speeds_agg = sup_inf_speeds.groupby('experiment').agg(\n",
    "        mean_speed_sup=('mean_vit_inst', lambda x: x[sup_inf_speeds['is_sup'] == 1].median() if (sup_inf_speeds['is_sup'] == 1).any() else 0),\n",
    "        mean_speed_inf=('mean_vit_inst', lambda x: x[sup_inf_speeds['is_inf'] == 1].median() if (sup_inf_speeds['is_inf'] == 1).any() else 0)\n",
    "    ).reset_index()\n",
    "\n",
    "    # Calculer taille et particules par champ\n",
    "    spatial_metrics = DATA.groupby('experiment').apply(lambda group: {\n",
    "        'taille': math.ceil(group['y'].max() / 2048) * math.ceil(group['x'].max() / 2048),\n",
    "        'nombre_part_par_champs': group['particle'].nunique() /\n",
    "        (math.ceil(group['y'].max() / 2048) * math.ceil(group['x'].max() / 2048)) if (\n",
    "            math.ceil(group['y'].max() / 2048) * math.ceil(group['x'].max() / 2048)) > 0 else 0\n",
    "    }).apply(pd.Series).reset_index()\n",
    "\n",
    "    # Calculer d'autres métriques\n",
    "    result_metrics = metrics_df.groupby('experiment').agg(\n",
    "        displacement_sum_mean=('displacement_sum [um]', 'median'),\n",
    "        start_end_distance_mean=('start_end_distance [um]', 'median'),\n",
    "        mean_speed=('mean_vit_inst [um/min]', 'median')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Fusionner toutes les métriques\n",
    "    consolidated_metrics = (\n",
    "        exp_hours\n",
    "        .merge(particle_counts, on='experiment', how='outer')\n",
    "        .merge(result_metrics, on='experiment', how='outer')\n",
    "        .merge(sup_inf_speeds_agg, on='experiment', how='outer')\n",
    "        .merge(spatial_metrics, on='experiment', how='outer')\n",
    "    )\n",
    "\n",
    "    # Renommer les colonnes après la fusion\n",
    "    consolidated_metrics = consolidated_metrics.rename(columns={\n",
    "        'displacement_sum_mean': 'displacement_sum_mean [um]',\n",
    "        'start_end_distance_mean': 'start_end_distance_mean [um]',\n",
    "        'mean_speed': 'mean_speed [um/min]',\n",
    "        'mean_speed_sup': 'mean_speed_sup [um/min]',\n",
    "        'mean_speed_inf': 'mean_speed_inf [um/min]'\n",
    "    })\n",
    "\n",
    "    return consolidated_metrics\n",
    "\n",
    "# Appel de la fonction\n",
    "all_metrics_df = calculate_all_metrics(DATA)\n",
    "\n",
    "# Affichage pour vérification\n",
    "all_metrics_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DATA[DATA['is_inf']==True]['particle'].nunique())\n",
    "print(DATA['particle'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Displacement\n",
    "importlib.reload(lib)\n",
    "lib.plot_displacement(\n",
    "    DATA,\n",
    "    start_end=metrics_df[['particle', 'start_end_distance [um]']],\n",
    "    alpha=0.1,\n",
    "    linewidth=0.3,\n",
    "    ylim=[0, 750],\n",
    "    xlim=[0, DATA['time (min)'].max()],\n",
    "    save=True,\n",
    "    pathway_saving=path_save_pic,\n",
    "    name='displacement start-end all',\n",
    "    img_type=IMG_TYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Histograms of Start-End Distances\n",
    "def plot_histograms(start_end, PART_COEF_SUP, PART_COEF_INF, IMG_TYPE):\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(5, 10), sharex=True, sharey=True)\n",
    "    axes[0].hist(metrics_df['start_end_distance [um]'], bins=250, color='royalblue', alpha=0.7, density=True)\n",
    "    axes[0].set_xlim([0, 400])\n",
    "    axes[0].set_ylim([0, 0.03])\n",
    "    axes[0].set_title('Start-End Distances - All Particles', fontsize=16)\n",
    "    axes[0].set_ylabel('Density', fontsize=14)\n",
    "    axes[0].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    axes[1].hist(metrics_df[metrics_df['particle'].isin(PART_COEF_SUP)][['start_end_distance [um]']], bins=250, color='blue', alpha=0.7, density=True)\n",
    "    axes[1].set_xlim([0, 400])\n",
    "    axes[1].set_title('Start-End Distances - High Coefficient Particles', fontsize=16)\n",
    "    axes[1].set_ylabel('Density', fontsize=14)\n",
    "    axes[1].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    axes[2].hist(metrics_df[metrics_df['particle'].isin(PART_COEF_INF)][['start_end_distance [um]']], bins=250, color='red', alpha=0.7, density=True)\n",
    "    axes[2].set_xlim([0, 400])\n",
    "    axes[2].set_title('Start-End Distances - Low Coefficient Particles', fontsize=16)\n",
    "    axes[2].set_xlabel('Distance (μm)', fontsize=14)\n",
    "    axes[2].set_ylabel('Density', fontsize=14)\n",
    "    axes[2].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_save_pic, f\"Nstart_end inf supp and all.{IMG_TYPE}\"), format=IMG_TYPE)\n",
    "    plt.show()\n",
    "\n",
    "plot_histograms(start_end, PART_COEF_SUP, PART_COEF_INF, IMG_TYPE=IMG_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Results in Function of Number of Particles per Field\n",
    "def plot_results_vs_particles(all_metrics_df, path_save_pic, CONDITION_simple, img_type='svg'):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "    ax1, ax2 = axes.flatten()\n",
    "    ax1.scatter(all_metrics_df['nombre_part_par_champs'], all_metrics_df['displacement_sum_mean [um]'], marker='+', color='orange')\n",
    "    ax1.set_title('Average distance traveled vs. Number of particles per field')\n",
    "    ax1.set_xlabel('Number of particles per field')\n",
    "    ax1.set_ylabel('Average distance traveled')\n",
    "    ax2.scatter(all_metrics_df['nombre_part_par_champs'], all_metrics_df['mean_speed [um/min]'], marker='+', color='blue')\n",
    "    ax2.set_title('Mean Speed vs. Number of particles per field')\n",
    "    ax2.set_xlabel('Number of particles per field')\n",
    "    ax2.set_ylabel('Mean Speed [μm/min]')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(os.path.join(path_save_pic, f\"Results_vs_particles_{CONDITION_simple}.{img_type}\"), format=img_type)\n",
    "\n",
    "plot_results_vs_particles(all_metrics_df, path_save_pic, CONDITION_simple, img_type=IMG_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Angle Changes between Directions\n",
    "def compute_angle_changes(DATA, PART_COEF_SUP, PART_COEF_INF):\n",
    "    def angle_between_directions(row):\n",
    "        dx1, dy1 = row['dir_x'], row['dir_y']\n",
    "        dx2, dy2 = row['dir_x_next'], row['dir_y_next']\n",
    "        angle_initial = np.arctan2(dy1, dx1)\n",
    "        angle_final = np.arctan2(dy2, dx2)\n",
    "        angle_change = angle_final - angle_initial\n",
    "        angle_change = (angle_change + np.pi) % (2 * np.pi) - np.pi\n",
    "        return np.degrees(angle_change)\n",
    "\n",
    "    df_sup = DATA[DATA['particle'].isin(PART_COEF_SUP)].copy()\n",
    "    df_sup.sort_values(by=['particle', 'frame'], inplace=True)\n",
    "    df_sup['dir_x'] = df_sup.groupby('particle')['x'].diff().fillna(0)\n",
    "    df_sup['dir_y'] = df_sup.groupby('particle')['y'].diff().fillna(0)\n",
    "    df_sup['dir_x_next'] = df_sup.groupby('particle')['dir_x'].shift(-1)\n",
    "    df_sup['dir_y_next'] = df_sup.groupby('particle')['dir_y'].shift(-1)\n",
    "    df_sup['angle_change'] = df_sup.apply(angle_between_directions, axis=1)\n",
    "    df_sup.dropna(subset=['dir_x_next', 'dir_y_next'], inplace=True)\n",
    "\n",
    "    df_inf = DATA[DATA['particle'].isin(PART_COEF_INF)].copy()\n",
    "    df_inf.sort_values(by=['particle', 'frame'], inplace=True)\n",
    "    df_inf['dir_x'] = df_inf.groupby('particle')['x'].diff().fillna(0)\n",
    "    df_inf['dir_y'] = df_inf.groupby('particle')['y'].diff().fillna(0)\n",
    "    df_inf['dir_x_next'] = df_inf.groupby('particle')['dir_x'].shift(-1)\n",
    "    df_inf['dir_y_next'] = df_inf.groupby('particle')['dir_y'].shift(-1)\n",
    "    df_inf['angle_change'] = df_inf.apply(angle_between_directions, axis=1)\n",
    "    df_inf.dropna(subset=['dir_x_next', 'dir_y_next'], inplace=True)\n",
    "\n",
    "    return df_sup, df_inf\n",
    "\n",
    "df_sup, df_inf = compute_angle_changes(DATA, PART_COEF_SUP, PART_COEF_INF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of angle changes\n",
    "def plot_angle_histograms(df_all, df_sup, df_inf, img_type='svg'):\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(5, 10), sharex=True)\n",
    "    axes[0].hist(df_all['angle_change'], bins=1000, alpha=0.5, color='green')\n",
    "    axes[0].set_title('Angle Changes - All Particles')\n",
    "    axes[0].set_xlabel('Angle (degrees)')\n",
    "    axes[0].set_ylabel('Density')\n",
    "\n",
    "    axes[1].hist(df_sup['angle_change'], bins=1000, color='blue', alpha=0.5)\n",
    "    axes[1].set_title('Angle Changes - High Coefficient Particles')\n",
    "    axes[1].set_xlabel('Angle (degrees)')\n",
    "    axes[1].set_ylabel('Density')\n",
    "\n",
    "    axes[2].hist(df_inf['angle_change'], bins=1000, color='red', alpha=0.5)\n",
    "    axes[2].set_title('Angle Changes - Low Coefficient Particles')\n",
    "    axes[2].set_xlabel('Angle (degrees)')\n",
    "    axes[2].set_ylabel('Density')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    fig.savefig(os.path.join(path_save_pic, f'Angle_Changes_Histograms.{img_type}'), format=img_type)\n",
    "\n",
    "df_all = pd.concat([df_sup, df_inf])\n",
    "plot_angle_histograms(df_all, df_sup, df_inf, img_type=IMG_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_vit_histograms_comparison(metrics_df, part_coef_sup, part_coef_inf, alpha=0.5, path_save_pic=None, img_type='png'):\n",
    "    \"\"\"\n",
    "    Trace sur le même graphique les histogrammes des mean_vit_inst [um/min]\n",
    "    pour les particules avec coefficients supérieurs et inférieurs.\n",
    "\n",
    "    Parameters:\n",
    "    - metrics_df (DataFrame): DataFrame contenant les données, avec une colonne 'mean_vit_inst [um/min]'.\n",
    "    - part_coef_sup (list): Liste des particules avec coefficients supérieurs.\n",
    "    - part_coef_inf (list): Liste des particules avec coefficients inférieurs.\n",
    "    - path_save_pic (str, optional): Chemin pour sauvegarder l'image. Si None, l'image ne sera pas sauvegardée.\n",
    "    - img_type (str, optional): Format de l'image pour la sauvegarde (par défaut 'png').\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Vérification de la présence de la colonne nécessaire\n",
    "    if 'mean_vit_inst [um/min]' not in metrics_df.columns:\n",
    "        raise ValueError(\"La colonne 'mean_vit_inst [um/min]' est absente de metrics_df.\")\n",
    "    \n",
    "    # Filtrer les données\n",
    "    df_sup = metrics_df[metrics_df['particle'].isin(part_coef_sup)]\n",
    "    df_inf = metrics_df[metrics_df['particle'].isin(part_coef_inf)]\n",
    "    \n",
    "    median_value_sup = df_sup['median_vit_inst [um/min]'].median()\n",
    "    median_value_inf = df_inf['median_vit_inst [um/min]'].median()\n",
    "\n",
    "    # Préparer le graphique\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.hist(df_sup['median_vit_inst [um/min]'], bins=100, color='blue', alpha=alpha, label=\"hight slope\", density=True)\n",
    "    plt.hist(df_inf['median_vit_inst [um/min]'], bins=100, color='red', alpha=alpha, label=\"low slope\", density=True)\n",
    "\n",
    "     # Ajouter une barre verticale à la médiane\n",
    "    plt.axvline(median_value_inf, color='red', linestyle='--', linewidth=2, label=f'Median: {median_value_inf:.2f} μm/min')\n",
    "    plt.axvline(median_value_sup, color='blue', linestyle='--', linewidth=2, label=f'Median: {median_value_sup:.2f} μm/min')\n",
    "\n",
    "\n",
    "    # Ajouter des titres et des légendes\n",
    "    plt.title(\"Median speed [μm/min]\", fontsize=14)\n",
    "    plt.xlabel(\"Median Instantaneous Velocity [μm/min]\", fontsize=12)\n",
    "    plt.ylabel(\"Density\", fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend(fontsize=12)\n",
    "    \n",
    "    # Sauvegarde de l'image si un chemin est spécifié\n",
    "    if path_save_pic:\n",
    "        save_path = os.path.join(path_save_pic, f'Median_Velocity_Histograms_Comparison.{img_type}')\n",
    "        plt.savefig(save_path, format=img_type)\n",
    "        print(f\"Plot sauvegardé à : {save_path}\")\n",
    "    \n",
    "    # Afficher le graphique\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_vit_histograms_comparison(metrics_df, PART_COEF_SUP, PART_COEF_INF, path_save_pic=path_save_pic, img_type=IMG_TYPE, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer le graphique\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.hist(DATA['VitInst [um/min]'], bins=500, color='limegreen', alpha=0.8, label=\"all speed\", density=True)\n",
    "\n",
    "# Ajouter une barre verticale à la médiane\n",
    "# plt.axvline(median_value, color='red', linestyle='--', linewidth=2, label=f'Median: {median_value:.2f} μm/min')\n",
    "\n",
    "# Ajouter des titres et des légendes\n",
    "plt.title(\"VitInst[μm/min]\", fontsize=14)\n",
    "plt.xlabel(\"Instantaneous Velocity [μm/min]\", fontsize=12)\n",
    "plt.ylabel(\"Density\", fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_vit_histograms_comparison(metrics_df, path_save_pic=None, img_type='png', alpha=0.7):\n",
    "    \"\"\"\n",
    "    Trace sur le même graphique les histogrammes des mean_vit_inst [um/min]\n",
    "    pour les particules avec coefficients supérieurs et inférieurs.\n",
    "\n",
    "    Parameters:\n",
    "    - metrics_df (DataFrame): DataFrame contenant les données, avec une colonne 'mean_vit_inst [um/min]'.\n",
    "    - path_save_pic (str, optional): Chemin pour sauvegarder l'image. Si None, l'image ne sera pas sauvegardée.\n",
    "    - img_type (str, optional): Format de l'image pour la sauvegarde (par défaut 'png').\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Vérification de la présence de la colonne nécessaire\n",
    "    if 'median_vit_inst [um/min]' not in metrics_df.columns:\n",
    "        raise ValueError(\"La colonne 'median_vit_inst [um/min]' est absente de metrics_df.\")\n",
    "    \n",
    "    # Calcul de la médiane\n",
    "    median_value = metrics_df['median_vit_inst [um/min]'].median()\n",
    "    print(f\"Median value: {median_value}\")\n",
    "\n",
    "    # Préparer le graphique\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.hist(metrics_df['median_vit_inst [um/min]'], bins=100, color='limegreen', alpha=alpha, label=\"all speed\", density=True)\n",
    "\n",
    "    # Ajouter une barre verticale à la médiane\n",
    "    plt.axvline(median_value, color='red', linestyle='--', linewidth=2, label=f'Median: {median_value:.2f} μm/min')\n",
    "\n",
    "    # Ajouter des titres et des légendes\n",
    "    plt.title(\"Median speed [μm/min]\", fontsize=14)\n",
    "    plt.xlabel(\"Median Instantaneous Velocity [μm/min]\", fontsize=12)\n",
    "    plt.ylabel(\"Density\", fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend(fontsize=12)\n",
    "    \n",
    "    # Sauvegarde de l'image si un chemin est spécifié\n",
    "    if path_save_pic:\n",
    "        save_path = os.path.join(path_save_pic, f'Median_Velocity_Histograms_all.{img_type}')\n",
    "        plt.savefig(save_path, format=img_type)\n",
    "        print(f\"Plot sauvegardé à : {save_path}\")\n",
    "    \n",
    "    # Afficher le graphique\n",
    "    # Sans tight_layout (les titres peuvent se chevaucher)\n",
    "    plt.tight_layout()  # Ajuste automatiquement l'espacement\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_vit_histograms_comparison(metrics_df, path_save_pic=path_save_pic, img_type=IMG_TYPE, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "\n",
    "def plot_velocity_histograms(all_metrics_df, metrics_df, path_save_pic, img_type):\n",
    "    \"\"\"\n",
    "    Plot histograms of median instantaneous velocities for each experiment, sorted by incubation time.\n",
    "\n",
    "    Parameters:\n",
    "    - all_metrics_df (DataFrame): Aggregated metrics per experiment.\n",
    "    - metrics_df (DataFrame): Metrics for each particle and experiment.\n",
    "    - path_save_pic (str): Path where the plot will be saved.\n",
    "    - img_type (str): Image format for saving the plot.\n",
    "    \"\"\"\n",
    "    # Trier les expériences par temps d'incubation\n",
    "    exp_hours = all_metrics_df[['experiment', 'time to incubation (hours)']].sort_values(by='time to incubation (hours)')\n",
    "    experiments = exp_hours['experiment'].tolist()\n",
    "    incubation_times = exp_hours['time to incubation (hours)'].tolist()\n",
    "\n",
    "    # Déterminer les bornes de l'axe X\n",
    "    global_min = metrics_df['median_vit_inst [um/min]'].min()\n",
    "    global_max = metrics_df['median_vit_inst [um/min]'].max()\n",
    "    delta = (global_max - global_min) * 0.1  # Ajouter 10% de marge pour l'affichage\n",
    "    global_min -= delta\n",
    "    global_max += delta\n",
    "\n",
    "    # Liste pour stocker les médianes des vitesses moyennes instantanées\n",
    "    median_values_list = []\n",
    "\n",
    "    # Nombre d'expériences à afficher\n",
    "    n_experiments = len(experiments)\n",
    "    fig, axes = plt.subplots(nrows=n_experiments, ncols=1, figsize=(10, 3 * n_experiments), sharex=True, sharey=True)\n",
    "\n",
    "    if n_experiments == 1:\n",
    "        axes = [axes]  # S'assurer que 'axes' est une liste si un seul subplot\n",
    "\n",
    "    # Palette de couleurs\n",
    "    palette = colormaps['tab20']\n",
    "    colors = [palette(i / n_experiments) for i in range(n_experiments)]\n",
    "\n",
    "    # Boucle sur chaque expérience\n",
    "    for idx, ax in enumerate(axes):\n",
    "        exp = experiments[idx]\n",
    "        hour = incubation_times[idx]\n",
    "\n",
    "        # Filtrer les données pour cette expérience\n",
    "        data_exp = metrics_df[metrics_df['experiment'] == exp]\n",
    "        num_particles = len(data_exp)  # Nombre de particules dans cette expérience\n",
    "\n",
    "        # Calculer la médiane des vitesses moyennes instantanées pour cette expérience\n",
    "        median_value = data_exp['median_vit_inst [um/min]'].median()\n",
    "        median_values_list.append(median_value)  # Stocker la médiane\n",
    "\n",
    "        # Tracer l'histogramme\n",
    "        ax.hist(data_exp['median_vit_inst [um/min]'], bins=30, alpha=0.3, range=(global_min, global_max), color=colors[idx])\n",
    "\n",
    "        # Ajouter titre et labels\n",
    "        ax.set_title(f'Vit. Inst. Mediane [μm/min] - {exp} (Incubation: {hour}h)')\n",
    "        ax.set_xlabel('VitInst [μm/min]')\n",
    "        ax.set_ylabel('Nombre de particules')\n",
    "\n",
    "        # Ajouter la médiane avec une ligne verticale rouge\n",
    "        ax.axvline(median_value, color='red', linestyle='dashed', linewidth=1)\n",
    "        ax.text(\n",
    "            median_value + 0.05 * (global_max - global_min), \n",
    "            # ax.get_ylim()[1] * 0.95,\n",
    "            75,\n",
    "            f'Médiane: {median_value:.2f}',\n",
    "            color='red',\n",
    "            ha='left'\n",
    "        )\n",
    "\n",
    "        # Ajouter le nombre total de particules sur le graphique\n",
    "        ax.text(\n",
    "            global_max - 0.1 * (global_max - global_min),  # Position X\n",
    "            # ax.get_ylim()[1] * 0.85,  # Position Y (haut du graphe)\n",
    "            75,\n",
    "            f'Nb Particules: {num_particles}',\n",
    "            color='black',\n",
    "            ha='right',\n",
    "            fontsize=10,\n",
    "            bbox=dict(facecolor='white', alpha=0.5, edgecolor='black')\n",
    "        )\n",
    "\n",
    "        # Ajuster les limites de l'axe X\n",
    "        ax.set_xlim(global_min, global_max)\n",
    "\n",
    "    # Calculer la moyenne et la médiane des médianes enregistrées\n",
    "    overall_median_of_medians = np.median(median_values_list)\n",
    "    overall_mean_of_medians = np.mean(median_values_list)\n",
    "\n",
    "    # Afficher les résultats finaux\n",
    "    print(f\"Médiane globale des médianes : {overall_median_of_medians:.2f} μm/min\")\n",
    "    print(f\"Moyenne globale des médianes : {overall_mean_of_medians:.2f} μm/min\")\n",
    "\n",
    "    # Ajuster l'affichage et sauvegarder la figure\n",
    "    plt.tight_layout()\n",
    "    fig_path = os.path.join(path_save_pic, f'Velocity_Histograms.{img_type}')\n",
    "    fig.savefig(fig_path, format=img_type)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Plot saved to {fig_path}\")\n",
    "\n",
    "    return overall_median_of_medians, overall_mean_of_medians  # Retourner ces valeurs si besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_velocity_histograms(all_mean_vitinst, medians, exp_hours, path_save_pic, IMG_TYPE)\n",
    "plot_velocity_histograms(all_metrics_df, metrics_df, path_save_pic, IMG_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<center><span style=\"color: skyblue; font-size: 20px\"> Calcul de l'autocorrelation de la vitesse </span></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def velocity_autocorrelation_per_particle(data, max_lag, fps):\n",
    "    \"\"\"\n",
    "    Calcule l'autocorrélation de la vitesse pour chaque particule individuellement.\n",
    "\n",
    "    Paramètres:\n",
    "    ----------\n",
    "    - data : pd.DataFrame\n",
    "        DataFrame contenant les trajectoires, avec les colonnes :\n",
    "        ['experiment', 'particle', 'frame', 'dx [pix]', 'dy [pix]']\n",
    "    - max_lag : int\n",
    "        Nombre maximum d'intervalle de temps (tau) pour l'autocorrélation.\n",
    "    - fps : float\n",
    "        Nombre d'images par seconde, pour convertir le temps en secondes.\n",
    "\n",
    "    Retourne:\n",
    "    ----------\n",
    "    - autocorr_df : pd.DataFrame\n",
    "        DataFrame contenant l'autocorrélation moyenne et individuelle par particule.\n",
    "    \"\"\"\n",
    "\n",
    "    # Vérifier que les colonnes nécessaires existent\n",
    "    required_columns = {'experiment', 'particle', 'frame', 'dx [pix]', 'dy [pix]'}\n",
    "    if not required_columns.issubset(data.columns):\n",
    "        raise KeyError(f\"🚨 Erreur : Les colonnes requises {required_columns} ne sont pas toutes présentes dans DATA.\")\n",
    "\n",
    "    # Trier les données\n",
    "    data = data.sort_values(by=['experiment', 'particle', 'frame'])\n",
    "\n",
    "    # Calculer les composantes de vitesse vx et vy\n",
    "    data['vx'] = data['dx [pix]'] / data.groupby(['experiment', 'particle'])['frame'].diff()\n",
    "    data['vy'] = data['dy [pix]'] / data.groupby(['experiment', 'particle'])['frame'].diff()\n",
    "\n",
    "    # Remplir les NaN initiaux (première frame de chaque particule)\n",
    "    data[['vx', 'vy']] = data[['vx', 'vy']].fillna(0)\n",
    "\n",
    "    # Dictionnaire pour stocker les résultats\n",
    "    autocorr_dict = {'lag': []}\n",
    "    particle_corrs = {}\n",
    "\n",
    "    # Parcourir chaque particule et calculer son autocorrélation individuelle\n",
    "    for particle, group in data.groupby(['experiment', 'particle']):\n",
    "        group = group.sort_values(by='frame')\n",
    "\n",
    "        # Vérifier qu'il y a assez de points pour calculer l'autocorrélation\n",
    "        if len(group) < max_lag:\n",
    "            continue\n",
    "\n",
    "        v_t = np.sqrt(group['vx']**2 + group['vy']**2).values\n",
    "\n",
    "        autocorr_values = []\n",
    "        for tau in range(1, max_lag + 1):\n",
    "            v_tau = np.roll(v_t, -tau)  # Décaler les vitesses de tau frames\n",
    "            valid_idx = np.arange(len(v_t)) < (len(v_t) - tau)  # Éviter les valeurs hors limites\n",
    "\n",
    "            # Calculer l'autocorrélation\n",
    "            corr = np.mean(v_t[valid_idx] * v_tau[valid_idx]) / np.mean(v_t[valid_idx]**2)\n",
    "            autocorr_values.append(corr)\n",
    "\n",
    "        particle_corrs[particle] = autocorr_values\n",
    "\n",
    "    # Transformer en DataFrame\n",
    "    autocorr_df = pd.DataFrame.from_dict(particle_corrs, orient='index', columns=[f'lag_{tau}' for tau in range(1, max_lag + 1)])\n",
    "    autocorr_df.index.name = 'particle'\n",
    "\n",
    "    # Calculer la moyenne des autocorrélations par lag\n",
    "    autocorr_df.loc['mean'] = autocorr_df.mean()\n",
    "\n",
    "    return autocorr_df\n",
    "\n",
    "# Définition des paramètres\n",
    "max_lag = 30  # Nombre de frames de décalage maximal\n",
    "fps = FPS  # Images par seconde\n",
    "\n",
    "# Calcul de l'autocorrélation par particule\n",
    "autocorr_result = velocity_autocorrelation_per_particle(DATA, max_lag=max_lag, fps=fps)\n",
    "\n",
    "# Afficher les résultats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lags = np.arange(1, max_lag + 1) / fps  # Convertir en secondes\n",
    "plt.plot(lags, autocorr_result.loc['mean'].values, marker='o', label=\"Autocorrélation moyenne\")\n",
    "\n",
    "plt.xlabel(\"Décalage temporel (s)\")\n",
    "plt.ylabel(\"Autocorrélation de la vitesse\")\n",
    "plt.title(\"Autocorrélation de la vitesse (moyenne sur particules)\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des paramètres\n",
    "max_lag = 30  # Nombre de frames de décalage maximal\n",
    "fps = FPS  # Images par seconde\n",
    "\n",
    "# Calcul de l'autocorrélation par particule\n",
    "autocorr_result = velocity_autocorrelation_per_particle(DATA, max_lag=max_lag, fps=fps)\n",
    "\n",
    "# Afficher les résultats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lags = np.arange(1, max_lag + 1) / fps  # Convertir en secondes\n",
    "plt.plot(lags, autocorr_result.loc['mean'].values, marker='o', label=\"Autocorrélation moyenne\")\n",
    "\n",
    "plt.xlabel(\"Décalage temporel (s)\")\n",
    "plt.ylabel(\"Autocorrélation de la vitesse\")\n",
    "plt.title(\"Autocorrélation de la vitesse (moyenne sur particules)\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def velocity_autocorrelation_by_experiment_and_global(data, max_lag, fps):\n",
    "    \"\"\"\n",
    "    Calcule l'autocorrélation de la vitesse par particule, puis :\n",
    "      1) Moyenne par expérience\n",
    "      2) Moyenne globale (sur toutes les particules de toutes les expériences).\n",
    "    \n",
    "    Retourne un DataFrame dont :\n",
    "      - L'index = décalages en secondes (1/fps, 2/fps, ..., max_lag/fps).\n",
    "      - Les colonnes = chaque expérience + la colonne 'All' (moyenne globale).\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        DataFrame contenant les trajectoires, avec colonnes :\n",
    "        ['experiment', 'particle', 'frame', 'dx [pix]', 'dy [pix]']\n",
    "    max_lag : int\n",
    "        Nombre maximum d'intervalle de temps (tau) pour l'autocorrélation.\n",
    "    fps : float\n",
    "        Nombre d'images par seconde, pour convertir frames -> secondes.\n",
    "    \n",
    "    Retourne\n",
    "    --------\n",
    "    autocorr_df : pd.DataFrame\n",
    "        * index : lags (s)\n",
    "        * colonnes : expériences + 'All'\n",
    "    \"\"\"\n",
    "    # Vérifier colonnes\n",
    "    required_cols = {'experiment', 'particle', 'frame', 'dx [pix]', 'dy [pix]'}\n",
    "    if not required_cols.issubset(data.columns):\n",
    "        raise KeyError(\n",
    "            f\"🚨 Les colonnes requises {required_cols} ne sont pas toutes présentes dans 'data'.\"\n",
    "        )\n",
    "    \n",
    "    # Trier la DataFrame\n",
    "    data = data.sort_values(by=['experiment', 'particle', 'frame'])\n",
    "    \n",
    "    # Calcul des composantes de vitesse vx, vy\n",
    "    data['delta_frame'] = data.groupby(['experiment', 'particle'])['frame'].diff()\n",
    "    data['vx'] = data['dx [pix]'] / data['delta_frame']\n",
    "    data['vy'] = data['dy [pix]'] / data['delta_frame']\n",
    "    data[['vx', 'vy']] = data[['vx', 'vy']].fillna(0)\n",
    "    \n",
    "    # Stockage des autocorrélations\n",
    "    # experiment_autocorrs[exp_name] = [ [autocorr_part1], [autocorr_part2], ... ]\n",
    "    experiment_autocorrs = {}\n",
    "    # Liste globale de toutes les particules, toutes expériences confondues\n",
    "    all_autocorrs = []\n",
    "    \n",
    "    # Calcul de l'autocorrélation par particule\n",
    "    for (exp_name, particle_id), group in data.groupby(['experiment', 'particle']):\n",
    "        group = group.sort_values(by='frame')\n",
    "        \n",
    "        # Norme de la vitesse\n",
    "        v_t = np.sqrt(group['vx']**2 + group['vy']**2).values\n",
    "        \n",
    "        if len(v_t) < max_lag:\n",
    "            # Pas assez de points\n",
    "            continue\n",
    "        \n",
    "        # Calcul de l'autocorrélation pour tau = 1..max_lag\n",
    "        autocorr_values = []\n",
    "        for tau in range(1, max_lag + 1):\n",
    "            v_tau = np.roll(v_t, -tau)\n",
    "            valid_idx = np.arange(len(v_t)) < (len(v_t) - tau)\n",
    "            \n",
    "            numerator = np.mean(v_t[valid_idx] * v_tau[valid_idx])\n",
    "            denominator = np.mean(v_t[valid_idx]**2)\n",
    "            corr = numerator / denominator if denominator != 0 else np.nan\n",
    "            autocorr_values.append(corr)\n",
    "        \n",
    "        # Stocker dans experiment_autocorrs\n",
    "        if exp_name not in experiment_autocorrs:\n",
    "            experiment_autocorrs[exp_name] = []\n",
    "        experiment_autocorrs[exp_name].append(autocorr_values)\n",
    "        \n",
    "        # Stocker aussi dans la liste globale\n",
    "        all_autocorrs.append(autocorr_values)\n",
    "    \n",
    "    # Moyenne par expérience\n",
    "    experiment_mean_corr = {}\n",
    "    for exp_name, list_autocorrs in experiment_autocorrs.items():\n",
    "        arr = np.array(list_autocorrs)  # shape: (nb_particules, max_lag)\n",
    "        mean_by_lag = np.nanmean(arr, axis=0)\n",
    "        experiment_mean_corr[exp_name] = mean_by_lag\n",
    "    \n",
    "    # Moyenne globale (All) sur toutes les particules de TOUTES les expériences\n",
    "    if len(all_autocorrs) > 0:\n",
    "        arr_all = np.array(all_autocorrs)  # shape: (nb_total_particules, max_lag)\n",
    "        global_mean = np.nanmean(arr_all, axis=0)\n",
    "    else:\n",
    "        global_mean = np.full(shape=(max_lag,), fill_value=np.nan)\n",
    "    \n",
    "    # Construire le DataFrame final\n",
    "    lags_in_sec = np.arange(1, max_lag + 1) / fps\n",
    "    autocorr_df = pd.DataFrame(experiment_mean_corr, index=lags_in_sec)\n",
    "    autocorr_df.index.name = \"lag (s)\"\n",
    "    \n",
    "    # Ajouter la colonne 'All'\n",
    "    autocorr_df['All'] = global_mean\n",
    "    \n",
    "    return autocorr_df\n",
    "\n",
    "\n",
    "max_lag = 30\n",
    "fps = FPS  # par exemple\n",
    "\n",
    "autocorr_df = velocity_autocorrelation_by_experiment_and_global(DATA, max_lag, fps)\n",
    "\n",
    "# Création de la figure\n",
    "plt.figure()#figsize=(8, 5))\n",
    "\n",
    "# Tracé de \"All\" en bleu avec un style spécifique\n",
    "plt.plot(autocorr_df.index, autocorr_df[\"All\"], marker='o', linestyle='-', \n",
    "         label=\"All\", color=\"blue\", linewidth=2, alpha=1.0)\n",
    "\n",
    "# Tracé des expériences avec transparence et ligne fine\n",
    "for col in autocorr_df.columns:\n",
    "    if col != \"All\":  # On exclut \"All\"\n",
    "        plt.plot(autocorr_df.index, autocorr_df[col], marker='+', linestyle='-', \n",
    "                 alpha=0.5, linewidth=0.5, label=col)\n",
    "\n",
    "# Ajout de légende unique\n",
    "plt.legend(title=\"Expériences et All\", loc=\"upper right\")\n",
    "\n",
    "# Axes et titre\n",
    "plt.xlabel(\"Lag (s)\")\n",
    "plt.ylabel(\"Autocorrélation\")\n",
    "plt.title(\"Autocorrélation de la vitesse, par expérience et globale\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit exponnentiel de l'autocorrelation de la vitesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(t, A, tau_c):\n",
    "    \"\"\"\n",
    "    Modèle simple d'exponentielle décroissante pour l'autocorrélation.\n",
    "    f(t) = A * exp(-t / tau_c)\n",
    "    \"\"\"\n",
    "    return A * np.exp(-t / tau_c)\n",
    "\n",
    "def exponential_decay_offset(t, A, tau_c, B):\n",
    "    \"\"\"\n",
    "    Modèle exponentiel avec offset.\n",
    "    f(t) = A * exp(-t / tau_c) + B\n",
    "    \"\"\"\n",
    "    return A * np.exp(-t / tau_c) + B\n",
    "\n",
    "def fit_velocity_autocorrelation(xdata, ydata, model=exponential_decay_offset, p0=(1.0, 1.0, 0.1)):\n",
    "    \"\"\"\n",
    "    Ajuste la courbe d'autocorrélation de la vitesse à un modèle donné.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    xdata : array-like\n",
    "        Les temps (lags) en secondes.\n",
    "    ydata : array-like\n",
    "        Les valeurs d'autocorrélation correspondantes.\n",
    "    model : callable\n",
    "        Fonction du modèle f(t, *params). Par défaut : exponential_decay_offset.\n",
    "    p0 : tuple\n",
    "        Valeurs initiales pour le fit. Par défaut : (1.0, 1.0, 0.1).\n",
    "        Correspond ici aux 3 paramètres (A, tau_c, B).\n",
    "\n",
    "    Retourne\n",
    "    -------\n",
    "    popt : ndarray\n",
    "        Paramètres optimaux du fit (selon 'model').\n",
    "    pcov : 2D ndarray\n",
    "        Matrice de covariance estimée des paramètres du fit.\n",
    "    \"\"\"\n",
    "    popt, pcov = curve_fit(model, xdata, ydata, p0=p0)\n",
    "    return popt, pcov\n",
    "\n",
    "\n",
    "# On va fitter la colonne \"All\"\n",
    "xdata = autocorr_df.index.to_numpy()    # lags en secondes (ex: [0.1, 0.2, 0.3, ...])\n",
    "ydata = autocorr_df[\"All\"].values       # autocorrélation globale\n",
    "\n",
    "# Ajustement\n",
    "popt, pcov = fit_velocity_autocorrelation(\n",
    "    xdata, \n",
    "    ydata,\n",
    "    model=exponential_decay_offset, \n",
    "    p0=(1.0, 1.0, 0.1)  # initial guess\n",
    ")\n",
    "\n",
    "# Résultats\n",
    "A_opt, tau_c_opt, B_opt = popt\n",
    "print(f\"Paramètres optimaux : A = {A_opt:.3f}, tau_c = {tau_c_opt:.3f}, B = {B_opt:.3f}\")\n",
    "\n",
    "# Construction d'un vecteur de points pour tracer la fonction ajustée\n",
    "x_fit = np.linspace(xdata.min(), xdata.max(), 200)\n",
    "y_fit = exponential_decay_offset(x_fit, A_opt, tau_c_opt, B_opt)\n",
    "\n",
    "# Affichage\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(xdata, ydata, 'o', label=\"Autocorr (colonne 'All')\")\n",
    "plt.plot(x_fit, y_fit, '-', label=(\n",
    "    f\"Fit: A={A_opt:.3f}, tau_c={tau_c_opt:.3f}, B={B_opt:.3f}\")\n",
    ")\n",
    "plt.xlabel(\"Décalage temporel (s)\")\n",
    "plt.ylabel(\"Autocorrélation de la vitesse\")\n",
    "plt.title(\"Fit exponentiel de la courbe 'All'\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_exp_decay(t, C0, tau_c):\n",
    "    \"\"\"Modèle exponentiel simple\"\"\"\n",
    "    return C0 * np.exp(-t / tau_c)\n",
    "\n",
    "def double_exp_decay(t, C0, tau1, C1, tau2):\n",
    "    \"\"\"Modèle double exponentiel\"\"\"\n",
    "    return C0 * np.exp(-t / tau1) + C1 * np.exp(-t / tau2)\n",
    "\n",
    "def fit_exponential_decay(\n",
    "    autocorr_result,\n",
    "    max_lag,\n",
    "    fps,\n",
    "    use_double_exp=False,\n",
    "    cut_time=1.0,\n",
    "    p0_single=None,\n",
    "    p0_double=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Ajuste une décroissance exponentielle sur l'autocorrélation de la vitesse.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    autocorr_result : pd.DataFrame\n",
    "        DataFrame contenant l'autocorrélation moyenne par lag ('lag_1', 'lag_2', ...).\n",
    "        Il doit contenir une ligne 'mean' avec les valeurs moyennes.\n",
    "    max_lag : int\n",
    "        Nombre maximal de décalages temporels utilisés pour l'ajustement.\n",
    "    fps : float\n",
    "        Nombre d'images par seconde (convertit le lag en secondes).\n",
    "        Exemple : fps=10 => 10 images/s, fps=1/15 => 1 image/15s.\n",
    "    use_double_exp : bool\n",
    "        Si True, ajuste un modèle double exponentiel au lieu d'un simple exponentiel.\n",
    "    cut_time : float\n",
    "        Temps (en secondes) en-deçà duquel on effectue l'ajustement (filtre t < cut_time).\n",
    "        Si aucun lag n'est inférieur à cut_time, on ne filtre pas du tout.\n",
    "    p0_single : list ou tuple, optionnel\n",
    "        Valeurs initiales pour le fit simple exponentiel (C0, tau_c).\n",
    "    p0_double : list ou tuple, optionnel\n",
    "        Valeurs initiales pour le fit double exponentiel (C0, tau1, C1, tau2).\n",
    "    \n",
    "    Retourne\n",
    "    --------\n",
    "    popt : ndarray\n",
    "        Paramètres ajustés du modèle.\n",
    "    \"\"\"\n",
    "\n",
    "    # -- Vérification de la présence d'une ligne 'mean' --\n",
    "    if 'mean' not in autocorr_result.index:\n",
    "        raise KeyError(\"⚠️ La ligne 'mean' est absente de `autocorr_result`.\")\n",
    "\n",
    "    # -- Nombre de lags disponibles dans le DataFrame --\n",
    "    num_lags = len(autocorr_result.columns)\n",
    "    # On veille à ne pas dépasser max_lag\n",
    "    num_lags = min(num_lags, max_lag)\n",
    "\n",
    "    # -- Construction du vecteur de temps pour chaque lag (en s) --\n",
    "    #    lag 1 => t = 1/fps, lag 2 => t = 2/fps, etc.\n",
    "    lags = np.arange(1, num_lags + 1) / fps\n",
    "\n",
    "    # -- Récupération de l'autocorrélation moyenne --\n",
    "    autocorr_values = autocorr_result.loc['mean'].values[:num_lags]\n",
    "\n",
    "    # -- Application du filtre lags < cut_time (si pertinent) --\n",
    "    mask = (lags < cut_time)\n",
    "    if mask.sum() == 0:\n",
    "        # Si aucun lag n'est < cut_time, on ne filtre pas du tout\n",
    "        print(f\"⚠️ Aucun lag n'est < {cut_time}s. On utilise toutes les données pour le fit.\")\n",
    "        lags_fit = lags\n",
    "        autocorr_fit = autocorr_values\n",
    "    else:\n",
    "        lags_fit = lags[mask]\n",
    "        autocorr_fit = autocorr_values[mask]\n",
    "\n",
    "    # -- Ajustement par curve_fit --\n",
    "    #    On choisit des valeurs initiales adaptées au simple ou double exponentiel\n",
    "    if p0_single is None:\n",
    "        # p0_single par défaut\n",
    "        p0_single = [0.8, 1.0]    # Valeurs arbitraires : amplitude=0.8, tau=1s\n",
    "    if p0_double is None:\n",
    "        # p0_double par défaut\n",
    "        p0_double = [0.8, 1.0, 0.2, 5.0]  # Valeurs arbitraires\n",
    "\n",
    "    try:\n",
    "        if use_double_exp:\n",
    "            popt, _ = curve_fit(double_exp_decay, lags_fit, autocorr_fit, p0=p0_double)\n",
    "            model_label = (\n",
    "                f\"Ajustement double exp.\\n\"\n",
    "                f\"C0={popt[0]:.2f}, tau1={popt[1]:.2f} s, \"\n",
    "                f\"C1={popt[2]:.2f}, tau2={popt[3]:.2f} s\"\n",
    "            )\n",
    "        else:\n",
    "            popt, _ = curve_fit(single_exp_decay, lags_fit, autocorr_fit, p0=p0_single)\n",
    "            model_label = (\n",
    "                f\"Ajustement simple exp.\\n\"\n",
    "                f\"C0={popt[0]:.2f}, tau_c={popt[1]:.2f} s\"\n",
    "            )\n",
    "    except RuntimeError:\n",
    "        print(\"⚠️ Échec de l'ajustement exponentiel, vérifiez les données.\")\n",
    "        return None\n",
    "\n",
    "    # -- Affichage du résultat --\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(lags, autocorr_values, marker='o', label=\"Autocorrélation mesurée\")\n",
    "\n",
    "    # On définit t_fit sur toute la plage de lags (0 jusqu’à lags.max())\n",
    "    t_fit = np.linspace(0, lags.max(), 300)\n",
    "\n",
    "    # Calcul de la courbe en utilisant tous les paramètres optimaux\n",
    "    if use_double_exp:\n",
    "        plt.plot(t_fit, double_exp_decay(t_fit, *popt), linestyle=\"--\", label=model_label)\n",
    "    else:\n",
    "        plt.plot(t_fit, single_exp_decay(t_fit, *popt), linestyle=\"--\", label=model_label)\n",
    "\n",
    "    plt.xlabel(\"Décalage temporel (s)\")\n",
    "    plt.ylabel(\"Autocorrélation de la vitesse\")\n",
    "    plt.title(\"Autocorrélation avec ajustement exponentiel\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return popt\n",
    "\n",
    "# Définition des paramètres\n",
    "max_lag = 400  # Nombre de frames de décalage maximal\n",
    "\n",
    "# Ajustement exponentiel simple\n",
    "# Ajustement double exponentiel\n",
    "popt_double = fit_exponential_decay(\n",
    "    autocorr_result,\n",
    "    max_lag=max_lag,\n",
    "    fps=FPS,\n",
    "    use_double_exp=True,\n",
    "    cut_time=200,\n",
    "    p0_double=[0.5, 30.0, 0.3, 100.0]  # exemple\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><span style=\"color: skyblue; font-size: 20px\"> Mean speed vs time to incubation </span></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_speed_with_sup_inf(all_metrics_df, path_save_pic, xlim: list = None):\n",
    "    \"\"\"\n",
    "    Plot mean speed, mean speed sup, and mean speed inf as a function of incubation time\n",
    "    on the same graph.\n",
    "\n",
    "    Parameters:\n",
    "    - all_metrics_df (DataFrame): DataFrame containing aggregated metrics for each experiment.\n",
    "                                  Must include columns: 'time to incubation (hours)',\n",
    "                                  'mean_speed [um/min]', 'mean_speed_sup [um/min]', \n",
    "                                  and 'mean_speed_inf [um/min]'.\n",
    "    - path_save_pic (str): Path where the plot will be saved.\n",
    "    - xlim (list, optional): Limit for the x-axis.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Trier les données par temps d'incubation\n",
    "    all_metrics_sorted = all_metrics_df.sort_values(by='time to incubation (hours)')\n",
    "\n",
    "    # Préparer le tracé\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Courbe pour la vitesse moyenne totale\n",
    "    plt.plot(\n",
    "        all_metrics_sorted['time to incubation (hours)'],\n",
    "        all_metrics_sorted['mean_speed [um/min]'],\n",
    "        linestyle='--', color='green', alpha=0.6,\n",
    "        label='Mean Speed (Total)'\n",
    "    )\n",
    "\n",
    "    # Courbe pour les particules sup\n",
    "    plt.plot(\n",
    "        all_metrics_sorted['time to incubation (hours)'],\n",
    "        all_metrics_sorted['mean_speed_sup [um/min]'],\n",
    "        linestyle='--', color='blue', alpha=0.6,\n",
    "        label='Mean Speed (Sup)'\n",
    "    )\n",
    "\n",
    "    # Courbe pour les particules inf\n",
    "    plt.plot(\n",
    "        all_metrics_sorted['time to incubation (hours)'],\n",
    "        all_metrics_sorted['mean_speed_inf [um/min]'],\n",
    "        linestyle='--', color='red', alpha=0.6,\n",
    "        label='Mean Speed (Inf)'\n",
    "    )\n",
    "\n",
    "    # Ajouter des labels et des titres\n",
    "    plt.title('Mean Speed vs. Time to Incubation (Total, Sup, Inf)', fontsize=14)\n",
    "    plt.xlabel('Time to Incubation (hours)', fontsize=12)\n",
    "    plt.ylabel('Mean Speed [μm/min]', fontsize=12)\n",
    "    plt.ylim([0, 15])  # Limites pour l'axe des y\n",
    "    if xlim:\n",
    "        plt.xlim(xlim)  # Limites pour l'axe des x (optionnel)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend(fontsize=10)\n",
    "\n",
    "    # Sauvegarder et afficher\n",
    "    plt.tight_layout()\n",
    "    fig_path = os.path.join(path_save_pic, 'Mean_Speed_vs_Time_Sup_Inf.png')\n",
    "    plt.savefig(fig_path, format='png')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Plot saved to {fig_path}\")\n",
    "\n",
    "# Exemple d'appel de la fonction\n",
    "plot_mean_speed_with_sup_inf(all_metrics_df, path_save_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_median_velocity_vs_time(all_metrics_df, path_save_pic, xlim: list = None):\n",
    "    \"\"\"\n",
    "    Plot median velocities as a function of incubation time using all_metrics_df.\n",
    "    Adds a trendline with a transparent error band to the data.\n",
    "\n",
    "    Parameters:\n",
    "    - all_metrics_df (DataFrame): DataFrame containing aggregated metrics for each experiment.\n",
    "    - path_save_pic (str): Path where the plot will be saved.\n",
    "    - xlim (list, optional): Limit for the x-axis.\n",
    "    \"\"\"\n",
    "    # Trier les données par temps d'incubation\n",
    "    all_metrics_sorted = all_metrics_df.sort_values(by='time to incubation (hours)')\n",
    "\n",
    "    # Extraire les données\n",
    "    x = all_metrics_sorted['time to incubation (hours)'].values\n",
    "    y = all_metrics_sorted['mean_speed [um/min]'].values\n",
    "\n",
    "    # Préparer le tracé\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(x, y, color='forestgreen', label='Médiane')  # Points\n",
    "    plt.plot(x, y, linestyle='--', color='limegreen', alpha=0.6)  # Ligne connectant les points\n",
    "\n",
    "    # Régression linéaire (y = ax + b)\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "    trendline = slope * x + intercept\n",
    "\n",
    "    # Calcul de la zone d'erreur\n",
    "    error_band = 100*std_err * np.sqrt(1 / len(x) + (x - np.mean(x))**2 / np.sum((x - np.mean(x))**2))\n",
    "    # Ajouter la ligne de tendance\n",
    "    plt.plot(x, trendline, color='red', label=f\"Tendance (y = {slope:.2f}x + {intercept:.2f})\", linestyle='-', linewidth=1.5)\n",
    "\n",
    "    # Ajouter l'aire d'erreur\n",
    "    plt.fill_between(x, trendline - error_band, trendline + error_band, color='red', alpha=0.2, label=\"Marge d'erreur\")\n",
    "\n",
    "    # Ajouter des labels et des titres\n",
    "    plt.title('Mean Speed vs. Time to Incubation', fontsize=14)\n",
    "    plt.xlabel('Time to Incubation (hours)', fontsize=12)\n",
    "    plt.ylabel('Mean Speed [μm/min]', fontsize=12)\n",
    "    plt.ylim([0, 15])\n",
    "    if xlim:\n",
    "        plt.xlim(xlim)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend(fontsize=10)\n",
    "\n",
    "    # Sauvegarder et afficher\n",
    "    plt.tight_layout()\n",
    "    fig_path = os.path.join(path_save_pic, 'Mean_Speed_vs_Time_with_Trendline_and_ErrorBand.png')\n",
    "    plt.savefig(fig_path, format='png')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Plot saved to {fig_path}\")\n",
    "\n",
    "#utilisation\n",
    "plot_median_velocity_vs_time(all_metrics_df, path_save_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_median_velocity_vs_time(all_metrics_df, path_save_pic, xlim: list = None):\n",
    "    \"\"\"\n",
    "    Plot median velocities as a function of incubation time using all_metrics_df.\n",
    "\n",
    "    Parameters:\n",
    "    - all_metrics_df (DataFrame): DataFrame containing aggregated metrics for each experiment.\n",
    "    - path_save_pic (str): Path where the plot will be saved.\n",
    "    \"\"\"\n",
    "    # Trier les données par temps d'incubation\n",
    "    all_metrics_sorted = all_metrics_df.sort_values(by='time to incubation (hours)')\n",
    "\n",
    "    # Préparer le tracé\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(all_metrics_sorted['time to incubation (hours)'], \n",
    "                all_metrics_sorted['mean_speed [um/min]'],  # Correction de la colonne utilisée\n",
    "                color='forestgreen', label='Médiane')\n",
    "    plt.plot(all_metrics_sorted['time to incubation (hours)'], \n",
    "             all_metrics_sorted['mean_speed [um/min]'],  # Correction de la colonne utilisée\n",
    "             linestyle='--', color='limegreen', alpha=0.6)\n",
    "\n",
    "    # Ajouter des labels et des titres\n",
    "    plt.title('Mean Speed vs. Time to Incubation', fontsize=14)\n",
    "    plt.xlabel('Time to Incubation (hours)', fontsize=12)\n",
    "    plt.ylim([0, 15])\n",
    "    plt.ylabel('Mean Speed [μm/min]', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Sauvegarder et afficher\n",
    "    plt.tight_layout()\n",
    "    fig_path = os.path.join(path_save_pic, 'Mean_Speed_vs_Time.png')\n",
    "    plt.savefig(fig_path, format='png')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Plot saved to {fig_path}\")\n",
    "\n",
    "# Appel de la fonction corrigée\n",
    "plot_median_velocity_vs_time(all_metrics_df, path_save_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_proportion_vs_time(all_metrics_df, path_save_pic, img_type):\n",
    "    \"\"\"\n",
    "    Plot the proportion of low coefficient particles (proportion_inf) vs. time to incubation.\n",
    "\n",
    "    Parameters:\n",
    "    - all_metrics_df (DataFrame): DataFrame containing aggregated metrics for each experiment.\n",
    "    - path_save_pic (str): Path where the plot will be saved.\n",
    "    - img_type (str): Image format for saving the plot.\n",
    "    \"\"\"\n",
    "    # Trier les données par temps d'incubation\n",
    "    all_metrics_sorted = all_metrics_df.sort_values(by='time to incubation (hours)')\n",
    "\n",
    "    # Préparer le tracé\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(all_metrics_sorted['time to incubation (hours)'], \n",
    "                all_metrics_sorted['proportion_inf'], \n",
    "                color='red', marker='+', label='Proportion inf')\n",
    "    \n",
    "    # Ajouter des titres et des labels\n",
    "    plt.title('Proportion of Low Coefficient Particles vs. Time to Incubation', fontsize=14)\n",
    "    plt.xlabel('Time to Incubation (hours)', fontsize=12)\n",
    "    plt.ylabel('Proportion of Low Coefficient Particles', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Ajuster et sauvegarder\n",
    "    plt.tight_layout()\n",
    "    fig_path = os.path.join(path_save_pic, f'Proportion_Low_Coeff_Particles_vs_Time.{img_type}')\n",
    "    plt.savefig(fig_path, format=img_type)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Plot saved to {fig_path}\")\n",
    "\n",
    "# Appel de la fonction\n",
    "plot_proportion_vs_time(all_metrics_df, path_save_pic, IMG_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_proportion_per_time_bins(all_metrics_df, path_save_pic, img_type):\n",
    "    \"\"\"\n",
    "    Plot proportions of particles (Inf and Sup) per incubation time bins.\n",
    "\n",
    "    Parameters:\n",
    "    - all_metrics_df (DataFrame): DataFrame containing aggregated metrics for each experiment.\n",
    "    - path_save_pic (str): Path where the plot will be saved.\n",
    "    - img_type (str): Image format for saving the plot.\n",
    "    \"\"\"\n",
    "    # Définir les intervalles de temps d'incubation\n",
    "    bins = np.arange(0, all_metrics_df['time to incubation (hours)'].max() + 10, 10)\n",
    "    labels = [f\"{int(left)}-{int(right)}\" for left, right in zip(bins[:-1], bins[1:])]\n",
    "    all_metrics_df['time_bin'] = pd.cut(all_metrics_df['time to incubation (hours)'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "    # Calculer les proportions moyennes pour chaque bin\n",
    "    proportion_per_bin_inf = all_metrics_df.groupby('time_bin')['proportion_inf'].mean()\n",
    "    proportion_per_bin_sup = 1 - proportion_per_bin_inf\n",
    "\n",
    "    # Configuration des barres pour le tracé\n",
    "    x = np.arange(len(proportion_per_bin_inf))\n",
    "    width = 0.35\n",
    "\n",
    "    # Tracé des proportions\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.bar(x - width/2, proportion_per_bin_inf, width, color='red', alpha=0.7, label='Proportion Inf')\n",
    "    ax.bar(x + width/2, proportion_per_bin_sup, width, color='blue', alpha=0.7, label='Proportion Sup')\n",
    "    ax.set_title('Proportion of Particles per Incubation Time Bin', fontsize=14)\n",
    "    ax.set_xlabel('Incubation Time Bin (hours)', fontsize=12)\n",
    "    ax.set_ylabel('Average Proportion of Particles', fontsize=12)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels, rotation=45)\n",
    "    ax.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Sauvegarder et afficher le graphique\n",
    "    plt.tight_layout()\n",
    "    fig_path = os.path.join(path_save_pic, f'Proportion_vs_Time_Bins.{img_type}')\n",
    "    plt.savefig(fig_path, format=img_type)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Plot saved to {fig_path}\")\n",
    "\n",
    "# Appel de la fonction\n",
    "plot_proportion_per_time_bins(all_metrics_df, path_save_pic, IMG_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot displacement comparison between low and high coefficient particles\n",
    "lib.plot_displacement_low_and_high(\n",
    "    traj_sup=df_sup,\n",
    "    traj_inf=df_inf,\n",
    "    part_coef_inf=PART_COEF_INF,\n",
    "    part_coef_sup=PART_COEF_SUP,\n",
    "    start_end=start_end,\n",
    "    save=True,\n",
    "    pathway_saving=path_save_pic,\n",
    "    name=\"displacement_start-end_time\",\n",
    "    img_type=IMG_TYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_displacement_from_start(traj, size_pix):\n",
    "    \"\"\"\n",
    "    Calcule la distance maximale entre le point de départ et toutes les positions\n",
    "    atteintes par chaque particule.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : pandas.DataFrame\n",
    "        Trajectoire des particules avec colonnes 'x', 'y', 'particle'.\n",
    "    size_pix : float\n",
    "        Taille d'un pixel en micromètres.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    max_displacements : pandas.Series\n",
    "        Distance maximale pour chaque particule.\n",
    "    \"\"\"\n",
    "    # Identifier les coordonnées de départ pour chaque particule\n",
    "    start_positions = traj.groupby('particle')[['x', 'y']].first()\n",
    "\n",
    "    # Ajouter les coordonnées de départ au DataFrame\n",
    "    traj = traj.join(start_positions, on='particle', rsuffix='_start')\n",
    "\n",
    "    # Calculer les distances à partir du point de départ\n",
    "    traj['distance_from_start [um]'] = size_pix * np.sqrt(\n",
    "        (traj['x'] - traj['x_start'])**2 + \n",
    "        (traj['y'] - traj['y_start'])**2\n",
    "    )\n",
    "\n",
    "    # Trouver la distance maximale pour chaque particule\n",
    "    max_displacements = traj.groupby('particle')['distance_from_start [um]'].max()\n",
    "\n",
    "    return max_displacements\n",
    "\n",
    "# Calcul des distances maximales\n",
    "max_distances = max_displacement_from_start(DATA, size_pix=SIZE_PIX)\n",
    "\n",
    "# Filtrage des particules appartenant à PART_COEF_INF et PART_COEF_SUP\n",
    "distances_part_coef_inf = max_distances[max_distances.index.isin(PART_COEF_INF)]\n",
    "distances_part_coef_sup = max_distances[max_distances.index.isin(PART_COEF_SUP)]\n",
    "\n",
    "# Tracer les deux histogrammes sur le même graphique\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(distances_part_coef_inf, bins=100, color='red', alpha=0.5, label='PART_COEF_INF')\n",
    "plt.hist(distances_part_coef_sup, bins=100, color='blue', alpha=0.5, label='PART_COEF_SUP')\n",
    "plt.title('Histogramme des distances maximales par catégorie', fontsize=16)\n",
    "plt.xlabel('Distance maximale [μm]', fontsize=14)\n",
    "plt.ylabel('Nombre de particules', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_size_histograms(DATA, PART_COEF_SUP, save=False, pathway_saving=None, img_type=\"png\"):\n",
    "    \"\"\"\n",
    "    Trace un histogramme des tailles des particules par expérience sur une seule figure,\n",
    "    avec un subplot par expérience.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    DATA : pandas.DataFrame\n",
    "        Contient les colonnes 'experiment', 'particle', et 'size'.\n",
    "    PART_COEF_SUP : set\n",
    "        Ensemble des particules appartenant à PART_COEF_SUP (bleu).\n",
    "    save : bool, optional\n",
    "        Si True, sauvegarde les plots.\n",
    "    pathway_saving : str, optional\n",
    "        Chemin pour sauvegarder les plots si save=True.\n",
    "    img_type : str, optional\n",
    "        Format d'image pour la sauvegarde (png, jpg, etc.).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Vérifier si les colonnes nécessaires sont présentes\n",
    "    if not all(col in DATA.columns for col in ['experiment', 'particle', 'size']):\n",
    "        raise ValueError(\"Les colonnes 'experiment', 'particle', et 'size' doivent être présentes dans DATA.\")\n",
    "    \n",
    "    # Obtenir la liste unique des expériences\n",
    "    experiments = DATA['experiment'].unique()\n",
    "    n_experiments = len(experiments)\n",
    "\n",
    "    # Calculer le nombre de lignes et colonnes pour les subplots\n",
    "    n_cols = 3  # Fixé pour avoir 3 colonnes\n",
    "    n_rows = math.ceil(n_experiments / n_cols)\n",
    "\n",
    "    # Création de la figure\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n",
    "    axes = axes.flatten()  # Convertir les axes en tableau 1D pour itération facile\n",
    "\n",
    "    for i, experiment in enumerate(experiments):\n",
    "        # Filtrer les données pour l'expérience courante\n",
    "        exp_data = DATA[DATA['experiment'] == experiment]\n",
    "\n",
    "        # Séparer les tailles en deux catégories\n",
    "        sizes_sup = exp_data[exp_data['particle'].isin(PART_COEF_SUP)]['ecc']\n",
    "        sizes_other = exp_data[~exp_data['particle'].isin(PART_COEF_SUP)]['ecc']\n",
    "\n",
    "        # Histogramme dans le subplot correspondant\n",
    "        ax = axes[i]\n",
    "        ax.hist(sizes_sup, bins=20, alpha=0.7, color='blue', label=\"PART_COEF_SUP\")\n",
    "        ax.hist(sizes_other, bins=20, alpha=0.7, color='red', label=\"Autres\")\n",
    "\n",
    "        ax.set_title(f\"Expérience : {experiment}\", fontsize=12)\n",
    "        ax.set_xlabel(\"Taille\", fontsize=10)\n",
    "        ax.set_ylabel(\"Nombre\", fontsize=10)\n",
    "        ax.legend(fontsize=9)\n",
    "        ax.grid(alpha=0.4)\n",
    "\n",
    "    # Supprimer les axes inutilisés\n",
    "    for j in range(len(experiments), len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # Ajuster les espaces entre subplots\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Sauvegarder ou afficher\n",
    "    if save and pathway_saving:\n",
    "        filename = f\"{pathway_saving}/size_histograms.{img_type}\"\n",
    "        plt.savefig(filename, format=img_type, bbox_inches=\"tight\")\n",
    "        print(f\"Figure sauvegardée : {filename}\")\n",
    "    plt.show()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "plot_size_histograms(\n",
    "    DATA=DATA,\n",
    "    PART_COEF_SUP=PART_COEF_SUP,\n",
    "    save=False,\n",
    "    pathway_saving=None,\n",
    "    img_type=\"png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_speed_vs_density(all_metrics_df, save=False, pathway_saving=None, img_type=\"png\"):\n",
    "    \"\"\"\n",
    "    Trace la vitesse moyenne des particules en fonction de la densité cellulaire,\n",
    "    en utilisant uniquement Matplotlib et des croix pour les points.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_metrics_df : pandas.DataFrame\n",
    "        Contient les colonnes 'mean_speed [um/min]' et 'nombre_part_par_champs'.\n",
    "    save : bool, optional\n",
    "        Si True, sauvegarde le graphique.\n",
    "    pathway_saving : str, optional\n",
    "        Chemin pour sauvegarder le graphique si save=True.\n",
    "    img_type : str, optional\n",
    "        Format d'image pour la sauvegarde (png, jpg, etc.).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Vérification des colonnes nécessaires\n",
    "    if not all(col in all_metrics_df.columns for col in ['mean_speed [um/min]', 'nombre_part_par_champs']):\n",
    "        raise ValueError(\"Les colonnes 'mean_speed [um/min]' et 'nombre_part_par_champs' doivent être présentes dans all_metrics_df.\")\n",
    "    \n",
    "    # Créer le graphique\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = plt.gca()  # Récupérer les axes actuels avec le style Matplotlib\n",
    "\n",
    "    # Tracé des points avec des croix\n",
    "    ax.scatter(\n",
    "        all_metrics_df['nombre_part_par_champs'],\n",
    "        all_metrics_df['mean_speed [um/min]'],\n",
    "        s=100,  # Taille des symboles\n",
    "        alpha=0.7,\n",
    "        color='#1f77b4',  # Couleur compatible avec axes.prop_cycle\n",
    "        marker='+',  # Utiliser des croix\n",
    "        label=\"Points\"\n",
    "    )\n",
    "\n",
    "    # Régression linéaire\n",
    "    x = all_metrics_df['nombre_part_par_champs']\n",
    "    y = all_metrics_df['mean_speed [um/min]']\n",
    "    coeffs = np.polyfit(x, y, 1)  # Ajustement linéaire\n",
    "    y_fit = np.polyval(coeffs, x)\n",
    "    ax.plot(x, y_fit, color='#ff7f0e', label=\"Régression linéaire\")  # Ligne de tendance\n",
    "\n",
    "    # Titre et axes\n",
    "    ax.set_title(\"Vitesse moyenne vs Densité cellulaire\", fontsize=16, color='white')\n",
    "    ax.set_xlabel(\"Nombre de particules par champ\", fontsize=14, color='white')\n",
    "    ax.set_ylabel(\"Vitesse moyenne [µm/min]\", fontsize=14, color='white')\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.grid(alpha=0.4)\n",
    "\n",
    "    # Sauvegarder ou afficher\n",
    "    if save and pathway_saving:\n",
    "        filename = f\"{pathway_saving}/mean_speed_vs_density.{img_type}\"\n",
    "        plt.savefig(filename, format=img_type, bbox_inches=\"tight\", facecolor=plt.rcParams[\"figure.facecolor\"])\n",
    "        print(f\"Graphique sauvegardé : {filename}\")\n",
    "    plt.show()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "plot_speed_vs_density(\n",
    "    all_metrics_df=all_metrics_df,\n",
    "    save=False,\n",
    "    pathway_saving=None,\n",
    "    img_type=\"png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_speed_vs_density(all_metrics_df, save=False, pathway_saving=None, img_type=\"png\"):\n",
    "    \"\"\"\n",
    "    Trace la vitesse moyenne des particules en fonction de la densité cellulaire,\n",
    "    en respectant les paramètres Matplotlib globaux.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_metrics_df : pandas.DataFrame\n",
    "        Contient les colonnes 'mean_speed [um/min]' et 'nombre_part_par_champs'.\n",
    "    save : bool, optional\n",
    "        Si True, sauvegarde le graphique.\n",
    "    pathway_saving : str, optional\n",
    "        Chemin pour sauvegarder le graphique si save=True.\n",
    "    img_type : str, optional\n",
    "        Format d'image pour la sauvegarde (png, jpg, etc.).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Vérification des colonnes nécessaires\n",
    "    if not all(col in all_metrics_df.columns for col in ['mean_speed [um/min]', 'nombre_part_par_champs']):\n",
    "        raise ValueError(\"Les colonnes 'mean_speed [um/min]' et 'nombre_part_par_champs' doivent être présentes dans all_metrics_df.\")\n",
    "    \n",
    "    # Désactiver le style Seaborn pour respecter Matplotlib\n",
    "    sns.set_theme(style=None)\n",
    "\n",
    "    # Créer le graphique\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = plt.gca()  # Récupérer les axes actuels avec le style Matplotlib\n",
    "\n",
    "    # Tracé des points avec scatterplot\n",
    "    sns.scatterplot(\n",
    "        x='nombre_part_par_champs',\n",
    "        y='mean_speed [um/min]',\n",
    "        data=all_metrics_df,\n",
    "        s=100,  # Taille des points\n",
    "        alpha=0.7,\n",
    "        color='#1f77b4',  # Couleur compatible avec axes.prop_cycle\n",
    "        edgecolor='white'\n",
    "    )\n",
    "\n",
    "    # Ajouter une ligne de tendance avec régression\n",
    "    sns.regplot(\n",
    "        x='nombre_part_par_champs',\n",
    "        y='mean_speed [um/min]',\n",
    "        data=all_metrics_df,\n",
    "        scatter=False,\n",
    "        color='#ff7f0e',  # Deuxième couleur du cycle\n",
    "        line_kws={'label': \"Régression linéaire\"}\n",
    "    )\n",
    "\n",
    "    # Titre et axes\n",
    "    ax.set_title(\"Vitesse moyenne vs Densité cellulaire\", fontsize=16, color='white')\n",
    "    ax.set_xlabel(\"Nombre de particules par champ\", fontsize=14, color='white')\n",
    "    ax.set_ylabel(\"Vitesse moyenne [µm/min]\", fontsize=14, color='white')\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.grid(alpha=0.4)\n",
    "\n",
    "    # Sauvegarder ou afficher\n",
    "    if save and pathway_saving:\n",
    "        filename = f\"{pathway_saving}/mean_speed_vs_density.{img_type}\"\n",
    "        plt.savefig(filename, format=img_type, bbox_inches=\"tight\", facecolor=plt.rcParams[\"figure.facecolor\"])\n",
    "        print(f\"Graphique sauvegardé : {filename}\")\n",
    "    plt.show()\n",
    "\n",
    "# utilisation\n",
    "plot_speed_vs_density(\n",
    "    all_metrics_df=all_metrics_df,\n",
    "    save=False,\n",
    "    pathway_saving=None,\n",
    "    img_type=\"png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_condition_and_save_hdf5(data, condition, name, save_path):\n",
    "    \"\"\"\n",
    "    Ajoute une colonne 'condition' à DATA et sauvegarde le DataFrame au format HDF5.\n",
    "\n",
    "    Parameters:\n",
    "    - DATA (pd.DataFrame): DataFrame auquel ajouter la colonne.\n",
    "    - CONDITION_simple (str): Valeur à ajouter dans la colonne 'condition'.\n",
    "    - save_path (str): Chemin pour sauvegarder le fichier HDF5.\n",
    "    -name (str): détail du fichier enregistré\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Ajouter la colonne 'condition'\n",
    "    data['condition'] = condition\n",
    "\n",
    "    # Vérifier si le DataFrame est non vide\n",
    "    if data.empty:\n",
    "        raise ValueError(\"Le DataFrame est vide, aucune donnée à sauvegarder.\")\n",
    "\n",
    "    # Sauvegarder au format HDF5\n",
    "    data.to_hdf(save_path + condition + f\"_{name}.hdf5\", key='DATA', mode='w', format='table')\n",
    "    print(f\"DataFrame {name} sauvegardé avec la colonne 'condition' à l'emplacement : {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_condition_and_save_hdf5(data=DATA, condition=CONDITION_simple, name=\"data\", save_path=\"/Users/souchaud/Desktop/Analyses/tables_resultats/\")\n",
    "add_condition_and_save_hdf5(data=all_metrics_df, condition=CONDITION_simple, name=\"all_metrics\", save_path=\"/Users/souchaud/Desktop/Analyses/tables_resultats/\")\n",
    "add_condition_and_save_hdf5(data=metrics_df, condition=CONDITION_simple, name=\"metrics\", save_path=\"/Users/souchaud/Desktop/Analyses/tables_resultats/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(PART_COEF_INF)/(len(PART_COEF_INF)+len(PART_COEF_SUP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(PART_COEF_SUP)/(len(PART_COEF_INF)+len(PART_COEF_SUP))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracking_and_analyse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
