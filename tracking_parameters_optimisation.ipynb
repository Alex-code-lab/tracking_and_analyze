{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Aug 21 10:51:23 2023\n",
    "\n",
    "@author: souchaud\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import trackpy as tp\n",
    "from tqdm import tqdm\n",
    "# import functions_track_and_analyze as lib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import util\n",
    "# from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidated parameters\n",
    "PARAMS = {\n",
    "        'diameter': 27,  # 15,\n",
    "        'minmass': 25,\n",
    "        'max_size': 25,\n",
    "        'separation': 5,\n",
    "        'noise_size': 7,  # 7, # 7,\n",
    "        'smoothing_size':None,\n",
    "        'invert': False,\n",
    "        'percentile': 10, #10,\n",
    "        'topn': None,\n",
    "        'preprocess': True,\n",
    "        'max_iterations': 25,\n",
    "        'filter_before': None,\n",
    "        'filter_after': None,\n",
    "        'characterize': True,\n",
    "        'engine': 'auto',\n",
    "        'threshold': 10,  # 40,\n",
    "        'min_frames': 200,\n",
    "        'max_displacement': 35, # 25, \n",
    "        'memory': 15,\n",
    "        'search_range': 30, #  20\n",
    "        'frame_interval': 15,\n",
    "        'pixel_size': 0.637,  # 1.2773,\n",
    "        'remove_exts': ['.jpg', '.svg', 'hdf5', '.png'],\n",
    "        'long_time': False,\n",
    "        'max_frame': 340,\n",
    "        'data_dir': '/Users/souchaud/Desktop/A_Analyser/CytoOne_HL5_10x/',\n",
    "        # 'data_dir': '/Volumes/Labo_Alex_Mac/A_analyser/CytoOne_HL5/',\n",
    "        # 'data_dir': '/Users/souchaud/Desktop/A_Analyser/NonT_SorC/',\n",
    "        # 'output_dir': '/Users/souchaud/Desktop/Analyses/CytoOne_HL5_longtime/'\n",
    "        # 'data_dir': '/Volumes/Labo_Alex_Mac/A_analyser/CytoOne_HL5/',´\n",
    "        'output_dir': '/Users/souchaud/Desktop/Analyses/CytoOne_HL5_10x_new_param/'\n",
    "        # 'output_dir': '/Users/souchaud/Desktop/Analyses/NonT_SorC_longtime_New/'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023_12_07_ASMOT110_AX3_P0_x10_15x_CytoOne_HL5/mosaic/']\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAMES = [f + '/mosaic/' for f in os.listdir(PARAMS['data_dir'])\n",
    "                    if os.path.isdir(os.path.join(PARAMS['data_dir'], f))]\n",
    "print(EXPERIMENT_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_speed(filtered):\n",
    "    \"\"\"\n",
    "    Compute mean speed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - filtered: DataFrame with tracked cells\n",
    "    Returns\n",
    "    - mean_speed: Mean speed of all particles\n",
    "    - mean_speed_part: Mean speed per particle\n",
    "    \"\"\"\n",
    "    dx = filtered.groupby('particle')['x'].diff()\n",
    "    dy = filtered.groupby('particle')['y'].diff()\n",
    "    displacement = np.sqrt(dx**2 + dy**2)\n",
    "    duration = filtered.groupby('particle')['frame'].diff() * PARAMS['frame_interval']\n",
    "    mean_speed = (displacement.sum() / duration.sum()) * PARAMS['pixel_size'] * 60\n",
    "    instant_speed = displacement / duration\n",
    "    mean_speed_part = instant_speed.groupby(filtered['particle']).mean() * PARAMS['pixel_size'] * 60\n",
    "    return mean_speed, mean_speed_part\n",
    "\n",
    "\n",
    "def clean_directory(dir_path):\n",
    "    \"\"\"Remove all files with the specified extensions in the directory.\"\"\"\n",
    "    for file in os.listdir(dir_path):\n",
    "        if file.endswith(tuple(PARAMS['remove_exts'])):\n",
    "            os.remove(os.path.join(dir_path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_brightness_contrast(img, brightness=0, contrast=0):\n",
    "    \"\"\" Ajuster la luminosité et le contraste d'une image \"\"\"\n",
    "    B = brightness / 100.0\n",
    "    C = contrast / 100.0\n",
    "    k = np.tan((45 + 44 * C) / 180 * np.pi)\n",
    "\n",
    "    img = (img - 127.5 * (1 - B)) * k + 127.5 * (1 + B)\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_experiment(exp_name, PARAMS):\n",
    "    \"\"\"Process a single experiment.\"\"\"\n",
    "    output_path = os.path.join(PARAMS['output_dir'], exp_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    clean_directory(output_path)\n",
    "\n",
    "    experiment_data_dir = os.path.join(PARAMS['data_dir'], exp_name)\n",
    "\n",
    "    def extract_number(filename):\n",
    "        # Extrait le numéro à partir du nom de fichier\n",
    "        base_name = os.path.basename(filename)\n",
    "        # Supprime l'extension et extrait le numéro\n",
    "        number = int(base_name.split('_')[-1].split('.')[0])\n",
    "        return number\n",
    "\n",
    "    tiff_files = sorted(glob.glob(os.path.join(experiment_data_dir, \"*.tif\")), key=extract_number)\n",
    "\n",
    "    # Use PARAMS dictionary to get the parameters\n",
    "    frame_data = []\n",
    "    frame_counter = 0\n",
    "    boucle = []\n",
    "    if PARAMS['long_time'] is False:\n",
    "        if len(os.listdir(experiment_data_dir)) < PARAMS['max_frame']:\n",
    "            nbr_frame_study_total = len(os.listdir(experiment_data_dir))\n",
    "        else:\n",
    "            nbr_frame_study_total = PARAMS['max_frame']\n",
    "    else:\n",
    "        nbr_frame_study_total = len(os.listdir(experiment_data_dir))\n",
    "\n",
    "    if nbr_frame_study_total > 150:\n",
    "        number = 150\n",
    "        while number < nbr_frame_study_total:\n",
    "            boucle.append(150)\n",
    "            number += 150\n",
    "            if number > nbr_frame_study_total:\n",
    "                boucle.append(nbr_frame_study_total - len(boucle) * 150)\n",
    "        nbr_frame_study = 150\n",
    "    else:\n",
    "        nbr_frame_study = nbr_frame_study_total\n",
    "        boucle.append(nbr_frame_study)\n",
    "\n",
    "    # Process each batch of frames\n",
    "    import time\n",
    "    for i in tqdm(boucle, desc=\"processing batches\"):\n",
    "        batch_frames = tiff_files[frame_counter:frame_counter + i]\n",
    "        batch_data = [np.array(imageio.imread(tiff_file)) for tiff_file in batch_frames]\n",
    "        time_count = time.time()\n",
    "\n",
    "        # luminosity = []\n",
    "        # for num, frame in enumerate(batch_data):\n",
    "        #     luminosity.append(np.mean(frame))\n",
    "        # # Calculer la luminosité moyenne sur l'ensemble du film\n",
    "        # average_luminosity = np.mean(luminosity)\n",
    "\n",
    "        for num, frame in enumerate(batch_data):\n",
    "            frame = util.invert(frame)\n",
    "            # Create a CLAHE object (Arguments are optional)\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(10, 10))\n",
    "            # Apply CLAHE\n",
    "            frame = clahe.apply(frame)\n",
    "            \n",
    "            # Appliquer un filtre Gaussien\n",
    "            frame = cv2.GaussianBlur(frame, (5, 5), 0)  # Modifier (5, 5) et 0 selon les besoins\n",
    "\n",
    "            # current_luminosity = np.mean(frame)\n",
    "            # # Calculer l'ajustement nécessaire\n",
    "            # brightness_adjustment = (average_luminosity - current_luminosity) * 100 / 255\n",
    "            # frame = adjust_brightness_contrast(frame, brightness=brightness_adjustment)\n",
    "    \n",
    "            \n",
    "\n",
    "            batch_data[num] = frame\n",
    "\n",
    "            if num == 0:\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                plt.imshow(frame, cmap='gray')\n",
    "                plt.show()\n",
    "\n",
    "                f = tp.locate(frame,\n",
    "                              diameter=PARAMS['diameter'],\n",
    "                              minmass=PARAMS['minmass'],\n",
    "                              maxsize=PARAMS['max_size'],\n",
    "                              separation=PARAMS['separation'],\n",
    "                              noise_size=PARAMS['noise_size'],\n",
    "                              smoothing_size=PARAMS['smoothing_size'],\n",
    "                              threshold=PARAMS['threshold'],\n",
    "                              invert=PARAMS['invert'],\n",
    "                              percentile=PARAMS['percentile'],\n",
    "                              topn=PARAMS['topn'],\n",
    "                              preprocess=PARAMS['preprocess'],\n",
    "                              max_iterations=PARAMS['max_iterations'],\n",
    "                              filter_before=PARAMS['filter_before'],\n",
    "                              filter_after=PARAMS['filter_after'],\n",
    "                              characterize=PARAMS['characterize'],\n",
    "                              engine=PARAMS['engine'])\n",
    "                print(len(f))\n",
    "                #             diameter=7,\n",
    "                #               minmass=50, maxsize=15,\n",
    "                #               separation=10, invert=PARAMS['invert'],\n",
    "                #               characterize=True, engine='auto')\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                tp.annotate(f, frame)\n",
    "                plt.show()\n",
    "        print(\"temps de travail sur les images : \", (time.time() - time_count)/60, \"min\")\n",
    "        # frame[frame > 90] = 0\n",
    "        # plt.figure(figsize=(12, 6))\n",
    "        # plt.imshow(cv2.GaussianBlur(frame, (251, 251), 0), cmap='gray')\n",
    "        # plt.show()\n",
    "        # if nbr_frame_study_total <= 260:\n",
    "        try:\n",
    "            cells_loc = tp.batch(batch_data,\n",
    "                                diameter=PARAMS['diameter'],\n",
    "                                minmass=PARAMS['minmass'],\n",
    "                                maxsize=PARAMS['max_size'],\n",
    "                                separation=PARAMS['separation'],\n",
    "                                noise_size=PARAMS['noise_size'],\n",
    "                                smoothing_size=PARAMS['smoothing_size'],\n",
    "                                threshold=PARAMS['threshold'],\n",
    "                                invert=PARAMS['invert'],\n",
    "                                percentile=PARAMS['percentile'],\n",
    "                                topn=PARAMS['topn'],\n",
    "                                preprocess=PARAMS['preprocess'],\n",
    "                                max_iterations=PARAMS['max_iterations'],\n",
    "                                filter_before=PARAMS['filter_before'],\n",
    "                                filter_after=PARAMS['filter_after'],\n",
    "                                characterize=PARAMS['characterize'],\n",
    "                                engine=PARAMS['engine'])\n",
    "            cells_loc['frame'] += frame_counter\n",
    "            frame_counter += i\n",
    "            frame_data.append(cells_loc)\n",
    "        except Exception as e:\n",
    "            print(f\"{exp_name} got an issue.\")\n",
    "            return\n",
    "\n",
    "    all_features = pd.concat(frame_data)\n",
    "\n",
    "    try:\n",
    "        trajectories = tp.link_df(all_features,\n",
    "                                  search_range=PARAMS['search_range'],  # PARAMS['max_displacement'],\n",
    "                                  memory=PARAMS['memory'],\n",
    "                                  neighbor_strategy='KDTree',\n",
    "                                  link_strategy='auto',  # 'hybrid',\n",
    "                                  adaptive_stop=3,\n",
    "                                  # verify_integritxy=True,\n",
    "                                  )\n",
    "        trajectories.to_hdf(os.path.join(output_path, 'filtered.hdf5'), 'table')\n",
    "        # verify_intetegrity=True)\n",
    "        # neighbor_strategy='KDTree',\n",
    "    except tp.SubnetOversizeException:\n",
    "        print(\"Issue with this one\")\n",
    "\n",
    "    filtered = tp.filter_stubs(trajectories, PARAMS['min_frames'])\n",
    "    # filtered = filtered[~filtered.particle.isin(\n",
    "    #     tp.filter_clusters(filtered, quantile=0.1,\n",
    "    #                        threshold=filtered['size'].mean() * 1).index)]\n",
    "    all_features.to_hdf(os.path.join(output_path, 'features.hdf5'), 'table')\n",
    "    filtered.to_hdf(os.path.join(output_path, 'filtered.hdf5'), 'table')\n",
    "\n",
    "    fig, axis = plt.subplots(figsize=(10, 10))\n",
    "    plt.title(f'Trajectories after suspicious particles {exp_name}')\n",
    "    tp.plot_traj(filtered, superimpose=batch_data[0], label=(False))\n",
    "    plt.show()\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rprocessing batches:  33%|███▎      | 1/3 [13:38<27:17, 818.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 149: 1 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sk/m9jkmr4n1k5dqc3wj_f53p4r0000gp/T/ipykernel_51823/3124286634.py:47: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  batch_data = [np.array(imageio.imread(tiff_file)) for tiff_file in batch_frames]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Process all experiments.\"\"\"\n",
    "    for exp_name in EXPERIMENT_NAMES:\n",
    "        print(exp_name)\n",
    "        process_experiment(exp_name, PARAMS)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
