{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Aug 21 10:51:23 2023\n",
    "\n",
    "@author: souchaud\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import imageio.v2 as imageio\n",
    "import cv2\n",
    "import gc  # Garbage Collector interface\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import trackpy as tp\n",
    "from scipy import ndimage\n",
    "from skimage import util\n",
    "from tqdm import tqdm\n",
    "# import functions_track_and_analyze as lib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "# from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidated parameters\n",
    "PARAMS = {\n",
    "        # Préparation images\n",
    "        'GaussianBlur': (5, 5), # (19, 19), #  (5, 5),\n",
    "        'sigmaX': 10,\n",
    "        'sigmaY': 10, \n",
    "        'threshold': 1, # 3, # 10  # 40,\n",
    "        'percentile': 20, #10,\n",
    "        'lenght_study': 50, # Découpage de la manip en nombre de frale pour favoriser l'étude (performence ordi)\n",
    "        'smoothing_size': None,\n",
    "        'invert': True,\n",
    "        'preprocess': True, \n",
    "        'characterize': True,\n",
    "        'filter_before': None,\n",
    "        'filter_after': None,\n",
    "        # Paramètres Manip\n",
    "        'pixel_size': 0.637,  # 1.2773, # en um\n",
    "        'frame_interval': 15, # temps entre chaque frame [s]\n",
    "        'long_time': False,\n",
    "        'max_frame': 340, # 340, #340 # Nombre de frame d'étude max.\n",
    "        'min_frames': 150, #150, #150, # Nombre de frame sur laquelle doit être suivie une cellule\n",
    "        'topn': 500, # None, # Nombre de particules max à détecter\n",
    "\n",
    "        # Détéction particules\n",
    "        'diameter': 15,  # 15, # Diamètres évalué des particules\n",
    "        'max_displacement': 30, # 35, # 25, # Déplacement maximal des cellules entre deux images (en pixel)\n",
    "        'search_range': 30, #  30, #  20 # même chose\n",
    "        'minmass': 500, #  Mass minimale mesurée des cellules\n",
    "        'max_size': 30, # 25, # Taille maximum de la particule\n",
    "        'separation': 20, # 9, # distance mimimanl pour séparé deux objets\n",
    "        'noise_size': 3,  # 7, # 7, # taille des particules à exclure \n",
    "        'max_iterations': 15, # Nombre d'itérations max pour résoudre un sous-réseau (déterminer les trajectoires entre 2 cellules)\n",
    "        'memory': 5, # Nombre de frame au dela de laquelle on oublie la cellule\n",
    "        'engine': 'auto',\n",
    "\n",
    "        # Format et chemins\n",
    "        'remove_exts': ['.jpg', '.svg', 'hdf5', '.png'],   \n",
    "        'data_dir': '/Users/souchaud/Desktop/A_Analyser/CytoOne_HL5_10x/',\n",
    "        # 'data_dir': '/Volumes/Labo_Alex_Mac/A_analyser/CytoOne_HL5/',\n",
    "        # 'data_dir': '/Users/souchaud/Desktop/A_Analyser/NonT_SorC/',\n",
    "        # 'output_dir': '/Users/souchaud/Desktop/Analyses/CytoOne_HL5_longtime/'\n",
    "        # 'data_dir': '/Volumes/Labo_Alex_Mac/A_analyser/CytoOne_HL5/',´\n",
    "        'output_dir': '/Users/souchaud/Desktop/Analyses/CytoOne_HL5_10x_new_param/'\n",
    "        # 'output_dir': '/Users/souchaud/Desktop/Analyses/NonT_SorC_longtime_New/'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajoutez cette fonction dans image_processing.py\n",
    "def preprocess_and_locate(tiff_file, params, frame_number):\n",
    "    \"\"\"\n",
    "    Applique le prétraitement à une image unique et utilise tp.locate pour détecter les particules.\n",
    "\n",
    "    :param frame: Image à traiter (déjà chargée en mémoire).\n",
    "    :param params: Dictionnaire contenant les paramètres de prétraitement et de détection des particules.\n",
    "    :param frame_number: Numéro de la frame en cours de traitement.\n",
    "    :return: DataFrame contenant les résultats de la détection des particules avec une colonne supplémentaire pour le numéro de la frame.\n",
    "    \"\"\"\n",
    "    frame = np.array(imageio.imread(tiff_file))\n",
    "    # Appliquer le prétraitement...\n",
    "    blurred = ndimage.median_filter(frame, size=8)\n",
    "    blurred = cv2.GaussianBlur(blurred, params['GaussianBlur'], 0)\n",
    "    # Détecter les particules...\n",
    "    particles = tp.locate(blurred, diameter=params['diameter'], minmass=params['minmass'])\n",
    "    particles['frame'] = frame_number\n",
    "    return particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAMES = [f + '/mosaic/' for f in os.listdir(PARAMS['data_dir'])\n",
    "                    if os.path.isdir(os.path.join(PARAMS['data_dir'], f))]\n",
    "print(EXPERIMENT_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_speed(filtered):\n",
    "    \"\"\"\n",
    "    Compute mean speed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - filtered: DataFrame with tracked cells\n",
    "    Returns\n",
    "    - mean_speed: Mean speed of all particles\n",
    "    - mean_speed_part: Mean speed per particle\n",
    "    \"\"\"\n",
    "    dx = filtered.groupby('particle')['x'].diff()\n",
    "    dy = filtered.groupby('particle')['y'].diff()\n",
    "    displacement = np.sqrt(dx**2 + dy**2)\n",
    "    duration = filtered.groupby('particle')['frame'].diff() * PARAMS['frame_interval']\n",
    "    mean_speed = (displacement.sum() / duration.sum()) * PARAMS['pixel_size'] * 60\n",
    "    instant_speed = displacement / duration\n",
    "    mean_speed_part = instant_speed.groupby(filtered['particle']).mean() * PARAMS['pixel_size'] * 60\n",
    "    return mean_speed, mean_speed_part\n",
    "\n",
    "\n",
    "def clean_directory(dir_path):\n",
    "    \"\"\"Remove all files with the specified extensions in the directory.\"\"\"\n",
    "    for file in os.listdir(dir_path):\n",
    "        if file.endswith(tuple(PARAMS['remove_exts'])):\n",
    "            os.remove(os.path.join(dir_path, file))\n",
    "\n",
    "def adjust_brightness_contrast(img, brightness=0, contrast=0):\n",
    "    \"\"\" Ajuster la luminosité et le contraste d'une image \"\"\"\n",
    "    B = brightness / 100.0\n",
    "    C = contrast / 100.0\n",
    "    k = np.tan((45 + 44 * C) / 180 * np.pi)\n",
    "\n",
    "    img = (img - 127.5 * (1 - B)) * k + 127.5 * (1 + B)\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_experiment(exp_name, PARAMS):\n",
    "    \"\"\"Process a single experiment.\"\"\"\n",
    "    output_path = os.path.join(PARAMS['output_dir'], exp_name)\n",
    "    print(\"output_path : \", output_path)\n",
    "    # Séparer la chaîne au premier \"/\"\n",
    "    exp_name_solo = exp_name.split('/', 1)[0]\n",
    "    print(\"exp name : \", exp_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    clean_directory(output_path)\n",
    "\n",
    "    experiment_data_dir = os.path.join(PARAMS['data_dir'], exp_name)\n",
    "\n",
    "    def extract_number(filename):\n",
    "        # Extrait le numéro à partir du nom de fichier\n",
    "        base_name = os.path.basename(filename)\n",
    "        # Supprime l'extension et extrait le numéro\n",
    "        number = int(base_name.split('_')[-1].split('.')[0])\n",
    "        return number\n",
    "\n",
    "    tiff_files = sorted(glob.glob(os.path.join(experiment_data_dir, \"*.tif\")), key=extract_number)\n",
    "\n",
    "    # Use PARAMS dictionary to get the parameters\n",
    "    frame_data = []\n",
    "    frame_counter = 0\n",
    "    boucle = []\n",
    "    if PARAMS['long_time'] is False:\n",
    "        if len(os.listdir(experiment_data_dir)) < PARAMS['max_frame']:\n",
    "            nbr_frame_study_total = len(os.listdir(experiment_data_dir))\n",
    "        else:\n",
    "            nbr_frame_study_total = PARAMS['max_frame']\n",
    "    else:\n",
    "        nbr_frame_study_total = len(os.listdir(experiment_data_dir))\n",
    "\n",
    "    lenght_study = PARAMS['lenght_study']\n",
    "    if nbr_frame_study_total > lenght_study:\n",
    "        number = lenght_study\n",
    "        while number < nbr_frame_study_total:\n",
    "            boucle.append(lenght_study)\n",
    "            number += lenght_study\n",
    "            if number > nbr_frame_study_total:\n",
    "                boucle.append(nbr_frame_study_total - len(boucle) * lenght_study)\n",
    "        nbr_frame_study = lenght_study\n",
    "    else:\n",
    "        nbr_frame_study = nbr_frame_study_total\n",
    "        boucle.append(nbr_frame_study)\n",
    "\n",
    "    # Process each batch of frames\n",
    "    import time\n",
    "    frame_0 = None  # Initialize frame_0 with a default value\n",
    "    for i in tqdm(boucle, desc=\"processing batches\"):\n",
    "        batch_frames = tiff_files[frame_counter:frame_counter + i]\n",
    "        batch_data = [np.array(imageio.imread(tiff_file)) for tiff_file in batch_frames]\n",
    "        time_count = time.time()\n",
    "\n",
    "\n",
    "    from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "    particles_results = []  # Liste pour stocker les DataFrames des résultats\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        future_to_frame = {\n",
    "            executor.submit(preprocess_and_locate, np.array(imageio.imread(tiff_file)), PARAMS, frame_number): frame_number \n",
    "            for frame_number, tiff_file in enumerate(tiff_files)\n",
    "        }\n",
    "\n",
    "        for future in tqdm(as_completed(future_to_frame), total=len(tiff_files), desc=\"Processing images\"):\n",
    "            frame_number = future_to_frame[future]\n",
    "            try:\n",
    "                frame_result = future.result()\n",
    "                frame_result['frame'] = frame_number  # Ajoutez le numéro de frame au DataFrame\n",
    "                particles_results.append(frame_result)  # Ajoutez le résultat à la liste\n",
    "            except Exception as exc:\n",
    "                print(f\"Frame {frame_number} generated an exception: {exc}\")\n",
    "\n",
    "    # Vérifiez si la liste particles_results est vide avant de tenter de concaténer\n",
    "    if particles_results:\n",
    "        all_features = pd.concat(particles_results, ignore_index=True)\n",
    "        all_features.sort_values(by='frame', inplace=True)  # Trie les résultats par numéro de frame\n",
    "        \n",
    "        # Sauvegardez ou utilisez all_particles selon vos besoins\n",
    "        # Exemple : all_particles.to_csv(os.path.join(output_path, 'all_particles.csv'))\n",
    "    else:\n",
    "        print(\"Aucun résultat à concaténer. Vérifiez les erreurs précédentes.\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        trajectories = tp.link_df(all_features,\n",
    "                                  search_range=PARAMS['search_range'],  # PARAMS['max_displacement'],\n",
    "                                  memory=PARAMS['memory'],\n",
    "                                  neighbor_strategy='KDTree',\n",
    "                                  link_strategy='auto',  # 'hybrid',\n",
    "                                  adaptive_stop=30,\n",
    "                                  # verify_integritxy=True,\n",
    "                                  )\n",
    "        trajectories.to_hdf(os.path.join(output_path, 'filtered.hdf5'), 'table')\n",
    "        # verify_intetegrity=True)\n",
    "        # neighbor_strategy='KDTree',\n",
    "    except tp.SubnetOversizeException:\n",
    "        print(\"Issue with this one\")\n",
    "\n",
    "    filtered = tp.filter_stubs(trajectories, PARAMS['min_frames'])\n",
    "    # filtered = filtered[~filtered.particle.isin(\n",
    "    #     tp.filter_clusters(filtered, quantile=0.1,\n",
    "    #                        threshold=filtered['size'].mean() * 1).index)]\n",
    "    all_features.to_hdf(os.path.join(output_path, 'features.hdf5'), 'table')\n",
    "    filtered.to_hdf(os.path.join(output_path, 'filtered.hdf5'), 'table')\n",
    "    if not filtered.empty:\n",
    "        if frame_0 is not None:\n",
    "            fig, ax = plt.subplots(figsize=(10, 10))\n",
    "            plt.title(f'Trajectories after suspicious particles {exp_name}')\n",
    "            tp.plot_traj(filtered, ax=ax, superimpose=frame_0, label=False)\n",
    "            plt.savefig(f'{output_path}/trajectories_{exp_name_solo}.png')  # Sauvegarder la figure\n",
    "            plt.close(fig)  # Fermer la figure pour libérer la mémoire\n",
    "    else:\n",
    "        print(f\"No trajectories to plot for {exp_name}.\")\n",
    "    gc.collect()  # Force la collecte de déchets pour libérer de la mémoire\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Process all experiments.\"\"\"\n",
    "    for exp_name in EXPERIMENT_NAMES:\n",
    "        print(exp_name)\n",
    "        process_experiment(exp_name, PARAMS)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
